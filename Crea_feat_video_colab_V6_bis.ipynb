{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Crea_feat_video_colab_V6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5xpcZJZDUI2",
        "colab_type": "text"
      },
      "source": [
        "!pip install opencv-contrib-python\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGi6Jr79U29Q",
        "colab_type": "code",
        "outputId": "ab74272c-0318-4142-c9bf-e79b9e6b9ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install opencv-contrib-python==4.1.1.26"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==4.1.1.26 in /usr/local/lib/python3.6/dist-packages (4.1.1.26)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==4.1.1.26) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV27ZKGjU1Xk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5diypuPlDUI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RtYKzHfRTCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8xzNEHDUJN",
        "colab_type": "text"
      },
      "source": [
        "# Télécharger les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98dpIYpDUJQ",
        "colab_type": "code",
        "outputId": "a226019a-c63b-4a92-c0e0-eafc38aa7bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Liaison avec les données\n",
        "!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/f/file/libmagic-mgc_5.32-2ubuntu0.2_amd64.deb  404  Not Found [IP: 91.189.88.149 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/f/file/libmagic1_5.32-2ubuntu0.2_amd64.deb  404  Not Found [IP: 91.189.88.149 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "fatal: destination path 'challenge-m2-sid' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs6EEyMGw_Qe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoJdUSDcxOvO",
        "colab_type": "text"
      },
      "source": [
        "# Détection du nombre de personnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8JqS4bBw67m",
        "colab_type": "code",
        "outputId": "c2c76e12-0db0-4777-88a0-c8a46d53875c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget  'https://pjreddie.com/media/files/yolov3.weights'\n",
        "!git clone 'https://github.com/ultralytics/yolov3'\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-05 15:25:06--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.3’\n",
            "\n",
            "yolov3.weights.3    100%[===================>] 236.52M  38.5MB/s    in 6.6s    \n",
            "\n",
            "2019-11-05 15:25:13 (36.0 MB/s) - ‘yolov3.weights.3’ saved [248007048/248007048]\n",
            "\n",
            "fatal: destination path 'yolov3' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXjpCkzTw7Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Yolo\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3/cfg/yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"yolov3/data/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e63AEBTKx-lS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_persons(img, net, output_layers, classes, colors):\n",
        "\n",
        "    # Loading image\n",
        "    \n",
        "    img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
        "    \n",
        "    height, width, channels = img.shape\n",
        "    \n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "    \n",
        "    # Showing informations on the screen\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                if classes[class_id] in ['person'] :\n",
        "                    boxes.append([x, y, w, h])\n",
        "                    confidences.append(float(confidence))\n",
        "                    class_ids.append(class_id)\n",
        "                   \n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4) \n",
        "\n",
        "    return len(indexes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5h5IGewyqVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_frame_person(nb_pers):\n",
        "    score = 0\n",
        "    if nb_pers==3 : score = 50\n",
        "    if nb_pers in [0,4] : score = 75\n",
        "    if nb_pers > 4 : 100\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwe3h_kPzzL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_pers_per_frame(extract, dic_nb_pers):\n",
        "    return sum(dic_nb_pers[extract])/len(dic_nb_pers[extract])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I9ff5JtynsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_extract_nb_pers(extract, dic_nb_pers):\n",
        "    nb_pers_frames = [score_frame_person(nb_pers) for nb_pers in dic_nb_pers[extract]]\n",
        "    return  sum(nb_pers_frames)/len(dic_nb_pers[extract])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kCvznqV1Fiu",
        "colab_type": "text"
      },
      "source": [
        "# Changements de plan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isw9Iigf1Jdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quantization(frame):\n",
        "    # Representation with 6 bits of the color of each pixel of the image\n",
        "    R, G, B = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
        "    Bit7_R, Bit6_R = np.bitwise_and(R,128)/128 , np.bitwise_and(R,64)/64\n",
        "    Bit7_G, Bit6_G = np.bitwise_and(G,128)/128 , np.bitwise_and(G,64)/64\n",
        "    Bit7_B, Bit6_B = np.bitwise_and(B,128)/128 , np.bitwise_and(B,64)/64\n",
        "    return(Bit7_R*32 + Bit6_R*16 + Bit7_G*8 +Bit6_G*4 + Bit7_B*2 + Bit6_B )\n",
        "\n",
        "\n",
        "def histogram(frame):\n",
        "    # For an image, creation of a list of 64 values.\n",
        "    # The first value indicates how many pixels have their color encoded with 0, \n",
        "    # the second value indicates how many pixels have their color encoded with 1, ...\n",
        "    h = np.histogram(frame.ravel(), bins = np.arange(64))\n",
        "    return(h[0].tolist())\n",
        "\n",
        "def distance(H):\n",
        "    # Returns a list of Manhattan distances between two consecutives frames\n",
        "    # H : list containing the histograms of each frame kept of a video\n",
        "    D_total = []\n",
        "    for i in range(len(H)-1):\n",
        "        distM = cdist(np.asarray([H[i]]),np.asarray([H[i+1]]), metric='cityblock')\n",
        "        D_total.append(distM[0][0])\n",
        "    return(D_total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejNV7cEP9ad6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_scene_break(D, threshold = 60000):\n",
        "    # Returns the list of the index of the frames where the scene breaks occur\n",
        "    # A scene break occurs when the Manhattan distance is upper than the threshold\n",
        "    # D : list of Manhattan distances between two consecutives frames\n",
        "    plans=[]\n",
        "    for i in range (len(D)):\n",
        "        if D[i] > threshold:\n",
        "            plans.append(i+1)\n",
        "    to_drop = []\n",
        "    for j in range((len(plans) - 1)) : \n",
        "        if plans[j+1] <= plans[j]+ 3 :\n",
        "            to_drop.append(plans[j+1])\n",
        "    plans = set(plans) - set(to_drop)\n",
        "    return(plans)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLH3Bv29nuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scene_break_per_min(histos, nb_fps_kept):\n",
        "    distances_M = distance(histos)\n",
        "    return len(count_scene_break(distances_M))*nb_fps_kept*60/(len(histos))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "4ckC86eyDUJY",
        "colab_type": "text"
      },
      "source": [
        "# Création des features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yN04_F4DUJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_features(path_video, extract, nb_fps_kept, dic_nb_pers):\n",
        "    # For each extract, create a file with a certain amount of frames\n",
        "    # video :  name of the video ('....m4v')\n",
        "    # path_video : path to the file containing the video\n",
        "    # nb_fps_kept : number of frames to keep for every second of the video\n",
        "\n",
        "    # set video file path of input video with name and extension\n",
        "    vid = cv2.VideoCapture(path_video + extract)\n",
        "    extr_name = extract[:-len('.m4v')] \n",
        "    \n",
        "    # Finding the number of frame per second\n",
        "    fps = int(round(vid.get(cv2.CAP_PROP_FPS),0))\n",
        "    step = int(round(fps//nb_fps_kept,0))\n",
        "   \n",
        "    # Height and width of the images\n",
        "    #print(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    #print(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    dic_nb_pers[extr_name]=[] \n",
        "    histos = []\n",
        "\n",
        "    #for frame identity\n",
        "    index = 0\n",
        "    while(True):\n",
        "        # Extract images\n",
        "        ret, frame = vid.read()\n",
        "        \n",
        "        # end of frames\n",
        "        if not ret: \n",
        "            break\n",
        "\n",
        "        if index%step == 0: \n",
        "            dic_nb_pers[extr_name].append(detect_persons(frame, *params_YOLO))      \n",
        "            histos.append(histogram(quantization(frame)))\n",
        "      \n",
        "        # next frame\n",
        "        index += 1\n",
        "    \n",
        "    mean_pers = mean_pers_per_frame(extr_name, dic_nb_pers)\n",
        "    score_nb_pers = score_extract_nb_pers(extr_name, dic_nb_pers)\n",
        "    breaks_per_min = scene_break_per_min(histos, nb_fps_kept)\n",
        "    return mean_pers, score_nb_pers, breaks_per_min\n",
        "    #return breaks_per_min\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZGpch3KAFMr",
        "colab_type": "text"
      },
      "source": [
        "# Initialisation des variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r5L2PLCvA_Mx",
        "colab": {}
      },
      "source": [
        "path = 'challenge-m2-sid/'\n",
        "path_video = 'challenge-m2-sid/corpus/video/'\n",
        "path_videos_output = 'Video_output/'\n",
        "nb_fps_kept = 4\n",
        "dic_nb_pers = dict()\n",
        "params_YOLO = (net, output_layers, classes, colors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "niwmjCfxDUJ3",
        "colab_type": "text"
      },
      "source": [
        "# Test sur un extrait"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3K4poEbGN2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract = '121_13.m4v'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvF7nqGHILyC",
        "colab_type": "code",
        "outputId": "3d931060-7b39-4f13-88a3-c04037aff92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "create_features(path_video, extract, nb_fps_kept, dic_nb_pers)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.0849056603773586, 16.745283018867923, 27.169811320754718)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drcYT1hp0XSA",
        "colab_type": "text"
      },
      "source": [
        "# Creation des features pour tous les extraits "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brSaA_1gDbIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for video in os.listdir(path_video):\n",
        "    create_frames(path_video + video, path_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYe3YyquBJ0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for extract in os.listdir('Video_output/'):  \n",
        "    dic_nb_pers[extract]=[] \n",
        "    for frame in os.listdir('Video_output/' + extract + '/') : \n",
        "        dic_nb_pers[extract].append(detect_objects('Video_output/' + extract + '/' + frame, net, \n",
        "                                   output_layers, classes, colors))  \n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97wYa9ScDUK2",
        "colab_type": "text"
      },
      "source": [
        "# Détection de visages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274j66JfDUK4",
        "colab_type": "code",
        "outputId": "aa12d7cb-4fc9-43cf-b6c9-842924a7f7c5",
        "colab": {}
      },
      "source": [
        "# coding:latin-1\n",
        "\n",
        "def detect_faces(image, image_out, path_haar, show = False):\n",
        "    # on charge l'image en mémoire\n",
        "    img = cv2.imread(image)\n",
        "    print(type(img))\n",
        "    #cv2.imshow('Image',img)\n",
        "    # on charge le modèle de détection des visages\n",
        "    face_model = cv2.CascadeClassifier(\"OpenCV/\" + path_haar)\n",
        "     \n",
        "     \n",
        "    # détection du ou des visages\n",
        "    faces = face_model.detectMultiScale(img)\n",
        "     \n",
        "    # on place un cadre autour des visages\n",
        "    print (\"nombre de visages\", len(faces), \"dimension de l'image\", img.shape, \"image\", image)\n",
        "    for face in faces:\n",
        "        cv2.rectangle(img, (face[0], face[1]), (face[0] + face[2], face[0] + face[3]), (255, 0, 0), 3)\n",
        "         \n",
        "    # on sauvegarde le résultat final\n",
        "    cv2.imwrite(image_out, img)\n",
        "     \n",
        "    # pour voir l'image, presser ESC pour sortir\n",
        "    if show :\n",
        "        cv2.imshow(\"visage\",img)\n",
        "        if cv2.waitKey(5000) == 27: cv2.destroyWindow(\"visage\")\n",
        "                                       \n",
        "path_haar_frontal = 'haarcascade_frontalface_alt2.xml'\n",
        "path_haar_profile = 'haarcascade_profileface.xml'\n",
        "\n",
        "\n",
        "detect_faces('Images/Input/test.jpg', 'res_visage_' + 'front_' + file, path_haar_frontal, True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (878, 1170, 3) image Images/Input/test.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSMvphhDUK8",
        "colab_type": "code",
        "outputId": "0829a3b7-5fa7-4c44-ac16-d4ab320b2113",
        "colab": {}
      },
      "source": [
        "\n",
        "for file in os.listdir(path_input):    \n",
        "    if os.path.splitext(file)[-1].lower() in [\".jpg\", \".jpeg\", \".png\" ] :    \n",
        "        print(file)\n",
        "        detect_faces(path_input + file, path_output + 'res_visage_' + 'front_' + file, path_haar_frontal, True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 0 dimension de l'image (147, 342, 3) image Images/Input/images.jpg\n",
            "Lenna.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (512, 512, 3) image Images/Input/Lenna.jpg\n",
            "test.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (878, 1170, 3) image Images/Input/test.jpg\n",
            "test2.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 2 dimension de l'image (878, 1170, 3) image Images/Input/test2.jpg\n",
            "test3.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 0 dimension de l'image (878, 1170, 3) image Images/Input/test3.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOBOKvJ_DULB",
        "colab_type": "code",
        "outputId": "31ba9121-8a6d-4e1b-f629-d7a35b6cb8e6",
        "colab": {}
      },
      "source": [
        "for file in os.listdir(path_input):    \n",
        "    if os.path.splitext(file)[-1].lower() in [\".jpg\", \".jpeg\", \".png\" ] :    \n",
        "        print(file)\n",
        "        detect_faces(path_input + file, path_output + 'res_visage_' + 'profile_' + file, path_haar_profile, True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (147, 342, 3) image Images/Input/images.jpg\n",
            "Lenna.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 0 dimension de l'image (512, 512, 3) image Images/Input/Lenna.jpg\n",
            "test.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (878, 1170, 3) image Images/Input/test.jpg\n",
            "test2.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 1 dimension de l'image (878, 1170, 3) image Images/Input/test2.jpg\n",
            "test3.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "nombre de visages 0 dimension de l'image (878, 1170, 3) image Images/Input/test3.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URANVlbzDULG",
        "colab_type": "text"
      },
      "source": [
        "# Création de features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdrhZRQEDULI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5LpPDjzDULM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}