{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_feature_12345_aggreg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6t6jWihX0aH",
        "colab_type": "text"
      },
      "source": [
        "# Challenge M2 SID : Partie Texte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXPU1GuryU-9",
        "colab_type": "text"
      },
      "source": [
        "### 1 - Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bMGx3icXxPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf challenge-m2-sid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJiWXJkOYRHg",
        "colab_type": "code",
        "outputId": "fefb16b5-9eee-41d4-b7a8-a92a7e931e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Liaison avec les donn√©es\n",
        "!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 132681 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package bc.\n",
            "Preparing to unpack .../4-bc_1.07.1-2_amd64.deb ...\n",
            "Unpacking bc (1.07.1-2) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../5-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../7-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../8-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package tree.\n",
            "Preparing to unpack .../9-tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up bc (1.07.1-2) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Cloning into 'challenge-m2-sid'...\n",
            "remote: Enumerating objects: 938, done.\u001b[K\n",
            "remote: Counting objects: 100% (938/938), done.\u001b[K\n",
            "remote: Compressing objects: 100% (930/930), done.\u001b[K\n",
            "remote: Total 938 (delta 5), reused 933 (delta 3)\u001b[K\n",
            "Receiving objects: 100% (938/938), 2.15 GiB | 14.96 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "Checking out files: 100% (904/904), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cF5YGYHZVBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re  \n",
        "from sklearn import preprocessing\n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import spacy\n",
        "from google.colab import files\n",
        "from sklearn import preprocessing\n",
        "import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import urllib.request"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFFTnA370tU",
        "colab_type": "code",
        "outputId": "1f1287ff-aa93-4118-f1c9-2ca9743c0678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print('Beginning file download')\n",
        "\n",
        "url = 'http://www.lexique.org/shiny/lexique/session/f5a29584fd4e031d9548b6a8da88c38d/download/download?w='\n",
        "urllib.request.urlretrieve(url, 'Lexique-query-2019-10-29 09_16_32.xlsx')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning file download\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Lexique-query-2019-10-29 09_16_32.xlsx',\n",
              " <http.client.HTTPMessage at 0x7f499cae4780>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhAwP14z4owp",
        "colab_type": "text"
      },
      "source": [
        "### 2 - Test code for every feature (RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q41-0kxrodo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_file = pd.read_csv(\"/content/challenge-m2-sid/annotations_challenge_sid.csv\", sep=\"\\t\" )\n",
        "\n",
        "# keep only lines that contains a number different from -1\n",
        "only_commented = []\n",
        "for index, row in csv_file.iterrows():\n",
        "    if row[\"il08_09\"] != -1 or row[\"vg04_05\"] != -1 \\\n",
        "            or row[\"fd03_04\"] != -1 or row[\"la09_10\"] != -1 \\\n",
        "        or row[\"cg13_14\"] != -1 or row[\"mb00_12\"] != -1 :\n",
        "        only_commented.append(row)\n",
        "# Transform it into a DataFrame\n",
        "only_commented = pd.DataFrame(only_commented)\n",
        "\n",
        "\n",
        "\n",
        "# Return a subset of informations limited to a communication medium \n",
        "# (audio : 100 , text : 001, audio and video : 110, audio and text : 101 \n",
        "# audio, video and text : 111)\n",
        "def get_medium(medium, df):\n",
        "    return df[df[\"code_doc\"].str.contains(\".*\"+medium+\"_[0-1]{1}\",regex=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3YJIB4S2V58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compar_anno(metric_fun, medium, only_commented):\n",
        "  list_max=list_max_docid(medium,only_commented)\n",
        "  #error_moy = np.array([])\n",
        "  list_doc = np.array([])\n",
        "  list_pred = np.array([])\n",
        "  list_annot = np.array([])\n",
        "  for doc in list_max:\n",
        "    list_pred = np.append(list_pred, metric_fun[doc])\n",
        "    list_doc = np.append(list_doc,doc)\n",
        "    list_annot = np.append(list_annot,list_max[doc])\n",
        "    #y_pred = metric_fun[doc]\n",
        "    #error = mean_squared_error(annot, y_pred)\n",
        "    #print(str(doc) + \" Annotation : \"+ str(list_max[doc]) + \" / pred :\" + str(y_pred) + \" / Error : \" + mean_squared_error(list_max[doc], y_pred))\n",
        "  print(\"Error(RMSE) : \" + str(np.sqrt(mean_squared_error(list_annot,list_pred))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p8Mvrb87OLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_max_docid(medium, only_commented):\n",
        "  # Get the list of annotated extracts for a medium\n",
        "  medium = get_medium(medium, only_commented)\n",
        "  # Get list of files identifiants\n",
        "  list_file = medium[\"code_doc\"]\n",
        "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
        "  # Return [(doc_id, max(annot)),....]\n",
        "  return {(i[0][:-6]+\".xml\"):i[1:].max() for i in medium[medium.columns[-7:]].values }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHR2jU9vzQGJ",
        "colab_type": "text"
      },
      "source": [
        "### 3 - Getting words and sentences, and cleaning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gUZgl3qT83pG",
        "colab": {}
      },
      "source": [
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtmX_015i0E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_text = 'challenge-m2-sid/corpus/text/'\n",
        "List_txt = os.listdir(path_text)\n",
        "List_txt.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mdi9xoTgv4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences(List_txt, path_text):\n",
        "  dic_docs = {}\n",
        "  for doc in List_txt:\n",
        "    tree = ET.parse(path_text + doc)\n",
        "    root = tree.getroot()\n",
        "    dic_docs[doc] = []\n",
        "    for s in root:\n",
        "      sentence = ''\n",
        "      for w in s:\n",
        "        word = w.text\n",
        "        if (word is not None):\n",
        "          sentence = sentence + word\n",
        "      dic_docs[doc].append(sentence)\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CU5-6O7q3k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_sentences(dic_docs):  \n",
        "  for key in dic_docs.keys() : \n",
        "    list_new = []\n",
        "    for sentence in dic_docs[key]:\n",
        "      sentence = sentence.replace(\"'\", ' ').replace(\"‚Äô\", ' ')\n",
        "      sentence = re.sub(\"([^\\s\\w\\-])\", '',sentence)\n",
        "      list_new.append(sentence)\n",
        "    dic_docs[key] = list_new\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncwJ7CL63DsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nlp = spacy.load('fr_core_news_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvcRbvexwluh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clean_words(dic_docs):\n",
        "  for key in dic_docs.keys() : \n",
        "    list_words = []\n",
        "    for sentence in dic_docs[key]:\n",
        "      for word in sentence.split():\n",
        "          w = word.replace(' ', '')\n",
        "          if len(w) != 0:\n",
        "            list_words.append(w.lower())\n",
        "    dic_docs[key] = list_words\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45_Zfg7WiDSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_docs = get_clean_words(clean_sentences(get_sentences(List_txt, path_text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFaXktLP3Ca1",
        "colab_type": "text"
      },
      "source": [
        "### Feature 1 : number of low frequencie words per video "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hcNgsHHiY4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_excel(file):\n",
        "  dfs = pd.ExcelFile(file)\n",
        "  sh = dfs.sheet_names[0]\n",
        "  df_lex = dfs.parse('Sheet1')\n",
        "  df_lex = df_lex[['ortho', 'lemme', 'cgram', 'freqfilms2', 'nbsyll']]\n",
        "  serie = df_lex['freqfilms2']\n",
        "  normalized_serie=(serie)/max(serie)\n",
        "  df_lex['freqfilms2_norm'] = normalized_serie\n",
        "  return(df_lex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH1p2o6uiy_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_lex = read_excel('Lexique-query-2019-10-29 09_16_32.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcH1yHkO8bwU",
        "colab_type": "code",
        "outputId": "69f5e2f3-936c-4b5a-ba52-e1f98017abea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "df_lex"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ortho</th>\n",
              "      <th>lemme</th>\n",
              "      <th>cgram</th>\n",
              "      <th>freqfilms2</th>\n",
              "      <th>nbsyll</th>\n",
              "      <th>freqfilms2_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>NOM</td>\n",
              "      <td>81.36</td>\n",
              "      <td>1</td>\n",
              "      <td>3.131254e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>avoir</td>\n",
              "      <td>AUX</td>\n",
              "      <td>6350.91</td>\n",
              "      <td>1</td>\n",
              "      <td>2.444237e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>avoir</td>\n",
              "      <td>VER</td>\n",
              "      <td>5498.34</td>\n",
              "      <td>1</td>\n",
              "      <td>2.116113e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a capella</td>\n",
              "      <td>a capella</td>\n",
              "      <td>ADV</td>\n",
              "      <td>0.04</td>\n",
              "      <td>4</td>\n",
              "      <td>1.539456e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a cappella</td>\n",
              "      <td>a cappella</td>\n",
              "      <td>ADV</td>\n",
              "      <td>0.04</td>\n",
              "      <td>4</td>\n",
              "      <td>1.539456e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142689</th>\n",
              "      <td>√¥t√©e</td>\n",
              "      <td>√¥t√©</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2</td>\n",
              "      <td>3.848641e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142690</th>\n",
              "      <td>√¥t√©es</td>\n",
              "      <td>√¥ter</td>\n",
              "      <td>VER</td>\n",
              "      <td>0.16</td>\n",
              "      <td>2</td>\n",
              "      <td>6.157825e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142691</th>\n",
              "      <td>√¥t√©es</td>\n",
              "      <td>√¥t√©</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>3.848641e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142692</th>\n",
              "      <td>√¥t√©s</td>\n",
              "      <td>√¥ter</td>\n",
              "      <td>VER</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2</td>\n",
              "      <td>1.539456e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142693</th>\n",
              "      <td>√¥t√©s</td>\n",
              "      <td>√¥t√©</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>3.848641e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142694 rows √ó 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ortho       lemme cgram  freqfilms2  nbsyll  freqfilms2_norm\n",
              "0                a           a   NOM       81.36       1     3.131254e-03\n",
              "1                a       avoir   AUX     6350.91       1     2.444237e-01\n",
              "2                a       avoir   VER     5498.34       1     2.116113e-01\n",
              "3        a capella   a capella   ADV        0.04       4     1.539456e-06\n",
              "4       a cappella  a cappella   ADV        0.04       4     1.539456e-06\n",
              "...            ...         ...   ...         ...     ...              ...\n",
              "142689        √¥t√©e         √¥t√©   ADJ        0.10       2     3.848641e-06\n",
              "142690       √¥t√©es        √¥ter   VER        0.16       2     6.157825e-06\n",
              "142691       √¥t√©es         √¥t√©   ADJ        0.01       2     3.848641e-07\n",
              "142692        √¥t√©s        √¥ter   VER        0.04       2     1.539456e-06\n",
              "142693        √¥t√©s         √¥t√©   ADJ        0.01       2     3.848641e-07\n",
              "\n",
              "[142694 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pba9u33B7Yve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_complexity_doc(doc, df_lex, dic_docs):\n",
        "  cplxty = 0\n",
        "  for word in list(set(dic_docs[doc])):\n",
        "    try : \n",
        "      freq = max(df_lex[df_lex['ortho']==word]['freqlemfilms2_norm'])\n",
        "    except :\n",
        "      if len(word) >= 3:\n",
        "        freq = 0\n",
        "      else : \n",
        "        freq = 1\n",
        "    if freq < 0.0001:\n",
        "      cplxty = cplxty + 1\n",
        "#      print(word)\n",
        "#      print(freq)\n",
        "  cplxty = cplxty/(len(list(set(dic_docs[doc]))))\n",
        "  return(cplxty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_WQRJpCj2fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_cplx(df_lex, dic_docs):\n",
        "  dic_cplx = {}\n",
        "  i = 1\n",
        "  N = len(dic_docs.keys())\n",
        "  for doc in dic_docs.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    dic_cplx[doc] = get_complexity_doc(doc, df_lex, dic_docs)\n",
        "    i = i + 1\n",
        "  return(dic_cplx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRalZfTjvj-",
        "colab_type": "code",
        "outputId": "827115d9-e861-4115-de32-cd82e34c4b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dic_cplx = get_all_cplx(df_lex, dic_docs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 300\n",
            "2 / 300\n",
            "3 / 300\n",
            "4 / 300\n",
            "5 / 300\n",
            "6 / 300\n",
            "7 / 300\n",
            "8 / 300\n",
            "9 / 300\n",
            "10 / 300\n",
            "11 / 300\n",
            "12 / 300\n",
            "13 / 300\n",
            "14 / 300\n",
            "15 / 300\n",
            "16 / 300\n",
            "17 / 300\n",
            "18 / 300\n",
            "19 / 300\n",
            "20 / 300\n",
            "21 / 300\n",
            "22 / 300\n",
            "23 / 300\n",
            "24 / 300\n",
            "25 / 300\n",
            "26 / 300\n",
            "27 / 300\n",
            "28 / 300\n",
            "29 / 300\n",
            "30 / 300\n",
            "31 / 300\n",
            "32 / 300\n",
            "33 / 300\n",
            "34 / 300\n",
            "35 / 300\n",
            "36 / 300\n",
            "37 / 300\n",
            "38 / 300\n",
            "39 / 300\n",
            "40 / 300\n",
            "41 / 300\n",
            "42 / 300\n",
            "43 / 300\n",
            "44 / 300\n",
            "45 / 300\n",
            "46 / 300\n",
            "47 / 300\n",
            "48 / 300\n",
            "49 / 300\n",
            "50 / 300\n",
            "51 / 300\n",
            "52 / 300\n",
            "53 / 300\n",
            "54 / 300\n",
            "55 / 300\n",
            "56 / 300\n",
            "57 / 300\n",
            "58 / 300\n",
            "59 / 300\n",
            "60 / 300\n",
            "61 / 300\n",
            "62 / 300\n",
            "63 / 300\n",
            "64 / 300\n",
            "65 / 300\n",
            "66 / 300\n",
            "67 / 300\n",
            "68 / 300\n",
            "69 / 300\n",
            "70 / 300\n",
            "71 / 300\n",
            "72 / 300\n",
            "73 / 300\n",
            "74 / 300\n",
            "75 / 300\n",
            "76 / 300\n",
            "77 / 300\n",
            "78 / 300\n",
            "79 / 300\n",
            "80 / 300\n",
            "81 / 300\n",
            "82 / 300\n",
            "83 / 300\n",
            "84 / 300\n",
            "85 / 300\n",
            "86 / 300\n",
            "87 / 300\n",
            "88 / 300\n",
            "89 / 300\n",
            "90 / 300\n",
            "91 / 300\n",
            "92 / 300\n",
            "93 / 300\n",
            "94 / 300\n",
            "95 / 300\n",
            "96 / 300\n",
            "97 / 300\n",
            "98 / 300\n",
            "99 / 300\n",
            "100 / 300\n",
            "101 / 300\n",
            "102 / 300\n",
            "103 / 300\n",
            "104 / 300\n",
            "105 / 300\n",
            "106 / 300\n",
            "107 / 300\n",
            "108 / 300\n",
            "109 / 300\n",
            "110 / 300\n",
            "111 / 300\n",
            "112 / 300\n",
            "113 / 300\n",
            "114 / 300\n",
            "115 / 300\n",
            "116 / 300\n",
            "117 / 300\n",
            "118 / 300\n",
            "119 / 300\n",
            "120 / 300\n",
            "121 / 300\n",
            "122 / 300\n",
            "123 / 300\n",
            "124 / 300\n",
            "125 / 300\n",
            "126 / 300\n",
            "127 / 300\n",
            "128 / 300\n",
            "129 / 300\n",
            "130 / 300\n",
            "131 / 300\n",
            "132 / 300\n",
            "133 / 300\n",
            "134 / 300\n",
            "135 / 300\n",
            "136 / 300\n",
            "137 / 300\n",
            "138 / 300\n",
            "139 / 300\n",
            "140 / 300\n",
            "141 / 300\n",
            "142 / 300\n",
            "143 / 300\n",
            "144 / 300\n",
            "145 / 300\n",
            "146 / 300\n",
            "147 / 300\n",
            "148 / 300\n",
            "149 / 300\n",
            "150 / 300\n",
            "151 / 300\n",
            "152 / 300\n",
            "153 / 300\n",
            "154 / 300\n",
            "155 / 300\n",
            "156 / 300\n",
            "157 / 300\n",
            "158 / 300\n",
            "159 / 300\n",
            "160 / 300\n",
            "161 / 300\n",
            "162 / 300\n",
            "163 / 300\n",
            "164 / 300\n",
            "165 / 300\n",
            "166 / 300\n",
            "167 / 300\n",
            "168 / 300\n",
            "169 / 300\n",
            "170 / 300\n",
            "171 / 300\n",
            "172 / 300\n",
            "173 / 300\n",
            "174 / 300\n",
            "175 / 300\n",
            "176 / 300\n",
            "177 / 300\n",
            "178 / 300\n",
            "179 / 300\n",
            "180 / 300\n",
            "181 / 300\n",
            "182 / 300\n",
            "183 / 300\n",
            "184 / 300\n",
            "185 / 300\n",
            "186 / 300\n",
            "187 / 300\n",
            "188 / 300\n",
            "189 / 300\n",
            "190 / 300\n",
            "191 / 300\n",
            "192 / 300\n",
            "193 / 300\n",
            "194 / 300\n",
            "195 / 300\n",
            "196 / 300\n",
            "197 / 300\n",
            "198 / 300\n",
            "199 / 300\n",
            "200 / 300\n",
            "201 / 300\n",
            "202 / 300\n",
            "203 / 300\n",
            "204 / 300\n",
            "205 / 300\n",
            "206 / 300\n",
            "207 / 300\n",
            "208 / 300\n",
            "209 / 300\n",
            "210 / 300\n",
            "211 / 300\n",
            "212 / 300\n",
            "213 / 300\n",
            "214 / 300\n",
            "215 / 300\n",
            "216 / 300\n",
            "217 / 300\n",
            "218 / 300\n",
            "219 / 300\n",
            "220 / 300\n",
            "221 / 300\n",
            "222 / 300\n",
            "223 / 300\n",
            "224 / 300\n",
            "225 / 300\n",
            "226 / 300\n",
            "227 / 300\n",
            "228 / 300\n",
            "229 / 300\n",
            "230 / 300\n",
            "231 / 300\n",
            "232 / 300\n",
            "233 / 300\n",
            "234 / 300\n",
            "235 / 300\n",
            "236 / 300\n",
            "237 / 300\n",
            "238 / 300\n",
            "239 / 300\n",
            "240 / 300\n",
            "241 / 300\n",
            "242 / 300\n",
            "243 / 300\n",
            "244 / 300\n",
            "245 / 300\n",
            "246 / 300\n",
            "247 / 300\n",
            "248 / 300\n",
            "249 / 300\n",
            "250 / 300\n",
            "251 / 300\n",
            "252 / 300\n",
            "253 / 300\n",
            "254 / 300\n",
            "255 / 300\n",
            "256 / 300\n",
            "257 / 300\n",
            "258 / 300\n",
            "259 / 300\n",
            "260 / 300\n",
            "261 / 300\n",
            "262 / 300\n",
            "263 / 300\n",
            "264 / 300\n",
            "265 / 300\n",
            "266 / 300\n",
            "267 / 300\n",
            "268 / 300\n",
            "269 / 300\n",
            "270 / 300\n",
            "271 / 300\n",
            "272 / 300\n",
            "273 / 300\n",
            "274 / 300\n",
            "275 / 300\n",
            "276 / 300\n",
            "277 / 300\n",
            "278 / 300\n",
            "279 / 300\n",
            "280 / 300\n",
            "281 / 300\n",
            "282 / 300\n",
            "283 / 300\n",
            "284 / 300\n",
            "285 / 300\n",
            "286 / 300\n",
            "287 / 300\n",
            "288 / 300\n",
            "289 / 300\n",
            "290 / 300\n",
            "291 / 300\n",
            "292 / 300\n",
            "293 / 300\n",
            "294 / 300\n",
            "295 / 300\n",
            "296 / 300\n",
            "297 / 300\n",
            "298 / 300\n",
            "299 / 300\n",
            "300 / 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLJ1k7tIBWYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ma_cplx = max(dic_cplx.values())\n",
        "mi_cplx = min(dic_cplx.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clTk_3V8kYOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_results(dic, ma, mi):\n",
        "  dic_N = {}\n",
        "  for doc in dic.keys():\n",
        "    score = dic[doc]\n",
        "    score =  100 * (score - mi) / (ma - mi)\n",
        "    dic_N[doc] = score\n",
        "  return(dic_N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KWKZyKhASdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cplx_1_doc(ma, doc, df_lex, dic_docs):\n",
        "  return(normalize_results({doc:get_complexity_doc(doc, df_lex, dic_docs)}, ma)[doc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5HMBqsvlC-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_cplx_N = normalize_results(dic_cplx, ma_cplx, mi_cplx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr913odv6-0N",
        "colab_type": "code",
        "outputId": "c66f496a-d713-4caa-e44c-add591a12405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "compar_anno(dic_cplx_N, \"001\", only_commented)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(RMSE) : 24.89150408305225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10uxGAm93KqG",
        "colab_type": "text"
      },
      "source": [
        "### Feature 2 - 3 : Number of sentences per minute and mean length of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAby9i09oN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_docs_sent = clean_sentences(get_sentences(List_txt, path_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgyxSc23jIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_length_sentences_nb(dic_docs_sent, dic_doc_len_video):\n",
        "  dic_len_sentence = {}\n",
        "  dic_nb_sentence =  {}\n",
        "  for doc in dic_docs_sent.keys():\n",
        "    time = dic_doc_len_video[doc]\n",
        "    time_s = time.total_seconds()\n",
        "    nb_s = len(dic_docs_sent[doc])\n",
        "    s_per_min = 60*nb_s/time_s\n",
        "    mean_len_s = np.mean([len(s.split()) for s in dic_docs_sent[doc]])\n",
        "    dic_len_sentence[doc] = mean_len_s\n",
        "    dic_nb_sentence[doc] = s_per_min\n",
        "  return(dic_len_sentence, dic_nb_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFLo754_BP0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_len_video(List_txt, path_text):\n",
        "  dic_doc_len_video = {}\n",
        "  for doc in List_txt:\n",
        "    tree = ET.parse(path_text + doc)\n",
        "    root = tree.getroot()\n",
        "    ma = int(max([root[i].attrib['id'] for i in range(len(root))]))\n",
        "    start = root[0][0].attrib['value'][:8]\n",
        "    end = root[ma-1][-1].attrib['value'][:8]\n",
        "    format_ = '%H:%M:%S'\n",
        "    startDateTime = datetime.datetime.strptime(start, format_)\n",
        "    endDateTime = datetime.datetime.strptime(end, format_)\n",
        "    diff = endDateTime - startDateTime\n",
        "    dic_doc_len_video[doc] = diff\n",
        "  return(dic_doc_len_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkgK9wgVDPLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_doc_len_video = get_len_video(List_txt, path_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpxSNs_L5DkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_len_sentence, dic_nb_sentence = get_length_sentences_nb(dic_docs_sent, dic_doc_len_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op1v_aBr5cON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ma_nb_s = max(dic_nb_sentence.values())\n",
        "mi_nb_s = min(dic_nb_sentence.values())\n",
        "ma_len_s = max(dic_len_sentence.values())\n",
        "mi_len_s = min(dic_len_sentence.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ie1HnIB73d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_len_sentence_N = normalize_results(dic_len_sentence, ma_len_s, mi_len_s)\n",
        "dic_nb_sentence_N = normalize_results(dic_nb_sentence, ma_nb_s, mi_nb_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjpgrR4C8GWM",
        "colab_type": "code",
        "outputId": "a6c3b7eb-2b2b-4991-e058-56e1985c590b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "compar_anno(dic_len_sentence_N, \"001\", only_commented)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(RMSE) : 31.08983940988317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmBOouJx8VmJ",
        "colab_type": "code",
        "outputId": "8be7e661-4c34-4acc-af85-6641d91af11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "compar_anno(dic_nb_sentence_N, \"001\", only_commented)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(RMSE) : 46.7215680126897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTMLtBiK-58E",
        "colab_type": "text"
      },
      "source": [
        "### Feature 4 : word repetition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVS4fTpvLfQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_repetition_ratio_doc(doc, dic_docs):\n",
        "  list_words_dif = list(set(dic_docs[doc]))\n",
        "  list_words = dic_docs[doc]\n",
        "  rep = 100*(len(list_words_dif)/len(list_words))\n",
        "  return(rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGuhlx9Mm4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_rep (dic_docs):\n",
        "  dic_repetition = {}\n",
        "  for doc in dic_docs.keys():\n",
        "    dic_repetition[doc] = get_repetition_ratio_doc(doc, dic_docs)\n",
        "  return(dic_repetition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHA_Cg02M07F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_repetition = get_all_rep (dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymXjTxlAIjKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ma_repet = max(dic_repetition.values())\n",
        "mi_repet = min(dic_repetition.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezQfPVcnIs2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_repetition_N = normalize_results(dic_repetition, ma_repet, mi_repet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYgphZu7M5k5",
        "colab_type": "code",
        "outputId": "894ee591-6d1c-40a9-ba42-148b5519eb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "compar_anno(dic_repetition_N, \"001\", only_commented)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(RMSE) : 30.77934152452047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE7clVBBO8PB",
        "colab_type": "text"
      },
      "source": [
        "### Feature 5 : Syllable per second"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOp9PnHPSinY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time_sentence(List_txt, path_text):\n",
        "  dic_doc_time_sentences = {}\n",
        "  for doc in List_txt:\n",
        "    tree = ET.parse(path_text + doc)\n",
        "    root = tree.getroot()\n",
        "    list_times_sec = []\n",
        "    for child in root : \n",
        "      TS = child[0].attrib['value'][:8]\n",
        "      TE = child[-1].attrib['value'][:8]\n",
        "      format_ = '%H:%M:%S'\n",
        "      startDateTime = datetime.datetime.strptime(TS, format_)\n",
        "      endDateTime = datetime.datetime.strptime(TE, format_)\n",
        "      diff = endDateTime - startDateTime\n",
        "      list_times_sec.append(diff.total_seconds())\n",
        "    dic_doc_time_sentences[doc] = list_times_sec\n",
        "  return(dic_doc_time_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmPZNoJuTrYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_doc_time_sentences =  get_time_sentence(List_txt, path_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90mW8leTyrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_syll_sec (dic_doc_time_sentences, dic_docs, df_lex):\n",
        "  dic_syll_per_sec = {}\n",
        "  i = 1\n",
        "  N = len(dic_docs)\n",
        "  m = np.mean(df_lex['nbsyll'])\n",
        "  list_words = list(set(list(df_lex['ortho'])))\n",
        "  for doc in dic_doc_time_sentences.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    time = 0\n",
        "    syll = 0\n",
        "    time = sum(dic_doc_time_sentences[doc])\n",
        "    syll = sum([df_lex[df_lex['ortho']==w]['nbsyll'] for w in dic_docs[doc] if w in list_words])\n",
        "    syll = syll + sum([m for w in dic_docs[doc] if w not in list_words])\n",
        "    ratio = syll / time \n",
        "    dic_syll_per_sec[doc] = ratio\n",
        "    i = i + 1\n",
        "  return(dic_syll_per_sec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ClY2y3WmMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5037e7d1-2938-49ab-daf7-853277dbcb4d"
      },
      "source": [
        "dic_syll_per_sec = nb_syll_sec (dic_doc_time_sentences, dic_docs_sent, df_lex)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 300\n",
            "2 / 300\n",
            "3 / 300\n",
            "4 / 300\n",
            "5 / 300\n",
            "6 / 300\n",
            "7 / 300\n",
            "8 / 300\n",
            "9 / 300\n",
            "10 / 300\n",
            "11 / 300\n",
            "12 / 300\n",
            "13 / 300\n",
            "14 / 300\n",
            "15 / 300\n",
            "16 / 300\n",
            "17 / 300\n",
            "18 / 300\n",
            "19 / 300\n",
            "20 / 300\n",
            "21 / 300\n",
            "22 / 300\n",
            "23 / 300\n",
            "24 / 300\n",
            "25 / 300\n",
            "26 / 300\n",
            "27 / 300\n",
            "28 / 300\n",
            "29 / 300\n",
            "30 / 300\n",
            "31 / 300\n",
            "32 / 300\n",
            "33 / 300\n",
            "34 / 300\n",
            "35 / 300\n",
            "36 / 300\n",
            "37 / 300\n",
            "38 / 300\n",
            "39 / 300\n",
            "40 / 300\n",
            "41 / 300\n",
            "42 / 300\n",
            "43 / 300\n",
            "44 / 300\n",
            "45 / 300\n",
            "46 / 300\n",
            "47 / 300\n",
            "48 / 300\n",
            "49 / 300\n",
            "50 / 300\n",
            "51 / 300\n",
            "52 / 300\n",
            "53 / 300\n",
            "54 / 300\n",
            "55 / 300\n",
            "56 / 300\n",
            "57 / 300\n",
            "58 / 300\n",
            "59 / 300\n",
            "60 / 300\n",
            "61 / 300\n",
            "62 / 300\n",
            "63 / 300\n",
            "64 / 300\n",
            "65 / 300\n",
            "66 / 300\n",
            "67 / 300\n",
            "68 / 300\n",
            "69 / 300\n",
            "70 / 300\n",
            "71 / 300\n",
            "72 / 300\n",
            "73 / 300\n",
            "74 / 300\n",
            "75 / 300\n",
            "76 / 300\n",
            "77 / 300\n",
            "78 / 300\n",
            "79 / 300\n",
            "80 / 300\n",
            "81 / 300\n",
            "82 / 300\n",
            "83 / 300\n",
            "84 / 300\n",
            "85 / 300\n",
            "86 / 300\n",
            "87 / 300\n",
            "88 / 300\n",
            "89 / 300\n",
            "90 / 300\n",
            "91 / 300\n",
            "92 / 300\n",
            "93 / 300\n",
            "94 / 300\n",
            "95 / 300\n",
            "96 / 300\n",
            "97 / 300\n",
            "98 / 300\n",
            "99 / 300\n",
            "100 / 300\n",
            "101 / 300\n",
            "102 / 300\n",
            "103 / 300\n",
            "104 / 300\n",
            "105 / 300\n",
            "106 / 300\n",
            "107 / 300\n",
            "108 / 300\n",
            "109 / 300\n",
            "110 / 300\n",
            "111 / 300\n",
            "112 / 300\n",
            "113 / 300\n",
            "114 / 300\n",
            "115 / 300\n",
            "116 / 300\n",
            "117 / 300\n",
            "118 / 300\n",
            "119 / 300\n",
            "120 / 300\n",
            "121 / 300\n",
            "122 / 300\n",
            "123 / 300\n",
            "124 / 300\n",
            "125 / 300\n",
            "126 / 300\n",
            "127 / 300\n",
            "128 / 300\n",
            "129 / 300\n",
            "130 / 300\n",
            "131 / 300\n",
            "132 / 300\n",
            "133 / 300\n",
            "134 / 300\n",
            "135 / 300\n",
            "136 / 300\n",
            "137 / 300\n",
            "138 / 300\n",
            "139 / 300\n",
            "140 / 300\n",
            "141 / 300\n",
            "142 / 300\n",
            "143 / 300\n",
            "144 / 300\n",
            "145 / 300\n",
            "146 / 300\n",
            "147 / 300\n",
            "148 / 300\n",
            "149 / 300\n",
            "150 / 300\n",
            "151 / 300\n",
            "152 / 300\n",
            "153 / 300\n",
            "154 / 300\n",
            "155 / 300\n",
            "156 / 300\n",
            "157 / 300\n",
            "158 / 300\n",
            "159 / 300\n",
            "160 / 300\n",
            "161 / 300\n",
            "162 / 300\n",
            "163 / 300\n",
            "164 / 300\n",
            "165 / 300\n",
            "166 / 300\n",
            "167 / 300\n",
            "168 / 300\n",
            "169 / 300\n",
            "170 / 300\n",
            "171 / 300\n",
            "172 / 300\n",
            "173 / 300\n",
            "174 / 300\n",
            "175 / 300\n",
            "176 / 300\n",
            "177 / 300\n",
            "178 / 300\n",
            "179 / 300\n",
            "180 / 300\n",
            "181 / 300\n",
            "182 / 300\n",
            "183 / 300\n",
            "184 / 300\n",
            "185 / 300\n",
            "186 / 300\n",
            "187 / 300\n",
            "188 / 300\n",
            "189 / 300\n",
            "190 / 300\n",
            "191 / 300\n",
            "192 / 300\n",
            "193 / 300\n",
            "194 / 300\n",
            "195 / 300\n",
            "196 / 300\n",
            "197 / 300\n",
            "198 / 300\n",
            "199 / 300\n",
            "200 / 300\n",
            "201 / 300\n",
            "202 / 300\n",
            "203 / 300\n",
            "204 / 300\n",
            "205 / 300\n",
            "206 / 300\n",
            "207 / 300\n",
            "208 / 300\n",
            "209 / 300\n",
            "210 / 300\n",
            "211 / 300\n",
            "212 / 300\n",
            "213 / 300\n",
            "214 / 300\n",
            "215 / 300\n",
            "216 / 300\n",
            "217 / 300\n",
            "218 / 300\n",
            "219 / 300\n",
            "220 / 300\n",
            "221 / 300\n",
            "222 / 300\n",
            "223 / 300\n",
            "224 / 300\n",
            "225 / 300\n",
            "226 / 300\n",
            "227 / 300\n",
            "228 / 300\n",
            "229 / 300\n",
            "230 / 300\n",
            "231 / 300\n",
            "232 / 300\n",
            "233 / 300\n",
            "234 / 300\n",
            "235 / 300\n",
            "236 / 300\n",
            "237 / 300\n",
            "238 / 300\n",
            "239 / 300\n",
            "240 / 300\n",
            "241 / 300\n",
            "242 / 300\n",
            "243 / 300\n",
            "244 / 300\n",
            "245 / 300\n",
            "246 / 300\n",
            "247 / 300\n",
            "248 / 300\n",
            "249 / 300\n",
            "250 / 300\n",
            "251 / 300\n",
            "252 / 300\n",
            "253 / 300\n",
            "254 / 300\n",
            "255 / 300\n",
            "256 / 300\n",
            "257 / 300\n",
            "258 / 300\n",
            "259 / 300\n",
            "260 / 300\n",
            "261 / 300\n",
            "262 / 300\n",
            "263 / 300\n",
            "264 / 300\n",
            "265 / 300\n",
            "266 / 300\n",
            "267 / 300\n",
            "268 / 300\n",
            "269 / 300\n",
            "270 / 300\n",
            "271 / 300\n",
            "272 / 300\n",
            "273 / 300\n",
            "274 / 300\n",
            "275 / 300\n",
            "276 / 300\n",
            "277 / 300\n",
            "278 / 300\n",
            "279 / 300\n",
            "280 / 300\n",
            "281 / 300\n",
            "282 / 300\n",
            "283 / 300\n",
            "284 / 300\n",
            "285 / 300\n",
            "286 / 300\n",
            "287 / 300\n",
            "288 / 300\n",
            "289 / 300\n",
            "290 / 300\n",
            "291 / 300\n",
            "292 / 300\n",
            "293 / 300\n",
            "294 / 300\n",
            "295 / 300\n",
            "296 / 300\n",
            "297 / 300\n",
            "298 / 300\n",
            "299 / 300\n",
            "300 / 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJFJvf0qXzO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ma_sy = max(dic_syll_per_sec.values())\n",
        "mi_sy = min(dic_syll_per_sec.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZp3tum2qfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_syll_per_sec_N = normalize_results(dic_syll_per_sec, ma_sy, mi_sy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QKJsTzd2xdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "484cff74-a386-471c-a394-311765122fb3"
      },
      "source": [
        "compar_anno(dic_syll_per_sec_N, \"001\", only_commented)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(RMSE) : 34.4227390793821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-Foc-BqJk3",
        "colab_type": "text"
      },
      "source": [
        "## 4 - Features agregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bNPYhIJ3Nno",
        "colab": {}
      },
      "source": [
        "def create_DF_agreg(dic_nb_sentence_N,\n",
        "                    dic_len_sentence_N,\n",
        "                    dic_cplx_N,\n",
        "                    dic_syll_per_sec_N,\n",
        "                    dic_repetition):\n",
        "  col = ['doc', 'nb_sentence', 'len_sentence', 'cplx_words', 'syll_sec','different_words']\n",
        "  list_DF = []\n",
        "  for doc in dic_nb_sentence_N.keys():\n",
        "    list_DF_doc = [doc,\n",
        "                   dic_nb_sentence_N[doc],\n",
        "                   dic_len_sentence_N[doc],\n",
        "                   dic_cplx_N[doc],\n",
        "                   dic_syll_per_sec_N[doc],\n",
        "                   dic_repetition[doc]]\n",
        "    list_DF.append(list_DF_doc)\n",
        "  DF = pd.DataFrame(list_DF, columns=col)\n",
        "  return(DF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k9-NVtsuXLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF_aggreg = create_DF_agreg(dic_nb_sentence_N,\n",
        "                    dic_len_sentence_N,\n",
        "                    dic_cplx_N,\n",
        "                    dic_syll_per_sec_N,\n",
        "                    dic_repetition_N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qka8vfAubTV",
        "colab_type": "code",
        "outputId": "d03246d0-6666-441c-e60b-4d20050a2fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "DF_aggreg[DF_aggreg['doc'] == '221_7.xml']"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>nb_sentence</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>cplx_words</th>\n",
              "      <th>syll_sec</th>\n",
              "      <th>different_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>221_7.xml</td>\n",
              "      <td>36.94281</td>\n",
              "      <td>29.096045</td>\n",
              "      <td>49.361208</td>\n",
              "      <td>47.567247</td>\n",
              "      <td>12.081019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           doc  nb_sentence  ...   syll_sec  different_words\n",
              "134  221_7.xml     36.94281  ...  47.567247        12.081019\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhH4YGHyyL9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17a2d2f7-5b4a-40ec-d322-7c5b5bb82ab0"
      },
      "source": [
        ""
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}