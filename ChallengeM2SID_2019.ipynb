{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChallengeM2SID_2019.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "TJB_Qi1KFPAy",
        "colab_type": "code",
        "outputId": "c4987433-249e-4ebd-e2bf-996fd131b59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# OS setup\n",
        "!rm -rf challenge-m2-sid/\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Liaison avec les donnÃ©es\n",
        "#!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Rq-iFYpFPA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import GaussianNoise,BatchNormalization, Conv1D\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re  \n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import spacy\n",
        "from google.colab import files\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn import preprocessing\n",
        "import sklearn.preprocessing\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "o9kIqLh4FPA4",
        "colab_type": "text"
      },
      "source": [
        "# Label preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CZRnow5RFPA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Return a part of the dataset with only 1 medium (text, audio, text + audio...)\n",
        "def get_medium(medium, df):\n",
        "  \"\"\"\n",
        "  # Return a subset of informations limited to a communication medium \n",
        "  # (audio : 100 , text : 001, audio and video : 110, audio and text : 101 \n",
        "  # audio, video and text : 111)\n",
        "  Parameters:\n",
        "      :param medium: ID for a medium \n",
        "      :param df: dataset containing \"code_doc\" columns containing \n",
        "      xx_x_medium_x as an document ID\n",
        "      \n",
        "      :type medium: string\n",
        "      :type df: DataFrame (pandas)\n",
        "  \n",
        "  Returns:\n",
        "      medium: the part of the dataset with only the choosen medium\n",
        "      type : DataFrame (pandas)\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> print(get_medium(\"100\",csv_file))\n",
        " Unnamed: 0      code_doc  il08_09  ...  la09_10  cg13_14  mb00_12\n",
        "5              6    57_6_100_1       -1  ...     -1.0     -1.0       76\n",
        "55            56   147_1_100_1       -1  ...     -1.0     -1.0       64\n",
        "135          136   210_3_100_1       70  ...     -1.0     -1.0       -1\n",
        "        ... \n",
        "  \"\"\"\n",
        "  return (df[df[\"code_doc\"].map(lambda x : x[len(x)-5:-2]==medium)])  \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# Return the list of label for each document\n",
        "def ret_max_docid(medium, only_commented):\n",
        "  '''\n",
        "  Choose the medium on which return the list of label for each document\n",
        "  Medium is a string : sequence of 3 bits : audio-video-texte sequence\n",
        "  only_commented : Dataframe of each annotated extract (not only extracts\n",
        "  ending with a \"1\")\n",
        "  Mean of multiple label is used when there are differents labels for one\n",
        "  document.\n",
        "  Parameters:\n",
        "      :param medium: ID for a medium \n",
        "      :param df: dataset containing \"code_doc\" columns containing \n",
        "      xx_x_medium_x as an document ID\n",
        "      \n",
        "      :type medium: string\n",
        "      :type df: DataFrame (pandas)\n",
        "  \n",
        "  Returns:\n",
        "      list_labels : couple list of each (document id, label) \n",
        "      type : list (of couple)\n",
        "  :Example:\n",
        "\n",
        "      >>>ret_max_docid(\"101\", only_commented)\n",
        "        [('57_6_101_0', 87.0),\n",
        "         ('88_11_101_1', 34.0),\n",
        "         ('51_5_101_1', 65.0),\n",
        "          ...\n",
        "  '''\n",
        "  # Get the list of annotated extracts for a medium\n",
        "  medium = get_medium(medium, only_commented)\n",
        "  # Replace all -1 by a NaN value  \n",
        "  medium = medium.replace(-1.,np.NaN)\n",
        "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
        "  return [(row[1],row[2:].mean()) for index,row in medium.iterrows() ]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1d_VM_GoFPA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "\n",
        "\n",
        "dataset = get_dataset(updated_csv)\n",
        "dataset = dataset.replace(50,np.NaN)\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JXYcjqiPFPA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Annotation file reading\n",
        "\n",
        "def get_dataset(csv_file):\n",
        "  \"\"\"\n",
        "  Get only the commented row in the annoted csv file. The last digit is \n",
        "  here to know if a row is empty or not but some labels are forgotten. This \n",
        "  function return only row that contains something different from -1.\n",
        "  Parameters:\n",
        "      :param csv_file: DataFrame with all label for each document \n",
        "      :type csv_file : DataFrame (pandas)\n",
        "      \n",
        "  Returns:\n",
        "      dataset: The sub part of the annotation file with only commented \n",
        "      documents\n",
        "      type : DataFrame Pandas\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> get_dataset(updated_csv)\n",
        "        \\t\tcode_doc\til08_09\tvg04_05\tfd03_04\tla09_10\tcg13_14\tja05_06\tfj11_12\tec20_11\tmb00_12\n",
        "      5\t6\t57_6_100_1\t-1\t-1\t-1\t-1.0\t-1.0\t-1.0\t100.0\t-1.0\t76\n",
        "      6\t7\t57_6_110_1\t100\t100\t-1\t-1.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
        "      7\t8\t57_6_111_1\t-1\t-1\t-1\t88.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
        "\n",
        "  \"\"\"\n",
        "  # 2 first columns are index and code_id\n",
        "  names = csv_file.columns[2:]\n",
        "  dataset=[]\n",
        "  for index,row in csv_file.iterrows():\n",
        "    if any(row[names]!=-1):\n",
        "      dataset.append(row)\n",
        "  return pd.DataFrame(dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y8kWpXyDFPBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a standard normalisation for the labels.\n",
        "def normalisation_annot(df):\n",
        "  \"\"\"\n",
        "  Compute a standard normalisation with mean and Standard deviation on label\n",
        "  to remove bias and make label comparables. Return the normalised distribution\n",
        "  with mean = 0 and std = 1, the max and the min of the distribution for each\n",
        "  annotator to make it available to get back the value of the label.\n",
        "  Parameters:\n",
        "      :param df: Label dataframe on wich perform the normalisation\n",
        "      :type df: DataFrame (pandas)\n",
        "      \n",
        "  Returns:\n",
        "      norm_df,max_list,min_list: tuple containing the normalised DataFrame, the\n",
        "      list of max for each annotator and the list of min for each annotator\n",
        "      type : (DataFrame (pandas), list,list)\n",
        "      \n",
        "  Other itema to note:\n",
        "      - Don't forget to remove -1 in the dataset, unless the normalisation\n",
        "      will be biased  \n",
        "\n",
        "  \"\"\"\n",
        "  name = df.columns[2:]\n",
        "  # Work on a copy of the DF\n",
        "  ret_df = df[df[name]!=-1]\n",
        "  max_list = []\n",
        "  min_list = []\n",
        "  for i, annot in enumerate(ret_df[name]):\n",
        "      ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
        "      max_list.append(ret_df[annot].max())\n",
        "      min_list.append(ret_df[annot].min())\n",
        "  for index in df.index :\n",
        "    ret_df[\"code_doc\"][index] = df[\"code_doc\"][index]\n",
        "  return  ret_df, np.array(max_list), np.array(min_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JDwPeo0xFPBG",
        "colab_type": "code",
        "outputId": "f8988ec8-42c3-409e-83fe-e873f602e65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "norm_dataset,data_max_list,data_min_list"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      \\t     code_doc   il08_09  ...   fj11_12   ec20_11   mb00_12\n",
              " 5    NaN   57_6_100_1       NaN  ...  1.359498       NaN  1.511797\n",
              " 6    NaN   57_6_110_1  2.355661  ...       NaN       NaN       NaN\n",
              " 7    NaN   57_6_111_1       NaN  ...       NaN       NaN       NaN\n",
              " 8    NaN   57_6_101_1       NaN  ...       NaN       NaN       NaN\n",
              " 9    NaN   57_6_001_1       NaN  ...       NaN  1.607416       NaN\n",
              " ...   ..          ...       ...  ...       ...       ...       ...\n",
              " 1430 NaN  256_1_100_1       NaN  ...       NaN  0.664170       NaN\n",
              " 1431 NaN  256_1_110_1       NaN  ... -0.192199       NaN  0.694386\n",
              " 1432 NaN  256_1_111_1       NaN  ...       NaN       NaN       NaN\n",
              " 1433 NaN  256_1_101_1       NaN  ...       NaN       NaN       NaN\n",
              " 1434 NaN  256_1_001_1 -0.308542  ...       NaN       NaN       NaN\n",
              " \n",
              " [241 rows x 11 columns],\n",
              " array([2.35566073, 1.00357724, 2.51622781, 1.59344352, 2.3850719 ,\n",
              "        1.85812355, 1.35949831, 1.60741643, 1.82967853]),\n",
              " array([-2.45148778, -2.59301938, -2.01415897, -3.2541503 , -1.68491953,\n",
              "        -1.45184789, -1.80855007, -2.33706812, -1.75784549]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Uk8YKxlIFPBI",
        "colab_type": "code",
        "outputId": "495b1d25-5b19-4f89-8509-f77c83edd055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "norm_dataset.describe()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\\t</th>\n",
              "      <th>il08_09</th>\n",
              "      <th>vg04_05</th>\n",
              "      <th>fd03_04</th>\n",
              "      <th>la09_10</th>\n",
              "      <th>cg13_14</th>\n",
              "      <th>ja05_06</th>\n",
              "      <th>fj11_12</th>\n",
              "      <th>ec20_11</th>\n",
              "      <th>mb00_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>5.300000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.018587e-17</td>\n",
              "      <td>-7.872491e-17</td>\n",
              "      <td>9.891078e-17</td>\n",
              "      <td>1.402918e-16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.021196e-17</td>\n",
              "      <td>1.564405e-17</td>\n",
              "      <td>2.018587e-18</td>\n",
              "      <td>-6.257621e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.451488e+00</td>\n",
              "      <td>-2.593019e+00</td>\n",
              "      <td>-2.014159e+00</td>\n",
              "      <td>-3.254150e+00</td>\n",
              "      <td>-1.684920</td>\n",
              "      <td>-1.451848e+00</td>\n",
              "      <td>-1.808550e+00</td>\n",
              "      <td>-2.337068e+00</td>\n",
              "      <td>-1.757845e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.402119e-01</td>\n",
              "      <td>-2.442216e-01</td>\n",
              "      <td>-8.006625e-01</td>\n",
              "      <td>-4.476486e-01</td>\n",
              "      <td>-0.771780</td>\n",
              "      <td>-9.535726e-01</td>\n",
              "      <td>-9.518839e-01</td>\n",
              "      <td>-5.363252e-01</td>\n",
              "      <td>-8.269057e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.895480e-02</td>\n",
              "      <td>2.695779e-01</td>\n",
              "      <td>8.923489e-02</td>\n",
              "      <td>1.264085e-01</td>\n",
              "      <td>-0.171718</td>\n",
              "      <td>7.856901e-02</td>\n",
              "      <td>1.633984e-01</td>\n",
              "      <td>2.354218e-01</td>\n",
              "      <td>-3.220102e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>6.470959e-01</td>\n",
              "      <td>7.099775e-01</td>\n",
              "      <td>7.094664e-01</td>\n",
              "      <td>7.961419e-01</td>\n",
              "      <td>0.715332</td>\n",
              "      <td>8.259819e-01</td>\n",
              "      <td>1.003901e+00</td>\n",
              "      <td>7.284824e-01</td>\n",
              "      <td>8.079154e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.355661e+00</td>\n",
              "      <td>1.003577e+00</td>\n",
              "      <td>2.516228e+00</td>\n",
              "      <td>1.593444e+00</td>\n",
              "      <td>2.385072</td>\n",
              "      <td>1.858124e+00</td>\n",
              "      <td>1.359498e+00</td>\n",
              "      <td>1.607416e+00</td>\n",
              "      <td>1.829679e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        \\t       il08_09  ...       ec20_11       mb00_12\n",
              "count  0.0  5.500000e+01  ...  5.500000e+01  5.500000e+01\n",
              "mean   NaN -2.018587e-17  ...  2.018587e-18 -6.257621e-17\n",
              "std    NaN  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
              "min    NaN -2.451488e+00  ... -2.337068e+00 -1.757845e+00\n",
              "25%    NaN -5.402119e-01  ... -5.363252e-01 -8.269057e-01\n",
              "50%    NaN -1.895480e-02  ...  2.354218e-01 -3.220102e-02\n",
              "75%    NaN  6.470959e-01  ...  7.284824e-01  8.079154e-01\n",
              "max    NaN  2.355661e+00  ...  1.607416e+00  1.829679e+00\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qXtM3urlFPBK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c8QhiewFFPBL",
        "colab_type": "code",
        "outputId": "722f7d87-9650-4425-8920-89e0f37a37af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "for annot in norm_dataset[norm_dataset.columns[2:]]:\n",
        "  norm_dataset[annot].hist()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        \\t       il08_09  ...       ec20_11       mb00_12\n",
            "count  0.0  4.700000e+01  ...  5.200000e+01  5.500000e+01\n",
            "mean   NaN -8.621945e-17  ... -1.174274e-16 -6.257621e-17\n",
            "std    NaN  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
            "min    NaN -2.409223e+00  ... -2.320991e+00 -1.757845e+00\n",
            "25%    NaN -4.342205e-01  ... -4.824622e-01 -8.269057e-01\n",
            "50%    NaN  1.143914e-01  ...  2.844668e-01 -3.220102e-02\n",
            "75%    NaN  5.807116e-01  ...  7.047019e-01  8.079154e-01\n",
            "max    NaN  2.144256e+00  ...  1.545172e+00  1.829679e+00\n",
            "\n",
            "[8 rows x 10 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjzZfdHFFuXn",
        "colab_type": "text"
      },
      "source": [
        "# Text features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EtW3d69yFPBN",
        "colab_type": "code",
        "outputId": "aec88710-c384-4df6-a15f-19c705c0c8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "\n",
        "dataset = get_dataset(get_medium(\"001\",updated_csv))\n",
        "norm_dataset,data_max, data_min = normalisation_annot(dataset)\n",
        "for annot in norm_dataset[norm_dataset.columns[2:]]:\n",
        "  norm_dataset[annot].hist()\n",
        "print(norm_dataset.describe())"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        \\t       il08_09  ...       ec20_11       mb00_12\n",
            "count  0.0  1.100000e+01  ...  1.100000e+01  1.100000e+01\n",
            "mean   NaN -7.569702e-17  ...  8.074349e-17 -7.222758e-17\n",
            "std    NaN  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
            "min    NaN -1.847096e+00  ... -1.804910e+00 -1.302613e+00\n",
            "25%    NaN -3.051008e-01  ... -4.948405e-01 -1.089388e+00\n",
            "50%    NaN  3.298387e-01  ...  4.092918e-01  1.046743e-01\n",
            "75%    NaN  6.624260e-01  ...  6.676154e-01  8.509631e-01\n",
            "max    NaN  9.950133e-01  ...  1.368779e+00  1.170801e+00\n",
            "\n",
            "[8 rows x 10 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQCoUIXEQnE/wPnr97qTbU03AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHRyl7ydFzFc",
        "colab_type": "text"
      },
      "source": [
        "# Audio features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N_Z1AZOF1FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyHYm4KiF2KD",
        "colab_type": "text"
      },
      "source": [
        "# Video features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc43AdbFF3T6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnx9UQULF3fH",
        "colab_type": "text"
      },
      "source": [
        "# Agregation models\n",
        "The models works on csv file from features extractions (some features take lot of time to be computed. To make it possible, we'll work directly with csv results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk02dN5ruBGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "88b51096-e323-4fc8-85b6-1e297d61c4aa"
      },
      "source": [
        "def create_features_dataframe(text_path ,audio_path, video_path ):\n",
        "  text_feat = pd.read_csv(text_path)\n",
        "  # Audio csv is build with special separator and encoding\n",
        "  audio_feat = pd.read_csv(audio_path, sep='Â§', engine='python', index_col=0, encoding='utf-8') \n",
        "  audio_feat[\"SCORE\"] = (1-audio_feat[\"SCORE\"])*100\n",
        "  video_feat= pd.read_csv(\"feat_break.csv\")\n",
        "  audio_video = pd.merge(audio_feat,video_feat,left_on=\"SCENE\",right_on=\"Unnamed: 0\")\n",
        "  audio_video = audio_video.drop([\"Unnamed: 0\"], axis=1)\n",
        "  audio_video = audio_video.rename(columns={\"SCENE\":\"code_doc\", \"SCORE\": \"Recognition score\"})\n",
        "  audio_video = audio_video.drop([\"RECON\",\"XML\"],axis=1)\n",
        "  audio_video_text = pd.merge(audio_video,text_feat,left_on=\"code_doc\",right_on=\"doc\")\n",
        "  audio_video_text = audio_video_text.drop([\"Unnamed: 0\",\"doc\"],axis=1)\n",
        "  return audio_video_text\n",
        "\n",
        "\n",
        "features = create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\")\n",
        "features"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code_doc</th>\n",
              "      <th>SR</th>\n",
              "      <th>SNR</th>\n",
              "      <th>VBR</th>\n",
              "      <th>CONF</th>\n",
              "      <th>Recognition score</th>\n",
              "      <th>env_br_per_min</th>\n",
              "      <th>scene_br_per_min</th>\n",
              "      <th>nb_sentence</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>cplx_words</th>\n",
              "      <th>syll_100</th>\n",
              "      <th>different_words</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100_1</td>\n",
              "      <td>0.506749</td>\n",
              "      <td>0.975847</td>\n",
              "      <td>0.937432</td>\n",
              "      <td>0.891960</td>\n",
              "      <td>46.659483</td>\n",
              "      <td>11.789474</td>\n",
              "      <td>15.157895</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>10.350000</td>\n",
              "      <td>0.634921</td>\n",
              "      <td>138.665032</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107_7</td>\n",
              "      <td>0.875052</td>\n",
              "      <td>0.992874</td>\n",
              "      <td>0.996106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.618720</td>\n",
              "      <td>1.441441</td>\n",
              "      <td>2.882883</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>14.681818</td>\n",
              "      <td>0.664474</td>\n",
              "      <td>137.962893</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>108_3</td>\n",
              "      <td>0.610753</td>\n",
              "      <td>0.950284</td>\n",
              "      <td>0.992284</td>\n",
              "      <td>0.892878</td>\n",
              "      <td>46.724891</td>\n",
              "      <td>15.678392</td>\n",
              "      <td>12.060302</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>7.333333</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>145.640040</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>128_5</td>\n",
              "      <td>0.636332</td>\n",
              "      <td>0.998066</td>\n",
              "      <td>0.989983</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52.879581</td>\n",
              "      <td>2.926829</td>\n",
              "      <td>1.951220</td>\n",
              "      <td>29.142857</td>\n",
              "      <td>9.117647</td>\n",
              "      <td>0.669643</td>\n",
              "      <td>129.190227</td>\n",
              "      <td>0.722581</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13_2</td>\n",
              "      <td>0.784851</td>\n",
              "      <td>0.995663</td>\n",
              "      <td>0.932309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.962963</td>\n",
              "      <td>3.720930</td>\n",
              "      <td>3.720930</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>0.723684</td>\n",
              "      <td>145.396761</td>\n",
              "      <td>0.767677</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>96_6</td>\n",
              "      <td>0.761384</td>\n",
              "      <td>0.900388</td>\n",
              "      <td>0.724127</td>\n",
              "      <td>0.909442</td>\n",
              "      <td>10.033445</td>\n",
              "      <td>8.470588</td>\n",
              "      <td>4.235294</td>\n",
              "      <td>24.827586</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>177.835900</td>\n",
              "      <td>0.746032</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>97_6</td>\n",
              "      <td>0.745310</td>\n",
              "      <td>0.962507</td>\n",
              "      <td>0.881788</td>\n",
              "      <td>0.896575</td>\n",
              "      <td>65.192582</td>\n",
              "      <td>2.440678</td>\n",
              "      <td>2.440678</td>\n",
              "      <td>34.285714</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>0.663265</td>\n",
              "      <td>152.829136</td>\n",
              "      <td>0.705036</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>98_13</td>\n",
              "      <td>0.661133</td>\n",
              "      <td>0.971335</td>\n",
              "      <td>0.997959</td>\n",
              "      <td>0.908270</td>\n",
              "      <td>37.795276</td>\n",
              "      <td>27.692308</td>\n",
              "      <td>27.692308</td>\n",
              "      <td>26.400000</td>\n",
              "      <td>8.818182</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>154.891601</td>\n",
              "      <td>0.762887</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>99_11</td>\n",
              "      <td>0.689642</td>\n",
              "      <td>0.995921</td>\n",
              "      <td>0.999603</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.858300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.330097</td>\n",
              "      <td>20.869565</td>\n",
              "      <td>12.750000</td>\n",
              "      <td>0.619718</td>\n",
              "      <td>133.037197</td>\n",
              "      <td>0.696078</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>9_1</td>\n",
              "      <td>0.554712</td>\n",
              "      <td>0.987751</td>\n",
              "      <td>0.953031</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.634002</td>\n",
              "      <td>12.590164</td>\n",
              "      <td>11.016393</td>\n",
              "      <td>52.500000</td>\n",
              "      <td>8.857143</td>\n",
              "      <td>0.594059</td>\n",
              "      <td>129.376739</td>\n",
              "      <td>0.543011</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows Ã 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    code_doc        SR       SNR  ...    syll_100  different_words  topic\n",
              "0      100_1  0.506749  0.975847  ...  138.665032         0.608696   0.75\n",
              "1      107_7  0.875052  0.992874  ...  137.962893         0.470588   1.00\n",
              "2      108_3  0.610753  0.950284  ...  145.640040         0.696970   0.75\n",
              "3      128_5  0.636332  0.998066  ...  129.190227         0.722581   0.75\n",
              "4       13_2  0.784851  0.995663  ...  145.396761         0.767677   0.50\n",
              "..       ...       ...       ...  ...         ...              ...    ...\n",
              "295     96_6  0.761384  0.900388  ...  177.835900         0.746032   0.75\n",
              "296     97_6  0.745310  0.962507  ...  152.829136         0.705036   1.00\n",
              "297    98_13  0.661133  0.971335  ...  154.891601         0.762887   0.75\n",
              "298    99_11  0.689642  0.995921  ...  133.037197         0.696078   1.00\n",
              "299      9_1  0.554712  0.987751  ...  129.376739         0.543011   0.75\n",
              "\n",
              "[300 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7KuxC3ShGp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjbdjqKLu6Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_dataset(labels,features):\n",
        "\n",
        "  model_data = pd.DataFrame(labels[labels.columns[2:]].mean(axis=1))\n",
        "  model_dataset = features\n",
        "\n",
        "\n",
        "  return model_dataset\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "features = create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\")\n",
        "\n",
        "\n",
        "\n",
        "#print(create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "#print(model_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT_9tLvfC2xO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "906c448e-0645-4033-bc46-dd0c33892512"
      },
      "source": [
        "\n",
        "dataset = get_dataset(updated_csv)\n",
        "dataset[\"code_doc\"] = dataset[\"code_doc\"].map(lambda x :x[:-6] )\n",
        "dataset"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\\t</th>\n",
              "      <th>code_doc</th>\n",
              "      <th>il08_09</th>\n",
              "      <th>vg04_05</th>\n",
              "      <th>fd03_04</th>\n",
              "      <th>la09_10</th>\n",
              "      <th>cg13_14</th>\n",
              "      <th>ja05_06</th>\n",
              "      <th>fj11_12</th>\n",
              "      <th>ec20_11</th>\n",
              "      <th>mb00_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>57_6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>57_6</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>57_6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>88.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>57_6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>57_6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>77</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>1431</td>\n",
              "      <td>256_1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431</th>\n",
              "      <td>1432</td>\n",
              "      <td>256_1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1432</th>\n",
              "      <td>1433</td>\n",
              "      <td>256_1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>1434</td>\n",
              "      <td>256_1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>50</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>1435</td>\n",
              "      <td>256_1</td>\n",
              "      <td>54</td>\n",
              "      <td>80</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>241 rows Ã 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        \\t code_doc  il08_09  vg04_05  ...  ja05_06  fj11_12  ec20_11  mb00_12\n",
              "5        6     57_6       -1       -1  ...     -1.0    100.0     -1.0       76\n",
              "6        7     57_6      100      100  ...     -1.0     -1.0     -1.0       -1\n",
              "7        8     57_6       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
              "8        9     57_6       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
              "9       10     57_6       -1       -1  ...    100.0     -1.0    100.0       -1\n",
              "...    ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
              "1430  1431    256_1       -1       -1  ...     -1.0     -1.0     78.0       -1\n",
              "1431  1432    256_1       -1       -1  ...     -1.0     52.0     -1.0       58\n",
              "1432  1433    256_1       -1       -1  ...     50.0     -1.0     -1.0       -1\n",
              "1433  1434    256_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
              "1434  1435    256_1       54       80  ...     -1.0     -1.0     -1.0       -1\n",
              "\n",
              "[241 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Om3WgOzF5nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def un_norm(in_values, maxi,mini):\n",
        "  values = np.array([])\n",
        "  for i,value in enumerate(in_values):\n",
        "    values = np.append(values,100*(value - mini)/(maxi - mini))\n",
        "  return values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2DtVamKPbFV",
        "colab_type": "text"
      },
      "source": [
        "### Kfold validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npjje2ZfPeUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def kfold_valid(model,model_dataset, data_max, data_min, verbose=0 ):\n",
        "\n",
        "\n",
        "  df_x = model_dataset[model_dataset.columns[1:len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_x)\n",
        "  df_y = model_dataset[model_dataset.columns[len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_y)\n",
        "  nb_split=10\n",
        "  print(df_x.shape)\n",
        "  kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
        "  aux = 0\n",
        "  for train_index, test_index in kf.split(df_y):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    \n",
        "    model.fit(df_x[train_index], df_y[train_index])\n",
        "\n",
        "    score = model.score(df_x[test_index], df_y[test_index])\n",
        "    aux += score\n",
        "    \n",
        "    print(\"Final score : \" +str(score) )\n",
        "    predict = model.predict(df_x[test_index])\n",
        "    if verbose==1:\n",
        "      print(\"Pred = \" + str(un_norm(predict,data_max,data_min)) )\n",
        "      print(\"Ground truth = \" + str(un_norm(df_y[test_index],data_max,data_min)))\n",
        "  print(\"Score moyen : \" + str(float(aux/nb_split)))\n",
        "  return float(aux/nb_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z16ekrqAKmVW",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning models with KFolds (10 folds) \n",
        "* Lasso regression (scikit-learn)\n",
        "* SGD Regressor (scikit-learn)\n",
        "* Gradient Boosting regressor (scikit-learn)\n",
        "* MLP regressor (scikit-learn)\n",
        "* Decision trees (scikit-learn)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoDLvcAJPHFi",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Regression (scikit-learn) : only text medium\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10zaiOOlJwqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10370897-1cf3-4ac3-cbcc-13f13fdf4d2d"
      },
      "source": [
        "from sklearn import linear_model\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
        "text_label = get_medium(\"001\",updated_csv)\n",
        "\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "#print(norm_dataset[norm_dataset.columns[2:]].mean(axis=1))\n",
        "#print(create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model = linear_model.Lasso(alpha=0.1)\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        \\t      code_doc  il08_09  vg04_05  ...  ja05_06  fj11_12  ec20_11  mb00_12\n",
            "9       10    57_6_001_1       -1       -1  ...    100.0     -1.0    100.0       -1\n",
            "39      40   88_11_001_1       63       88  ...     -1.0     -1.0     -1.0       -1\n",
            "49      50    51_5_001_1       -1       -1  ...     -1.0     96.0     -1.0       55\n",
            "59      60   147_1_001_1       -1       -1  ...     85.0     -1.0     77.0       -1\n",
            "139    140   210_3_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "159    160  253_11_001_1       -1       -1  ...     48.0     -1.0     86.0       -1\n",
            "199    200    13_2_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "219    220    72_2_001_1       -1       -1  ...     74.0     -1.0     79.0       -1\n",
            "229    230   173_1_001_1       -1       -1  ...     -1.0      7.0     -1.0        7\n",
            "259    260  272_11_001_1       -1       -1  ...     -1.0     50.0     -1.0       48\n",
            "364    365   239_6_001_1       -1       -1  ...     -1.0     61.0     -1.0       11\n",
            "419    420  231_13_001_1       -1       -1  ...     18.0     -1.0     58.0       -1\n",
            "444    445  211_15_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "464    465   273_6_001_1       58       96  ...     -1.0     -1.0     -1.0       -1\n",
            "474    475    67_3_001_1       50       32  ...     -1.0     -1.0     -1.0       -1\n",
            "479    480  289_14_001_1       59       71  ...     -1.0     -1.0     -1.0       -1\n",
            "529    530    74_4_001_1       20        2  ...     -1.0     -1.0     -1.0       -1\n",
            "544    545   180_4_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "569    570   100_1_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "584    585   148_4_001_1       -1       -1  ...     72.0     -1.0     50.0       -1\n",
            "604    605  116_15_001_1       39       69  ...     -1.0     -1.0     -1.0       -1\n",
            "614    615  267_15_001_1       -1       -1  ...     -1.0     69.0     -1.0       62\n",
            "624    625   221_7_001_1       -1       -1  ...     65.0     -1.0     74.0       -1\n",
            "634    635   45_14_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "639    640   226_6_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "669    670   296_8_001_1       19       29  ...     -1.0     -1.0     -1.0       -1\n",
            "684    685    17_9_001_1       -1       -1  ...     -1.0     13.0     -1.0        4\n",
            "694    695   129_5_001_1       66       66  ...     -1.0     -1.0     -1.0       -1\n",
            "714    715    71_7_001_1       -1       -1  ...     -1.0     95.0     -1.0       54\n",
            "734    735    89_2_001_1       -1       -1  ...     -1.0     72.0     -1.0       61\n",
            "769    770   128_5_001_1       -1       -1  ...    100.0     -1.0     83.0       -1\n",
            "824    825  208_12_001_1       -1       -1  ...    100.0     -1.0     49.0       -1\n",
            "909    910  219_10_001_1       55       70  ...     -1.0     -1.0     -1.0       -1\n",
            "959    960    80_9_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "979    980   12_13_001_1       -1       -1  ...     -1.0     41.0     -1.0       37\n",
            "1024  1025  271_14_001_1       -1       -1  ...     50.0     -1.0     22.0       -1\n",
            "1029  1030    79_8_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "1124  1125   245_3_001_1       -1       -1  ...     -1.0      2.0     -1.0        6\n",
            "1194  1195   44_12_001_1       -1       -1  ...     -1.0     91.0     -1.0       35\n",
            "1204  1205   197_7_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "1319  1320   157_9_001_1       62       28  ...     -1.0     -1.0     -1.0       -1\n",
            "1324  1325   199_9_001_1       -1       -1  ...     18.0     -1.0     14.0       -1\n",
            "1394  1395  165_10_001_1       -1       -1  ...     -1.0     -1.0     -1.0       -1\n",
            "1434  1435   256_1_001_1       54       80  ...     -1.0     -1.0     -1.0       -1\n",
            "\n",
            "[44 rows x 11 columns]\n",
            "(197, 12)\n",
            "Final score : 0.004333902588194882\n",
            "Final score : 0.3478276834106181\n",
            "Final score : -0.08860243310221949\n",
            "Final score : 0.22273086170989453\n",
            "Final score : 0.3182343304310175\n",
            "Final score : 0.4675847182670564\n",
            "Final score : -0.6038081168516467\n",
            "Final score : -0.01983953764793256\n",
            "Final score : 0.20624461446305187\n",
            "Final score : 0.549729576720165\n",
            "Score moyen : 0.14044355999881994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJDIVMExJq3j",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Regression (scikit-learn) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akzr3iATLHZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "86d75738-e16d-46f2-c4cc-616a4feeebf4"
      },
      "source": [
        "from sklearn import linear_model\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "#print(norm_dataset[norm_dataset.columns[2:]].mean(axis=1))\n",
        "#print(create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model = linear_model.Lasso(alpha=0.1)\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(197, 12)\n",
            "Final score : 0.004333902588194882\n",
            "Final score : 0.3478276834106181\n",
            "Final score : -0.08860243310221949\n",
            "Final score : 0.22273086170989453\n",
            "Final score : 0.3182343304310175\n",
            "Final score : 0.4675847182670564\n",
            "Final score : -0.6038081168516467\n",
            "Final score : -0.01983953764793256\n",
            "Final score : 0.20624461446305187\n",
            "Final score : 0.549729576720165\n",
            "Score moyen : 0.14044355999881994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKOpFuBk3NNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "8c985a10-0bea-4f66-c0ce-c39f063e8def"
      },
      "source": [
        "model=  linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=\"elasticnet\")\n",
        "\n",
        "\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model = linear_model.Lasso(alpha=0)\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27, 13)\n",
            "Final score : -0.04240336647526699\n",
            "Pred = [70.032486   89.82172506 41.17763317]\n",
            "Ground truth = [98.14066914 49.65622552 30.92770188]\n",
            "Final score : -43.1063761392617\n",
            "Pred = [63.46604428 91.79452454 59.85196833]\n",
            "Ground truth = [63.70176391 58.10460822 64.89975187]\n",
            "Final score : -0.8842977096919905\n",
            "Pred = [84.45945647 71.94855441 18.61557439]\n",
            "Ground truth = [47.22380909 83.49528664 40.66093141]\n",
            "Final score : 0.5661965487530919\n",
            "Pred = [87.72003393 74.46762545 44.44572665]\n",
            "Ground truth = [103.34627858  67.11200058  58.39855765]\n",
            "Final score : 0.3152162587222773\n",
            "Pred = [58.63560639 62.24118881 30.83758567]\n",
            "Ground truth = [41.79914458 78.70829686 40.4083529 ]\n",
            "Final score : -1.6390739874660953\n",
            "Pred = [64.93735592 40.02839387 70.20357578]\n",
            "Ground truth = [41.31638573 79.16090934 70.89884755]\n",
            "Final score : -816.9639515529188\n",
            "Pred = [100.91881899  53.39614014  97.07673029]\n",
            "Ground truth = [85.99864905 84.63385268 86.32260322]\n",
            "Final score : -83.76338024913925\n",
            "Pred = [39.06259316 39.66808979]\n",
            "Ground truth = [67.05789223 73.84399889]\n",
            "Final score : -0.5987129548734904\n",
            "Pred = [69.57236111 69.2596639 ]\n",
            "Ground truth = [79.54862286 68.34336759]\n",
            "Final score : 0.33566879107281566\n",
            "Pred = [63.62096327 71.7153895 ]\n",
            "Ground truth = [48.05927339 90.8409602 ]\n",
            "Score moyen : -94.57811143612784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRHYLcnf36Eb",
        "colab_type": "text"
      },
      "source": [
        "## SGD Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aziSaE6U3-EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model=  linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=\"elasticnet\")\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXwwBbE4dxg",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVGJFBcP4dm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=  GradientBoostingRegressor(loss=\"ls\",learning_rate=0.5,n_estimators=10000)\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLWKFdzf7RF7",
        "colab_type": "text"
      },
      "source": [
        "## MLP regressor (scikit-learn)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixPYe_857Uko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model= MLPRegressor()\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_fnEF6071qV",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZG_-zQ73Wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a388f0b7-7359-4a23-9d1a-264ca062b581"
      },
      "source": [
        "\n",
        "from sklearn import tree\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=tree.DecisionTreeRegressor()\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    code_doc        SR       SNR  ...  different_words  topic   0\n",
            "0      100_1  0.506749  0.975847  ...         0.608696   0.75 NaN\n",
            "1      107_7  0.875052  0.992874  ...         0.470588   1.00 NaN\n",
            "2      108_3  0.610753  0.950284  ...         0.696970   0.75 NaN\n",
            "3      128_5  0.636332  0.998066  ...         0.722581   0.75 NaN\n",
            "4       13_2  0.784851  0.995663  ...         0.767677   0.50 NaN\n",
            "..       ...       ...       ...  ...              ...    ...  ..\n",
            "295     96_6  0.761384  0.900388  ...         0.746032   0.75 NaN\n",
            "296     97_6  0.745310  0.962507  ...         0.705036   1.00 NaN\n",
            "297    98_13  0.661133  0.971335  ...         0.762887   0.75 NaN\n",
            "298    99_11  0.689642  0.995921  ...         0.696078   1.00 NaN\n",
            "299      9_1  0.554712  0.987751  ...         0.543011   0.75 NaN\n",
            "\n",
            "[300 rows x 15 columns]\n",
            "(197, 12)\n",
            "Final score : 0.3127147766323025\n",
            "Pred = [79.06209554 72.7880005  79.06209554 72.7880005  72.7880005  72.7880005\n",
            " 66.51390545 79.06209554 72.7880005  72.7880005  66.51390545 79.06209554\n",
            " 72.7880005  79.06209554 72.7880005  66.51390545 72.7880005  79.06209554\n",
            " 79.06209554 66.51390545]\n",
            "Ground truth = [79.06209554 72.7880005  79.06209554 72.7880005  66.51390545 66.51390545\n",
            " 72.7880005  79.06209554 66.51390545 72.7880005  72.7880005  79.06209554\n",
            " 79.06209554 79.06209554 72.7880005  60.23981041 79.06209554 79.06209554\n",
            " 72.7880005  72.7880005 ]\n",
            "Final score : 0.14163090128755373\n",
            "Pred = [79.06209554 66.51390545 79.06209554 72.7880005  53.96571536 72.7880005\n",
            " 72.7880005  72.7880005  72.7880005  79.06209554 60.23981041 72.7880005\n",
            " 53.96571536 72.7880005  60.23981041 79.06209554 72.7880005  53.96571536\n",
            " 72.7880005  79.06209554]\n",
            "Ground truth = [72.7880005  66.51390545 79.06209554 79.06209554 60.23981041 60.23981041\n",
            " 60.23981041 79.06209554 53.96571536 79.06209554 60.23981041 72.7880005\n",
            " 66.51390545 79.06209554 60.23981041 79.06209554 72.7880005  66.51390545\n",
            " 72.7880005  79.06209554]\n",
            "Final score : -0.9847328244274807\n",
            "Pred = [79.06209554 79.06209554 72.7880005  72.7880005  72.7880005  79.06209554\n",
            " 72.7880005  60.23981041 60.23981041 79.06209554 72.7880005  79.06209554\n",
            " 60.23981041 79.06209554 72.7880005  66.51390545 79.06209554 72.7880005\n",
            " 79.06209554 66.51390545]\n",
            "Ground truth = [60.23981041 79.06209554 72.7880005  53.96571536 66.51390545 72.7880005\n",
            " 72.7880005  60.23981041 66.51390545 72.7880005  72.7880005  72.7880005\n",
            " 72.7880005  79.06209554 60.23981041 66.51390545 53.96571536 72.7880005\n",
            " 66.51390545 72.7880005 ]\n",
            "Final score : -1.0253164556962022\n",
            "Pred = [72.7880005  72.7880005  66.51390545 79.06209554 72.7880005  66.51390545\n",
            " 72.7880005  79.06209554 72.7880005  60.23981041 79.06209554 66.51390545\n",
            " 53.96571536 60.23981041 79.06209554 72.7880005  79.06209554 60.23981041\n",
            " 53.96571536 72.7880005 ]\n",
            "Ground truth = [72.7880005  72.7880005  66.51390545 72.7880005  72.7880005  72.7880005\n",
            " 72.7880005  79.06209554 66.51390545 79.06209554 79.06209554 72.7880005\n",
            " 60.23981041 72.7880005  79.06209554 79.06209554 66.51390545 60.23981041\n",
            " 72.7880005  72.7880005 ]\n",
            "Final score : -0.4814814814814814\n",
            "Pred = [79.06209554 79.06209554 79.06209554 66.51390545 60.23981041 66.51390545\n",
            " 72.7880005  72.7880005  72.7880005  79.06209554 60.23981041 60.23981041\n",
            " 79.06209554 72.7880005  72.7880005  72.7880005  66.51390545 79.06209554\n",
            " 72.7880005  66.51390545]\n",
            "Ground truth = [72.7880005  79.06209554 72.7880005  66.51390545 79.06209554 72.7880005\n",
            " 72.7880005  53.96571536 79.06209554 66.51390545 60.23981041 66.51390545\n",
            " 79.06209554 66.51390545 66.51390545 79.06209554 72.7880005  66.51390545\n",
            " 60.23981041 60.23981041]\n",
            "Final score : -0.011235955056179803\n",
            "Pred = [79.06209554 79.06209554 72.7880005  60.23981041 79.06209554 72.7880005\n",
            " 60.23981041 60.23981041 79.06209554 79.06209554 79.06209554 79.06209554\n",
            " 60.23981041 60.23981041 66.51390545 66.51390545 72.7880005  72.7880005\n",
            " 79.06209554 60.23981041]\n",
            "Ground truth = [72.7880005  72.7880005  79.06209554 60.23981041 79.06209554 66.51390545\n",
            " 66.51390545 66.51390545 79.06209554 79.06209554 72.7880005  79.06209554\n",
            " 66.51390545 72.7880005  66.51390545 66.51390545 66.51390545 79.06209554\n",
            " 79.06209554 72.7880005 ]\n",
            "Final score : -2.0409356725146197\n",
            "Pred = [79.06209554 72.7880005  72.7880005  60.23981041 66.51390545 72.7880005\n",
            " 53.96571536 60.23981041 72.7880005  60.23981041 66.51390545 79.06209554\n",
            " 66.51390545 72.7880005  66.51390545 66.51390545 60.23981041 66.51390545\n",
            " 66.51390545 79.06209554]\n",
            "Ground truth = [72.7880005  72.7880005  72.7880005  66.51390545 66.51390545 72.7880005\n",
            " 72.7880005  66.51390545 66.51390545 72.7880005  72.7880005  79.06209554\n",
            " 66.51390545 72.7880005  79.06209554 72.7880005  66.51390545 72.7880005\n",
            " 72.7880005  79.06209554]\n",
            "Final score : -1.054054054054054\n",
            "Pred = [79.06209554 66.51390545 72.7880005  72.7880005  66.51390545 79.06209554\n",
            " 72.7880005  79.06209554 72.7880005  66.51390545 66.51390545 79.06209554\n",
            " 72.7880005  66.51390545 72.7880005  72.7880005  66.51390545 60.23981041\n",
            " 66.51390545]\n",
            "Ground truth = [72.7880005  72.7880005  72.7880005  66.51390545 66.51390545 72.7880005\n",
            " 72.7880005  72.7880005  72.7880005  79.06209554 66.51390545 72.7880005\n",
            " 72.7880005  72.7880005  72.7880005  60.23981041 60.23981041 72.7880005\n",
            " 79.06209554]\n",
            "Final score : -0.07090909090909082\n",
            "Pred = [66.51390545 66.51390545 66.51390545 60.23981041 79.06209554 53.96571536\n",
            " 66.51390545 66.51390545 72.7880005  72.7880005  72.7880005  53.96571536\n",
            " 72.7880005  60.23981041 72.7880005  53.96571536 79.06209554 60.23981041\n",
            " 66.51390545]\n",
            "Ground truth = [53.96571536 66.51390545 60.23981041 66.51390545 79.06209554 60.23981041\n",
            " 66.51390545 66.51390545 60.23981041 79.06209554 79.06209554 66.51390545\n",
            " 72.7880005  60.23981041 53.96571536 66.51390545 79.06209554 66.51390545\n",
            " 66.51390545]\n",
            "Final score : -0.5736196319018407\n",
            "Pred = [66.51390545 53.96571536 60.23981041 72.7880005  72.7880005  79.06209554\n",
            " 72.7880005  72.7880005  72.7880005  79.06209554 79.06209554 79.06209554\n",
            " 66.51390545 79.06209554 72.7880005  60.23981041 66.51390545 72.7880005\n",
            " 72.7880005 ]\n",
            "Ground truth = [72.7880005  72.7880005  60.23981041 79.06209554 72.7880005  79.06209554\n",
            " 72.7880005  79.06209554 66.51390545 79.06209554 72.7880005  72.7880005\n",
            " 66.51390545 60.23981041 66.51390545 66.51390545 66.51390545 72.7880005\n",
            " 79.06209554]\n",
            "Score moyen : -0.5787939488121093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg4mrF18LG6W",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning : Neural network \n",
        "\n",
        "\n",
        "Deep learning model with Keras over Tensorflow ( KFold with 10 folds as it is a small neural network with low number of samples ) :\n",
        "* Dense multilayer neural network with dropout, regularization, early stopping on validation ( optimizer : Adam, loss : MSE, metric : MAE)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwOZ70oiLm3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_network(nb_features):\n",
        "  model = Sequential()\n",
        " # model.add(Conv1D(4, int(nb_features[0]/2),input_shape=(nb_features[1], nb_features[2]), strides=1, padding='valid', dilation_rate=1, activation=None, \n",
        "  #                              use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', data_format=\"channels_first\",\n",
        "   #                             kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
        "  model.add(Dense(8, input_shape=(nb_features,)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  #model.add(GaussianNoise(0.1))\n",
        "  model.add(Dense(4, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
        "  \n",
        "  #model.add(Dense(nb_features, activation='relu'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Dense(2, activation='relu',kernel_regularizer=regularizers.l2(0.01) ))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Flatten())\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  adam = Adam(lr=0.0001)\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def kfold_valid(model,model_dataset, data_max, data_min, verbose=0,nb_epoch = 100 ):\n",
        "\n",
        "\n",
        "  df_x = model_dataset[model_dataset.columns[1:len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_x)\n",
        "  df_y = model_dataset[model_dataset.columns[len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_y)\n",
        "  nb_split=10\n",
        "  print(df_x.shape)\n",
        "  kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
        "  aux = 0\n",
        "  for train_index, test_index in kf.split(df_y):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    \n",
        "    model.fit(df_x[train_index], df_y[train_index],nb_epoch=nb_epoch, verbose=0)\n",
        "\n",
        "    score = model.evaluate(df_x[test_index], df_y[test_index])\n",
        "    aux += score[0]\n",
        "    \n",
        "    print(\"Final score : \" +str(score) )\n",
        "    predict = model.predict(df_x[test_index])\n",
        "    if verbose==1:\n",
        "      print(\"Pred = \" + str(un_norm(predict,data_max,data_min)) )\n",
        "      print(\"Ground truth = \" + str(un_norm(df_y[test_index],data_max,data_min)))\n",
        "  print(\"Score moyen : \" + str(float(aux/nb_split)))\n",
        "  return float(aux/nb_split)\n",
        "\n",
        "  \n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=get_network(len(model_dataset.columns[1:-1]))\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J29ln4qF8he4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}