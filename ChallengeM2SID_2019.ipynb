{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ChallengeM2SID_2019 (2).ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6t6jWihX0aH",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "Ce notebook permet de metter en place l'environnement de développement en python3 pour travailler sur le challenge. Les données sont synchronisées à la machine virtuelle dans les premières étapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJiWXJkOYRHg",
    "colab_type": "code",
    "outputId": "99133e2b-38e2-4247-995a-ea32e3260ec6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    }
   },
   "source": [
    "# OS setup\n",
    "!rm -rf challenge-m2-sid/\n",
    "!cat /etc/os-release\n",
    "!apt-get install -qq bc tree sox\n",
    "\n",
    "# Liaison avec les données\n",
    "#!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "NAME=\"Ubuntu\"\n",
      "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
      "VERSION_ID=\"18.04\"\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "VERSION_CODENAME=bionic\n",
      "UBUNTU_CODENAME=bionic\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0cF5YGYHZVBd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import GaussianNoise,BatchNormalization, Conv1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re  \n",
    "from google.colab import drive\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "from google.colab import files\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import urllib.request"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_t0arCaxebsA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#!tree challenge-m2-sid"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czYvPdRuab9E",
    "colab_type": "text"
   },
   "source": [
    "Un petit exemple d'utilisation de ce notebook..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hyxEvsAdZcNW",
    "colab_type": "code",
    "outputId": "eb00b37a-ec46-47be-db4f-b1432ba6d44c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "# Affichage d'un spectrogramme\n",
    "''' \n",
    "signal, fe = librosa.load('/content/challenge-m2-sid/corpus/audio/100_1_mono.wav', sr=16000, mono=True)\n",
    "sp = np.abs(librosa.stft(signal, n_fft=512, hop_length=256, window=np.hanning(512 + 2)[1:-1]))\n",
    "sp = 20.0 * np.log10(np.maximum(sp, np.max(sp) / 1e6))\n",
    "sp = sp - np.mean(sp)\n",
    "sp = sp - np.max(sp)\n",
    "librosa.display.specshow(sp, sr=fe, hop_length=256, y_axis='linear', x_axis='time', cmap='viridis', vmin=-80.0, vmax=0)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Linear-frequency power spectrogram')\n",
    "plt.show()\n",
    "\n",
    "# Affichage du signal\n",
    "plt.figure(1)\n",
    "plt.plot(np.arange(len(signal))/fe,signal)\n",
    "plt.xlabel('temps (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Signal audio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\" \\nsignal, fe = librosa.load('/content/challenge-m2-sid/corpus/audio/100_1_mono.wav', sr=16000, mono=True)\\nsp = np.abs(librosa.stft(signal, n_fft=512, hop_length=256, window=np.hanning(512 + 2)[1:-1]))\\nsp = 20.0 * np.log10(np.maximum(sp, np.max(sp) / 1e6))\\nsp = sp - np.mean(sp)\\nsp = sp - np.max(sp)\\nlibrosa.display.specshow(sp, sr=fe, hop_length=256, y_axis='linear', x_axis='time', cmap='viridis', vmin=-80.0, vmax=0)\\nplt.colorbar(format='%+2.0f dB')\\nplt.title('Linear-frequency power spectrogram')\\nplt.show()\\n\\n# Affichage du signal\\nplt.figure(1)\\nplt.plot(np.arange(len(signal))/fe,signal)\\nplt.xlabel('temps (s)')\\nplt.ylabel('Amplitude')\\nplt.title('Signal audio')\\nplt.grid(True)\\nplt.show()\\n\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7_dPc1aKZfcm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# lecture du fichier\n",
    "#Audio(data=signal, rate=fe)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbHbsyLSW2oV",
    "colab_type": "text"
   },
   "source": [
    "#Data vizualisation and normalisation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "H0775r3Chpu7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "# Annotation file reading\n",
    "csv_file = pd.read_csv(\"/content/annotations_challenge_sid.csv\", sep=\"\\t\" )\n",
    "\n",
    "# keep only lines that contains a number different from -1\n",
    "only_commented = []\n",
    "'''\n",
    "for index, row in csv_file.iterrows():\n",
    "    if row[\"il08_09\"] != -1 or row[\"vg04_05\"] != -1 \\\n",
    "            or row[\"fd03_04\"] != -1 or row[\"la09_10\"] != -1 \\\n",
    "        or row[\"cg13_14\"] != -1 or row[\"mb00_12\"] != -1 :\n",
    "        only_commented.append(row)\n",
    "# Transform it into a DataFrame\n",
    "only_commented = pd.DataFrame(only_commented)\n",
    "'''\n",
    "\n",
    "\n",
    "# Return a subset of informations limited to a communication medium \n",
    "# (audio : 100 , text : 001, audio and video : 110, audio and text : 101 \n",
    "# audio, video and text : 111)\n",
    "def get_medium(medium, df):\n",
    "  return (df[df[\"code_doc\"].map(lambda x : x[len(x)-5:-2]==medium)])\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "q9Lvn_KRhpu9",
    "colab_type": "code",
    "outputId": "fc2e8446-ff9d-4b4e-cc13-23620671d475",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    }
   },
   "source": [
    "#Audio\n",
    "print(get_medium(\"100\",only_commented))\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-06d61a11d97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_medium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"100\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monly_commented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-2cdd2911db9d>\u001b[0m in \u001b[0;36mget_medium\u001b[0;34m(medium, df)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# audio, video and text : 111)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_medium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code_doc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yhrGk6UahpvA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Texte\n",
    "print(get_medium(\"001\",only_commented))\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yPbCeAN_hpvC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Audio vidéo\n",
    "print(get_medium(\"110\",only_commented))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "alQiCMaYhpvE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Audio texte\n",
    "print(get_medium(\"101\",only_commented))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "O_7lqY91hpvG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#All\n",
    "print(get_medium(\"111\",only_commented))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "iLs2JfTvhpvK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIgxJ9qxim9s",
    "colab_type": "text"
   },
   "source": [
    " # Comparaisons aux annotations\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WBsMORLdirSa",
    "colab_type": "code",
    "outputId": "6e583416-0744-4ac9-bc11-c3b60122d6f1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    }
   },
   "source": [
    "\n",
    "# Choose the medium to use\n",
    "# Medium is a string : sequence of 3 bits : audio-video-texte sequence\n",
    "# only_commented : Dataframe of each annotated extract (not only extracts\n",
    "# ending with a \"1\")\n",
    "def ret_max_docid(medium, only_commented):\n",
    "  # Get the list of annotated extracts for a medium\n",
    "  medium = get_medium(medium, only_commented)\n",
    "  # Get list of files identifiants\n",
    "  list_file = medium[\"code_doc\"]\n",
    "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
    "  return [(i[0],i[1:].max()) for i in medium[medium.columns[-7:]].values ]\n",
    "ret_max_docid(\"101\", only_commented)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2a12cc697ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Return the list of couple (doc_id, evaluation max of complexity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmedium\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mret_max_docid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"101\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_commented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2a12cc697ab7>\u001b[0m in \u001b[0;36mret_max_docid\u001b[0;34m(medium, only_commented)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mret_max_docid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_commented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Get the list of annotated extracts for a medium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmedium\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_medium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_commented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Get list of files identifiants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlist_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedium\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code_doc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-2cdd2911db9d>\u001b[0m in \u001b[0;36mget_medium\u001b[0;34m(medium, df)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# audio, video and text : 111)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_medium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code_doc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmedium\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d6Y_ma8Lirob",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "csv_file_nan = csv_file.replace(-1,np.nan)\n",
    "csv_file_nan.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_ujN_bmYMrFk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "csv_file_nan[csv_file_nan.columns[2:]].describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xi2O1cWBQaY1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "names = csv_file_nan.columns[2:]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard_scaled_csv = scaler.fit_transform(only_commented[csv_file_nan.columns[2:]])\n",
    "standard_scaled_csv = pd.DataFrame(standard_scaled_csv, columns=names)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u_usJ4KARQ_l",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "standard_scaled_csv.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j9pLFl-fUtkL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_scaled_csv= preprocessing.normalize(only_commented[csv_file_nan.columns[2:]])\n",
    "norm_scaled_csv = pd.DataFrame(norm_scaled_csv, columns=names)\n",
    "norm_scaled_csv.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GO4XWqXKVNXR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_scaled_csv"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KtYVuSuFuTb7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "only_commented_nan = only_commented.replace(-1,np.nan)\n",
    "imputer.fit(only_commented_nan[csv_file_nan.columns[2:]])\n",
    "coucou = imputer.transform(only_commented_nan[csv_file_nan.columns[2:]])\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SpE0SKoh06Fu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_scaled_csv= preprocessing.normalize(coucou)\n",
    "norm_scaled_csv = pd.DataFrame(norm_scaled_csv, columns=names)\n",
    "norm_scaled_csv"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ez2D9wlY1B_P",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#only_commented_nan\n",
    "def norm_to_zero_one(df):\n",
    "    return (df - df.min()) * 1.0 / (df.max() - df.min())\n",
    "#norm_to_zero_one()\n",
    "norm_to_zero_one(only_commented_nan[only_commented_nan.columns[2:]]).describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HXhPr_zS6Rzo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "def normalisation_annot(df):\n",
    "    name = df.columns[2:]\n",
    "    #fig, ax = plt.subplots(6, 1, figsize=(9, 16), sharex=True)\n",
    "    ret_df = df[df[name]!=-1]\n",
    "    max_list = []\n",
    "    min_list = []\n",
    "    for i, annot in enumerate(ret_df[name]):\n",
    "      #test[test[annotateur]!=-1][annotateur]\n",
    "        #  ((only_commented_nan[annot]-only_commented_nan[annot].mean() )/only_commented_nan[annot].std()).hist()\n",
    "        ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
    "        max_list.append(ret_df[annot].max())\n",
    "        min_list.append(ret_df[annot].min())\n",
    "    return  ret_df, max_list, min_list \n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qMBl3h551uj8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def plot_hist(df):\n",
    "    fig, ax = plt.subplots(6,1,figsize=(9, 16), sharex=True )\n",
    "    name = df.columns[2:]\n",
    "    for i,annot in enumerate(df[name]):\n",
    "    #  ((only_commented_nan[annot]-only_commented_nan[annot].mean() )/only_commented_nan[annot].std()).hist()\n",
    "      ax[i].hist(((df[annot]-df[annot].mean() )/df[annot].std()))\n",
    "    fig.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LR1r-SPU5TrA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm,maxi,mini = normalisation_annot(only_commented)\n",
    "maxi = np.array(maxi).max()\n",
    "mini = np.array(mini).min()\n",
    "norm[norm.columns[2:]]\n",
    "print(mini)\n",
    "print(maxi)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GrgHTr4E6mRO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "f, ax = plt.subplots(6, 1, sharex=True, figsize=(14, 12))\n",
    "\n",
    "#print(csv_file[csv_file[annot] != -1][annot].describe())\n",
    "for i, annot in enumerate(names):\n",
    "  std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "  #print(get_commented_for_annot(csv_file,annot)[annot].values)\n",
    "  # coucou = std_scaler.fit_transform(np.array(get_commented_for_annot(csv_file[csv_file[annot] != -1],annot)[annot].values).reshape(-1,1))\n",
    "  coucou = csv_file[csv_file[annot] != -1][annot].values\n",
    "\n",
    "  coucou = (coucou - np.mean(coucou)) / np.std(coucou)\n",
    "  #coucou = 100*(coucou - coucou.min() ) / (coucou.max() - coucou.min())\n",
    "\n",
    "\n",
    "\n",
    "  #coucou2 = 100*(coucou2 - coucou2.min() ) / (coucou2.max() - coucou2.min())\n",
    "  #print(pd.DataFrame(coucou).describe())\n",
    "  # Normalisé ! Ouais ! Youpi !\n",
    "  ax[i].hist(norm[norm.columns[2:]][annot])\n",
    "  #pd.DataFrame(norm[norm.columns[2:]]).hist(ax=ax[i])\n",
    "  #norm.hist(ax=ax[i])\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TfobcsPe-kw7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "#for annot in norm.columns[2:]:\n",
    "#    print(norm[np.isfinite(norm[annot])][annot])\n",
    "def get_medium_from_normalised(medium,norm,csv_file):\n",
    "  return norm[norm[ norm.columns[0]].index.isin( get_medium(medium,csv_file).index)]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K3vhwyB7WYp2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puDU_PTwWzH9",
    "colab_type": "text"
   },
   "source": [
    "#Audio feature extraction part\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uIRNaiYLW7MM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#print('Beginning file download')\n",
    "\n",
    "#url = 'http://www.lexique.org/shiny/lexique/session/f5a29584fd4e031d9548b6a8da88c38d/download/download?w='\n",
    "#urllib.request.urlretrieve(url, 'Lexique-query-2019-10-29 09_16_32.xlsx')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pn7rPWYdW_pt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_sentences(List_txt, path_text):\n",
    "  dic_docs = {}\n",
    "  for doc in List_txt:\n",
    "    tree = ET.parse(path_text + doc)\n",
    "    root = tree.getroot()\n",
    "    dic_docs[doc] = []\n",
    "    for s in root:\n",
    "      sentence = ''\n",
    "      for w in s:\n",
    "        word = w.text\n",
    "        if (word is not None):\n",
    "          sentence = sentence + word\n",
    "      dic_docs[doc].append(sentence)\n",
    "  return(dic_docs)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_cNL4CntXAzj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def clean_sentences(dic_docs):  \n",
    "  for key in dic_docs.keys() : \n",
    "    list_new = []\n",
    "    for sentence in dic_docs[key]:\n",
    "      sentence = sentence.replace(\"'\", ' ').replace(\"’\", ' ')\n",
    "      sentence = re.sub(\"([^\\s\\w\\-])\", '',sentence)\n",
    "      list_new.append(sentence)\n",
    "    dic_docs[key] = list_new\n",
    "  return(dic_docs)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Iri5pGfZXCA6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_clean_words(dic_docs):\n",
    "  for key in dic_docs.keys() : \n",
    "    list_words = []\n",
    "    for sentence in dic_docs[key]:\n",
    "      for word in sentence.split():\n",
    "          w = word.replace(' ', '')\n",
    "          if len(w) != 0:\n",
    "            list_words.append(w.lower())\n",
    "    dic_docs[key] = list_words\n",
    "  return(dic_docs)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bRzeb8C-XEsM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#path_text = 'challenge-m2-sid/corpus/text/'\n",
    "#List_txt = os.listdir(path_text)\n",
    "#List_txt.sort()\n",
    "#dic_docs = get_clean_words(clean_sentences(get_sentences(List_txt, path_text)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FjIfxHXvOw",
    "colab_type": "text"
   },
   "source": [
    "###Feature 1 : number of low frequencie words per video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VFDpah1oXxTo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def read_excel(file):\n",
    "  dfs = pd.ExcelFile(file)\n",
    "  sh = dfs.sheet_names[0]\n",
    "  df_lex = dfs.parse('Sheet1')\n",
    "  df_lex = df_lex[['ortho', 'lemme', 'cgram', 'freqfilms2', 'nbsyll']]\n",
    "  serie = df_lex['freqfilms2']\n",
    "  normalized_serie=(serie)/max(serie)\n",
    "  df_lex['freqfilms2_norm'] = normalized_serie\n",
    "  return(df_lex)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S5oK9yQIXGZc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#df_lex = read_excel('Lexique-query.xlsx')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lYb3v8G6XIPo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_complexity_doc(doc, df_lex, dic_docs):\n",
    "  cplxty = 0\n",
    "  for word in list(set(dic_docs[doc])):\n",
    "    try : \n",
    "      freq = max(df_lex[df_lex['ortho']==word]['freqlemfilms2_norm'])\n",
    "    except :\n",
    "      if len(word) >= 3:\n",
    "        freq = 0\n",
    "      else : \n",
    "        freq = 1\n",
    "    if freq < 0.0001:\n",
    "      cplxty = cplxty + 1\n",
    "#      print(word)\n",
    "#      print(freq)\n",
    "  cplxty = cplxty/(len(list(set(dic_docs[doc]))))\n",
    "  return(cplxty)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9QzEgXWGXJoe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_all_cplx(df_lex, dic_docs):\n",
    "  dic_cplx = {}\n",
    "  i = 1\n",
    "  N = len(dic_docs.keys())\n",
    "  for doc in dic_docs.keys():\n",
    "    print(str(i) + ' / ' + str(N))\n",
    "    dic_cplx[doc] = get_complexity_doc(doc, df_lex, dic_docs)\n",
    "    i = i + 1\n",
    "  return(dic_cplx)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a4Okz_3fXLSz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_cplx = get_all_cplx(df_lex, dic_docs)\n",
    "#ma_cplx = max(dic_cplx.values())\n",
    "#mi_cplx = min(dic_cplx.values())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eacuttD-XROB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def normalize_results(dic, ma, mi):\n",
    "  dic_N = {}\n",
    "  for doc in dic.keys():\n",
    "    score = dic[doc]\n",
    "    score =  100 * (score - mi) / (ma - mi)\n",
    "    dic_N[doc] = score\n",
    "  return(dic_N)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vECSiradXSg7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_cplx_1_doc(ma, doc, df_lex, dic_docs):\n",
    "  return(normalize_results({doc:get_complexity_doc(doc, df_lex, dic_docs)}, ma)[doc])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W0ssr74CXTvW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_cplx_N = normalize_results(dic_cplx, ma_cplx, mi_cplx)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HbTCNvLUXVEY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# compar_anno(dic_cplx_N, \"001\", only_commented)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC41wLquXYEV",
    "colab_type": "text"
   },
   "source": [
    "### Feature 2-3 : Number of sentences per minute and mean length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ti6HvtZNX4Tl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_docs_sent = clean_sentences(get_sentences(List_txt, path_text))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ckc9wArRX5ZY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_length_sentences_nb(dic_docs_sent, dic_doc_len_video):\n",
    "  dic_len_sentence = {}\n",
    "  dic_nb_sentence =  {}\n",
    "  for doc in dic_docs_sent.keys():\n",
    "    time = dic_doc_len_video[doc]\n",
    "    time_s = time.total_seconds()\n",
    "    nb_s = len(dic_docs_sent[doc])\n",
    "    s_per_min = 60*nb_s/time_s\n",
    "    mean_len_s = np.mean([len(s.split()) for s in dic_docs_sent[doc]])\n",
    "    dic_len_sentence[doc] = mean_len_s\n",
    "    dic_nb_sentence[doc] = s_per_min\n",
    "  return(dic_len_sentence, dic_nb_sentence)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cKjD1_AEX6iM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_len_video(List_txt, path_text):\n",
    "  dic_doc_len_video = {}\n",
    "  for doc in List_txt:\n",
    "    tree = ET.parse(path_text + doc)\n",
    "    root = tree.getroot()\n",
    "    ma = int(max([root[i].attrib['id'] for i in range(len(root))]))\n",
    "    start = root[0][0].attrib['value'][:8]\n",
    "    end = root[ma-1][-1].attrib['value'][:8]\n",
    "    format_ = '%H:%M:%S'\n",
    "    startDateTime = datetime.datetime.strptime(start, format_)\n",
    "    endDateTime = datetime.datetime.strptime(end, format_)\n",
    "    diff = endDateTime - startDateTime\n",
    "    dic_doc_len_video[doc] = diff\n",
    "  return(dic_doc_len_video)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4tYQus10X7uv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_doc_len_video = get_len_video(List_txt, path_text)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BW2MI54YX9C9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_len_sentence, dic_nb_sentence = get_length_sentences_nb(dic_docs_sent, dic_doc_len_video)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wLkhz0kCX-X0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#ma_nb_s = max(dic_nb_sentence.values())\n",
    "#mi_nb_s = min(dic_nb_sentence.values())\n",
    "#ma_len_s = max(dic_len_sentence.values())\n",
    "#mi_len_s = min(dic_len_sentence.values())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gnMtMIhfX_bu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_len_sentence_N = normalize_results(dic_len_sentence, ma_len_s, mi_len_s)\n",
    "#dic_nb_sentence_N = normalize_results(dic_nb_sentence, ma_nb_s, mi_nb_s)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Klqmn4VlYB9Z",
    "colab_type": "text"
   },
   "source": [
    "### Feature 4 : Word repetition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OlNu6of6YJQG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_repetition_ratio_doc(doc, dic_docs):\n",
    "  list_words_dif = list(set(dic_docs[doc]))\n",
    "  list_words = dic_docs[doc]\n",
    "  rep = 100*(len(list_words_dif)/len(list_words))\n",
    "  return(rep)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "giFBzcLTYKcK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_all_rep (dic_docs):\n",
    "  dic_repetition = {}\n",
    "  for doc in dic_docs.keys():\n",
    "    dic_repetition[doc] = get_repetition_ratio_doc(doc, dic_docs)\n",
    "  return(dic_repetition)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tGwLGBp6YKXU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_repetition = get_all_rep (dic_docs)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tQI7zpI9YM_l",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#ma_repet = max(dic_repetition.values())\n",
    "#mi_repet = min(dic_repetition.values())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yWNN9hJRYOLe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_repetition_N = normalize_results(dic_repetition, ma_repet, mi_repet)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFba9AvcYQPT",
    "colab_type": "text"
   },
   "source": [
    "### Feature 5 : Syllable per seconds"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3hOGDMOGYTH9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_time_sentence(List_txt, path_text):\n",
    "  dic_doc_time_sentences = {}\n",
    "  for doc in List_txt:\n",
    "    tree = ET.parse(path_text + doc)\n",
    "    root = tree.getroot()\n",
    "    list_times_sec = []\n",
    "    for child in root : \n",
    "      TS = child[0].attrib['value'][:8]\n",
    "      TE = child[-1].attrib['value'][:8]\n",
    "      format_ = '%H:%M:%S'\n",
    "      startDateTime = datetime.datetime.strptime(TS, format_)\n",
    "      endDateTime = datetime.datetime.strptime(TE, format_)\n",
    "      diff = endDateTime - startDateTime\n",
    "      list_times_sec.append(diff.total_seconds())\n",
    "    dic_doc_time_sentences[doc] = list_times_sec\n",
    "  return(dic_doc_time_sentences)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-baU9ZWXYUeu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_doc_time_sentences =  get_time_sentence(List_txt, path_text)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vy715czgYVpd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def nb_syll_sec (dic_doc_time_sentences, dic_docs, df_lex):\n",
    "  dic_syll_per_sec = {}\n",
    "  i = 1\n",
    "  N = len(dic_docs)\n",
    "  m = np.mean(df_lex['nbsyll'])\n",
    "  list_words = list(set(list(df_lex['ortho'])))\n",
    "  for doc in dic_doc_time_sentences.keys():\n",
    "    print(str(i) + ' / ' + str(N))\n",
    "    time = 0\n",
    "    syll = 0\n",
    "    time = sum(dic_doc_time_sentences[doc])\n",
    "    syll = sum([df_lex[df_lex['ortho']==w]['nbsyll'] for w in dic_docs[doc] if w in list_words])\n",
    "    syll = syll + sum([m for w in dic_docs[doc] if w not in list_words])\n",
    "    ratio = syll / time \n",
    "    dic_syll_per_sec[doc] = ratio\n",
    "    i = i + 1\n",
    "  return(dic_syll_per_sec)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y7iMALdoYWvs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_syll_per_sec = nb_syll_sec (dic_doc_time_sentences, dic_docs_sent, df_lex)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8DwlAH-dYX--",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#ma_sy = max(dic_syll_per_sec.values())\n",
    "#mi_sy = min(dic_syll_per_sec.values())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x_CzLPGfYZGo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#dic_syll_per_sec_N = normalize_results(dic_syll_per_sec, ma_sy, mi_sy)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vdgq-R7hYuGc",
    "colab_type": "text"
   },
   "source": [
    "### Features-aggregation \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKWh6YeLYxMr",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def create_DF_agreg(dic_nb_sentence_N,\n",
    "                    dic_len_sentence_N,\n",
    "                    dic_cplx_N,\n",
    "                    dic_syll_per_sec_N,\n",
    "                    dic_repetition):\n",
    "  col = ['doc', 'nb_sentence', 'len_sentence', 'cplx_words', 'syll_sec','different_words']\n",
    "  list_DF = []\n",
    "  for doc in dic_nb_sentence_N.keys():\n",
    "    list_DF_doc = [doc,\n",
    "                   dic_nb_sentence_N[doc],\n",
    "                   dic_len_sentence_N[doc],\n",
    "                   dic_cplx_N[doc],\n",
    "                   dic_syll_per_sec_N[doc],\n",
    "                   dic_repetition[doc]]\n",
    "    list_DF.append(list_DF_doc)\n",
    "  DF = pd.DataFrame(list_DF, columns=col)\n",
    "  return(DF)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UpAtHQ0GYyoB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#DF_aggreg = create_DF_agreg(dic_nb_sentence_N,\n",
    "#                    dic_len_sentence_N,\n",
    "#                    dic_cplx_N,\n",
    "#                    dic_syll_per_sec_N,\n",
    "#                    dic_repetition_N)\n",
    "\n",
    "\n",
    "DF_aggreg = pd.read_csv(\"DF_aggreg.csv\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qrNvi-s-Y34Y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DF_aggreg"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CcVSH19c1Pck",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#DF_aggreg.to_csv(\"DF_aggreg.csv\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3o2lsGJWV_T",
    "colab_type": "text"
   },
   "source": [
    "# Aggregation model part "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hdvdwmFID_8C",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDFuUdaHp7YO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_text = get_medium_from_normalised(\"100\",norm,csv_file)\n",
    "#print(csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"])\n",
    "#print(norm_text)  \n",
    "df_code_doc =csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"]\n",
    "\n",
    "df_code_doc=df_code_doc.map(lambda x : x.split(\"_\")[0]+\"_\"+x.split(\"_\")[1]+\".xml\")\n",
    "\n",
    "\n",
    "df_code_annot = pd.concat([df_code_doc,norm_text[norm_text.columns[2:]]], axis=1)\n",
    "#print(df_code_annot)\n",
    "#df_code_annot[\"code_doc\"] = df_code_annot[\"code_doc\"].map(lambda x : x[:6] + \".xml\")\n",
    "\n",
    "df_mean = df_code_annot[df_code_annot.columns[1:]].mean(axis=1)\n",
    "print(df_code_annot)\n",
    "df_code_mean = pd.concat([df_code_annot[df_code_annot.columns[0]], df_mean], axis=1)\n",
    "print(df_code_mean)\n",
    "\n",
    "#print(df_code_mean)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iWa7rSC6xbVi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_text = get_medium_from_normalised(\"100\",norm,csv_file)\n",
    "#print(csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"])\n",
    "#print(norm_text)  \n",
    "df_code_doc =csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"]\n",
    "\n",
    "df_code_doc=df_code_doc.map(lambda x : x.split(\"_\")[0]+\"_\"+x.split(\"_\")[1]+\".xml\")\n",
    "\n",
    "\n",
    "df_code_annot = pd.concat([df_code_doc,norm_text[norm_text.columns[2:]]], axis=1)\n",
    "#print(df_code_annot)\n",
    "#df_code_annot[\"code_doc\"] = df_code_annot[\"code_doc\"].map(lambda x : x[:6] + \".xml\")\n",
    "\n",
    "df_mean = df_code_annot[df_code_annot.columns[1:]].mean(axis=1)\n",
    "print(df_code_annot)\n",
    "df_code_mean = pd.concat([df_code_annot[df_code_annot.columns[0]], df_mean], axis=1)\n",
    "print(df_code_mean)\n",
    "\n",
    "#print(df_code_mean)\n",
    "#pattern = re.compile(\"[1-9]{1,3}_[1-9]{1,3}_100_[0-1]\")\n",
    "#list_doc = np.array([])\n",
    "#for i in csv_file[\"code_doc\"]:\n",
    "#  if pattern.match(i):\n",
    "#    print(i)\n",
    "#    list_doc = np.append(list_doc, i)\n",
    "#csv_file[csv_file[\"code_doc\"]==list_doc]\n",
    "\n",
    "#print(norm_text[norm_text.columns[2:]].mean(axis=1))\n",
    "#print(csv_file[csv_file.index.isin( y_set.index)])\n",
    "\n",
    "\n",
    "norm_text = get_medium_from_normalised(\"100\",norm,csv_file)\n",
    "#print(csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"])pre training neural network for complexity scoring\n",
    "#print(norm_text)  \n",
    "#df_code_doc =csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"]\n",
    "coucou = pd.concat([csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"],norm_text[norm_text.columns[2:]]], axis=1)\n",
    "#print(coucou)\n",
    "#coucou.to_csv(\"norm_text_commented.csv\")\n",
    "#print(norm_text.shape)\n",
    "#print(file_list)\n",
    "norm_text = norm_text[norm_text.columns]\n",
    "print(norm_text)\n",
    "#On prend le max\n",
    "norm_text=norm_text.mean(axis=1)\n",
    "################################## TESTER LA MEDIANE / LA MOYENNE\n",
    "print(norm_text)\n",
    "y_set = norm_text\n",
    "#print(file_list)\n",
    "#print(y_set[y_set.columns[2:]].mean(axis=1))\n",
    "#print(y_set.shape)\n",
    "#print(DF_aggreg)\n",
    "#df_code_doc = df_code_doc.map(lambda x: re.search(\"[1-9]{1,3}_[1-9]{1,3}\",x)[0]+\".xml\")\n",
    "#print(df_code_doc)\n",
    "print(DF_aggreg[\"doc\"])\n",
    "print(df_code_doc)\n",
    "x_set = DF_aggreg[DF_aggreg[\"doc\"].isin(df_code_doc)]\n",
    "x_set=x_set[x_set.columns]\n",
    "x_set = x_set.rename(columns={\"doc\":\"code_doc\"})\n",
    "print(x_set)\n",
    "#print(x_set)\n",
    "#for annot in norm.columns[2:]:\n",
    "#    print(norm[np.isfinite(norm[annot])][annot])\n",
    "#def get_medium_from_normalised(norm,csv_file):\n",
    " # return norm[norm[ norm.columns[0]].index.isin( get_medium(\"101\",csv_file).index)]\n",
    "\n",
    "\n",
    "# FAIRE UNE FONCTION POUR TOUT CA"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZI38pH6DRR6g",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "df_code_mean = df_code_mean.rename(columns={0:\"label\"})\n",
    "df_code_mean = df_code_mean.sort_values(by=[\"code_doc\"])\n",
    "x_set = x_set.sort_values(by=[\"code_doc\"])\n",
    "print(x_set)\n",
    "#print(y_set)\n",
    "#print(df_code_mean)\n",
    "dataset = pd.merge(x_set,df_code_mean, on=\"code_doc\")\n",
    "print(dataset)\n",
    "print(DF_aggreg.columns)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A9SJ4d8P5w6c",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "# A FAIRE : get list des doc à featuriser\n",
    "#y_set = get_medium(\"100\",csv_file) \n",
    "#print(normalisation(csv_file))\n",
    "def only_commented_f(df):\n",
    "  only_commented = []\n",
    "  for index, row in df.iterrows():\n",
    "      if row[\"il08_09\"] != -1 or row[\"vg04_05\"] != -1 \\\n",
    "              or row[\"fd03_04\"] != -1 or row[\"la09_10\"] != -1 \\\n",
    "          or row[\"cg13_14\"] != -1 or row[\"mb00_12\"] != -1 :\n",
    "          only_commented.append(row)\n",
    "  # Transform it into a DataFrame\n",
    "  return pd.DataFrame(only_commented)\n",
    "#print(only_commented(y_set))\n",
    "#for i in y_set[y_set.columns[2:]]:\n",
    "# CHOIX A FAIRE SUR Y_SET -> transform into 1 value dataframe\n",
    "\n",
    "\n",
    "  #model.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "  #            activity_regularizer=regularizers.l1(0.01)))\n",
    "  #model.add(Dropout(0.25))\n",
    "\n",
    "def get_network(nb_features):\n",
    "  model = Sequential()\n",
    " # model.add(Conv1D(4, int(nb_features[0]/2),input_shape=(nb_features[1], nb_features[2]), strides=1, padding='valid', dilation_rate=1, activation=None, \n",
    "  #                              use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', data_format=\"channels_first\",\n",
    "   #                             kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "  model.add(Dense(8, input_shape=(nb_features,)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation(\"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  #model.add(GaussianNoise(0.1))\n",
    "  model.add(Dense(4, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  \n",
    "  #model.add(Dense(nb_features, activation='relu'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Dense(2, activation='relu',kernel_regularizer=regularizers.l2(0.01) ))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Flatten())\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  adam = Adam(lr=0.0001)\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wVbVXv4Qv3j0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def un_norm(in_values, maxi,mini):\n",
    "  values = np.array([])\n",
    "  for i,value in enumerate(in_values):\n",
    "    values = np.append(values,100*(value - mini)/(maxi - mini))\n",
    "  return values\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalisation(df):\n",
    "    name = df.columns\n",
    "    #fig, ax = plt.subplots(6, 1, figsize=(9, 16), sharex=True)\n",
    "    ret_df = df[df[name]!=-1]\n",
    "    max_list = []\n",
    "    min_list = []\n",
    "    for i, annot in enumerate(ret_df[name]):\n",
    "      #test[test[annotateur]!=-1][annotateur]\n",
    "        #  ((only_commented_nan[annot]-only_commented_nan[annot].mean() )/only_commented_nan[annot].std()).hist()\n",
    "        ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
    "        max_list.append(ret_df[annot].max())\n",
    "        min_list.append(ret_df[annot].min())\n",
    "    return  ret_df, max_list, min_list \n",
    "#print(kf)\n",
    "#print(dataset)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7BeAPWe_J7tm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import seaborn as sb\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "sb.heatmap(dataset[dataset.columns[2:]].corr())\n",
    "plt.matshow(dataset[dataset.columns[2:]].corr())\n",
    "\n",
    "plt.show()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LLNo0JH9PioH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dataset"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "32VcM0gES-Qm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(dataset.columns[1:])\n",
    "features = [ 'nb_sentence', 'len_sentence', 'cplx_words',\n",
    "       'syll_sec', 'different_words']\n",
    "\n",
    "df_x = dataset[features].to_numpy()\n",
    "df_x_norm,_,_ = normalisation(pd.DataFrame(df_x))\n",
    "df_x_norm = df_x_norm.to_numpy()\n",
    "#print(df_x)\n",
    "df_y = dataset[dataset.columns[len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_y)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rjBkq6n3VgQV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def addition_monpote(features):\n",
    "  pred = []\n",
    "  weights= [0.1,0.1,0.4,0.1,0.3]\n",
    "  for feature_list in features:\n",
    "    pred.append(feature_list.dot(weights))\n",
    "  return pred\n",
    "\n",
    "def max_monpote(features):\n",
    "  pred = []\n",
    "\n",
    "  for feature_list in features:\n",
    "    pred.append(max(feature_list))\n",
    "  return pred\n",
    "print(un_norm(max_monpote(df_x),maxi,mini))\n",
    "print(un_norm(df_y,maxi,mini))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9aKkVes9Ymmb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "  #X = [[0.44, 0.68], [0.99, 0.23]]\n",
    "  #vector = [109.85, 155.72]\n",
    "  #predict= [[0.49, 0.18]]\n",
    "#Edit: added second square bracket above to fix the ValueError problem\n",
    "\n",
    "'''\n",
    "  >>> from sklearn.preprocessing import PolynomialFeatures\n",
    ">>> from sklearn.linear_model import LinearRegression\n",
    ">>> from sklearn.pipeline import Pipeline\n",
    ">>> import numpy as np\n",
    ">>> model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "...                   ('linear', LinearRegression(fit_intercept=False))])\n",
    ">>> # fit to an order-3 polynomial data\n",
    ">>> x = np.arange(5)\n",
    ">>> y = 3 - 2 * x + x ** 2 - x ** 3\n",
    ">>> model = model.fit(x[:, np.newaxis], y)\n",
    ">>> model.named_steps['linear'].coef_\n",
    "'''\n",
    "def polynomial_reg(data):\n",
    "  array([ 3., -2.,  1., -1.])\n",
    "  poly = PolynomialFeatures(degree=2)\n",
    "  X_ = poly.fit_transform(data)\n",
    "  predict_ = poly.fit_transform(predict)\n",
    "\n",
    "  clf = linear_model.LinearRegression()\n",
    "  clf.fit(X_, vector)\n",
    "  print(clf.predict(predict_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  poly = PolynomialFeatures(degree=2)\n",
    "  X_ = poly.fit_transform(data)\n",
    "  predict_ = poly.fit_transform(predict)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mJy-zgOZKS7V",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_splits = 10\n",
    "aux=  np.array([0,0])\n",
    "kf = KFold(n_splits = n_splits, shuffle = True, random_state = 0)\n",
    "'''\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  x = df_x_norm[train_index]\n",
    "  #x= np.reshape(x,(1,x.shape[0], x.shape[1]))\n",
    "  #x = np.expand_dims(x, axis=0)\n",
    "  print(x.shape)\n",
    "  model=get_network(x.shape[1])\n",
    "  model.fit(x, df_y[train_index], validation_data=(x[test_index], df_y[test_index]),epochs=300\n",
    "            , verbose = 0, callbacks=[EarlyStopping(verbose=1,patience = 10)])\n",
    "  score = model.evaluate(df_x_norm[test_index], df_y[test_index])\n",
    "\n",
    "  print(\"Final loss : \" +str(score) )\n",
    "  predict = model.predict(x)\n",
    "  print(\"Pred = \" + str(un_norm(predict,maxi,mini) ))\n",
    "  print(\"Ground truth = \" + str(un_norm(df_y,maxi,mini)))\n",
    "  aux[0] += score[0]\n",
    "  aux[1] += score[1]\n",
    "aux = aux / n_splits\n",
    "print(\"Mean loss : \", end=\"\")\n",
    "\n",
    "\n",
    "print(aux)\n",
    "\n",
    "print(model.summary())\n",
    "'''"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J6bAhT7C85v8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "''' \n",
    "x_values = df.iloc[:,2:len(df)-2].values\n",
    "\n",
    "y_index = df.columns[-1:]\n",
    "list_data= df.to_numpy().transpose()\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 0)\n",
    "\n",
    "result = next(kf.split(df), None)\n",
    "#print(result)\n",
    "label = df[df.columns[-1:]]\n",
    "print(label)\n",
    "#pre training neural network for complexity scoring\n",
    "x = df[df.columns[1:-1]]\n",
    "print(x)\n",
    "tf_data = tf.data.Dataset.from_tensor_slices((x.values, label.values))\n",
    "print(tf_data)\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  \n",
    "  #x_train = dataset[x_index].iloc()[train_index]\n",
    "  #print(x_train.shape)\n",
    "  #y_train = dataset[y_index].iloc()[train_index]\n",
    "  #print(y_train.shape)\n",
    "  #x_test = dataset[x_index].iloc()[test_index]\n",
    "  #print(x_test)\n",
    "  #y_test = dataset[y_index].iloc()[test_index]\n",
    "  #print(y_test.shape)\n",
    "\n",
    "\n",
    "  model=get_network(5)\n",
    "\n",
    "  model.fit(tf_data,epochs=50)\n",
    "'''"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKoUjHgH6Fgm",
    "colab_type": "text"
   },
   "source": [
    "Corrélation, scatter plot\n",
    "\n",
    "TODO : Barlett test, IID verification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80udwdGpJgC3",
    "colab_type": "text"
   },
   "source": [
    "# Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OsmTNBB8mQEh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(kf)\n",
    "df_x = dataset[dataset.columns[2:len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = dataset[dataset.columns[len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model= linear_model.Lasso(alpha=0)\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(predict) )\n",
    "  print(\"Ground truth = \" + str(df_y[test_index]))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd4-qUx-Jh39",
    "colab_type": "text"
   },
   "source": [
    "SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CkSs7AvJIBVO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "#print(kf)\n",
    "df_x = dataset[dataset.columns[2:len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = dataset[dataset.columns[len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model=  linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=\"elasticnet\")\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  print(df_x[test_index])\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(predict) )\n",
    "  print(\"Ground truth = \" + str(df_y[test_index]))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPrujK9fNtqj",
    "colab_type": "text"
   },
   "source": [
    "#Sklearn multilayer perceptron regressor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FnLl1-3LJy3z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "#print(kf)\n",
    "df_x = dataset[dataset.columns[2:len(dataset.columns)-1-4]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = dataset[dataset.columns[len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model=  MLPRegressor()\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  print(df_x[test_index])\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(un_norm(predict,maxi,mini) ) )\n",
    "  print(\"Ground truth = \" + str(un_norm(df_y[test_index],maxi,mini) ))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14w1_7g6YsJh",
    "colab_type": "text"
   },
   "source": [
    "# Gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V7wpt5yVLIzs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#print(kf)\n",
    "df_x = dataset[dataset.columns[2:len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = dataset[dataset.columns[len(dataset.columns)-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model=  GradientBoostingRegressor(loss=\"ls\",learning_rate=0.5,n_estimators=10000)\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  #print(df_x[test_index])\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(predict) )\n",
    "  print(\"Ground truth = \" + str(df_y[test_index]))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zu3GSTPcO3Ki",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Annotation file reading\n",
    "csv_file_bis = pd.read_csv(\"/content/annotations_challenge_sid.csv\", sep=\"\\t\" )\n",
    "\n",
    "# keep only lines that contains a number different from -1\n",
    "only_commented = []\n",
    "for index, row in csv_file.iterrows():\n",
    "    if row[\"il08_09\"] != -1 or row[\"vg04_05\"] != -1 \\\n",
    "            or row[\"fd03_04\"] != -1 or row[\"la09_10\"] != -1 \\\n",
    "        or row[\"cg13_14\"] != -1 or row[\"mb00_12\"] != -1 :\n",
    "        only_commented.append(row)\n",
    "# Transform it into a DataFrame\n",
    "only_commented_bis = pd.DataFrame(only_commented)\n",
    "print(csv_file_bis[csv_file_bis[csv_file_bis.columns[2:]]!=-1].describe())\n",
    "\n",
    "print(csv_file_bis[csv_file_bis[csv_file_bis[csv_file_bis.columns[2:]]!=-1]==50].describe())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QXM_NR0bPEmB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgWzvTvKHJzi",
    "colab_type": "text"
   },
   "source": [
    "# Weighted least square \n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5917244/\n",
    "Moralement : on veut pouvoir réaliser une régression sur des choses non objectives (la perception de la difficulté par un humain), on utilise les outils qui ont été utilisés pour mesurer la notion de difficulté dans les émotions.\n",
    "\n",
    "\n",
    "Selon Wikipédia : \"weighted linear regression is a generalization of ordinary least squares and linear regression in which the errors covariance matrix is allowed to be different from an identity matrix. \""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mIXsrP9BHhGP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import statsmodels.api as sm\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vmrlPpHrH3RR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "(difficulté texte + (1-difficulté audio)* difficulté texte) / 2   "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gJOUDcLtIOPj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9bj6IW_OV8C",
    "colab_type": "text"
   },
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iRp1c_oVOXuH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "features = [ 'nb_sentence', 'len_sentence', 'cplx_words',\n",
    "       'syll_sec', 'different_words']\n",
    "\n",
    "df_x = dataset[features].to_numpy()\n",
    "X = df_x\n",
    "y = df_y\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)\n",
    "#un_norm(clf.predict(X),maxi,mini)\n",
    "\n",
    "print(X)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZzYa39VsPHRm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "un_norm(y,maxi,mini)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mNtzXj76PTOY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "un_norm(clf.predict(np.array([100,100,100,100,100]).reshape(1,-1)),maxi,mini)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fww8GW-5P18X",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "updated_csv.columns[2:]\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zcinGYx5oIV",
    "colab_type": "text"
   },
   "source": [
    "## Passage Full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6IAdcKYZ5quz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "\n",
    "def get_dataset(csv_file):\n",
    "  names = csv_file.columns[2:]\n",
    "  dataset=[]\n",
    "  for index,row in csv_file.iterrows():\n",
    "    if any(row[names]!=-1):\n",
    "      dataset.append(row)\n",
    "  return pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "def normalisation_annot(df):\n",
    "    name = df.columns[2:]\n",
    "    #fig, ax = plt.subplots(6, 1, figsize=(9, 16), sharex=True)\n",
    "    ret_df = df[df[name]!=-1]\n",
    "    max_list = []\n",
    "    min_list = []\n",
    "    for i, annot in enumerate(ret_df[name]):\n",
    "      #test[test[annotateur]!=-1][annotateur]\n",
    "        #  ((only_commented_nan[annot]-only_commented_nan[annot].mean() )/only_commented_nan[annot].std()).hist()\n",
    "        ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
    "        max_list.append(ret_df[annot].max())\n",
    "        min_list.append(ret_df[annot].min())\n",
    "    return  ret_df, max_list, min_list \n",
    "\n",
    "\n",
    "\n",
    "# Annotation file reading\n",
    "csv_file = pd.read_csv(\"/content/annotations_challenge_sid.csv\", sep=\"\\t\" )\n",
    "\n",
    "\n",
    "norm_text = get_medium_from_normalised(\"100\",norm,csv_file)\n",
    "#print(csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"])\n",
    "#print(norm_text)  \n",
    "df_code_doc =csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"]\n",
    "\n",
    "df_code_doc=df_code_doc.map(lambda x : x.split(\"_\")[0]+\"_\"+x.split(\"_\")[1]+\".xml\")\n",
    "\n",
    "\n",
    "df_code_annot = pd.concat([df_code_doc,norm_text[norm_text.columns[2:]]], axis=1)\n",
    "#print(df_code_annot)\n",
    "#df_code_annot[\"code_doc\"] = df_code_annot[\"code_doc\"].map(lambda x : x[:6] + \".xml\")\n",
    "\n",
    "df_mean = df_code_annot[df_code_annot.columns[1:]].mean(axis=1)\n",
    "#print(df_code_annot)\n",
    "df_code_mean = pd.concat([df_code_annot[df_code_annot.columns[0]], df_mean], axis=1)\n",
    "#print(df_code_mean)\n",
    "\n",
    "#print(df_code_mean)\n",
    "#pattern = re.compile(\"[1-9]{1,3}_[1-9]{1,3}_100_[0-1]\")\n",
    "#list_doc = np.array([])\n",
    "#for i in csv_file[\"code_doc\"]:\n",
    "#  if pattern.match(i):\n",
    "#    print(i)\n",
    "#    list_doc = np.append(list_doc, i)\n",
    "#csv_file[csv_file[\"code_doc\"]==list_doc]\n",
    "\n",
    "#print(norm_text[norm_text.columns[2:]].mean(axis=1))\n",
    "#print(csv_file[csv_file.index.isin( y_set.index)])\n",
    "\n",
    "\n",
    "norm_text = get_medium_from_normalised(\"100\",norm,csv_file)\n",
    "#print(csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"])pre training neural network for complexity scoring\n",
    "#print(norm_text)  \n",
    "#df_code_doc =csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"]\n",
    "coucou = pd.concat([csv_file[csv_file.index.isin(norm_text.index)][\"code_doc\"],norm_text[norm_text.columns[2:]]], axis=1)\n",
    "#print(coucou)\n",
    "#coucou.to_csv(\"norm_text_commented.csv\")\n",
    "#print(norm_text.shape)\n",
    "#print(file_list)\n",
    "norm_text = norm_text[norm_text.columns]\n",
    "#print(norm_text)\n",
    "#On prend le max\n",
    "norm_text=norm_text.mean(axis=1)\n",
    "################################## TESTER LA MEDIANE / LA MOYENNE\n",
    "#print(norm_text)\n",
    "y_set = norm_text\n",
    "#print(file_list)\n",
    "#print(y_set[y_set.columns[2:]].mean(axis=1))\n",
    "#print(y_set.shape)\n",
    "#print(DF_aggreg)\n",
    "#df_code_doc = df_code_doc.map(lambda x: re.search(\"[1-9]{1,3}_[1-9]{1,3}\",x)[0]+\".xml\")\n",
    "#print(df_code_doc)\n",
    "#print(DF_aggreg[\"doc\"])\n",
    "#print(df_code_doc)\n",
    "x_set = DF_aggreg[DF_aggreg[\"doc\"].isin(df_code_doc)]\n",
    "x_set=x_set[x_set.columns]\n",
    "x_set = x_set.rename(columns={\"doc\":\"code_doc\"})\n",
    "#print(x_set)\n",
    "#print(x_set)\n",
    "#for annot in norm.columns[2:]:\n",
    "#    print(norm[np.isfinite(norm[annot])][annot])Project-Archean\n",
    "#def get_medium_from_normalised(norm,csv_file):\n",
    " # return norm[norm[ norm.columns[0]].index.isin( get_medium(\"101\",csv_file).index)]\n",
    "\n",
    "\n",
    "# FAIRE UNE FONCTION POUR TOUT CA"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H4waZJH77Yg2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dataset_upd = get_dataset(updated_csv)\n",
    "dataset_upd_nan =dataset_upd.replace(-1,np.nan)  \n",
    "dataset_upd_nan.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9uUUM9HZBQTp",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dataset_upd[dataset_upd[dataset_upd.columns[2:]]==50].describe()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C4DneECeBi9U",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "norm_dataset_upd,_,_ = normalisation_annot(dataset_upd)\n",
    "def plot_hist(norm_df):\n",
    "  names = norm_df.columns[2:]\n",
    "  for annot in names:\n",
    "    norm_df[annot].hist()\n",
    "plot_hist(norm_dataset_upd)\n",
    "norm_dataset_upd.to_csv(\"label_normalised.csv\")\n",
    "#norm_.to_csv(\"label_normalised.csv\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f76-alFaF7VX",
    "colab_type": "text"
   },
   "source": [
    "Cela semble ne pas être de distribution normale !"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c7CqkeUoF6II",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "nb_pers = pd.read_csv(\"df_nb_pers.csv\")\n",
    "#nb_pers.sort_values(\"Unnamed: 0\")\n",
    "nb_pers"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qri3jdF9CNJZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "nb_scene = pd.read_csv(\"feat_scene_breaks.csv\")\n",
    "nb_scene.sort_values(\"Unnamed: 0\")\n",
    "nb_pers = nb_pers.rename(columns={\"code_doc\":\"Unnamed: 0\"})"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ITOAy7mXu0xX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "nb_pers"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX3yznsyR4z1",
    "colab_type": "text"
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BqcvPmOyWSvH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "video = pd.merge(nb_pers,nb_scene , on=\"Unnamed: 0\")\n",
    "video = video.rename(columns={\"Unnamed: 0\":\"code_doc\"})"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vYBTdcCNkeZw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "audio = df_features = pd.read_csv('audio_features.csv', sep='§', engine='python', index_col=0, encoding='utf-8')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ITcnAxZd1Eev",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "audio = audio.rename(columns={\"SCENE\":\"code_doc\"})\n",
    "names = ['code_doc', 'SR', 'SNR', 'SCORE']\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H31eMB-d12CP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "audio = audio[names]\n",
    "audio"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jBK7wvwY27WI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "video"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeNqCLLN3d_r",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "audio_video = pd.merge(audio , video ,on=\"code_doc\")\n",
    "audio_video"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TSMCIbo13uie",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "texte = pd.read_csv(\"DF_aggreg.csv\")\n",
    "texte = texte.rename(columns={\"doc\":\"code_doc\"})\n",
    "texte[\"code_doc\"] = texte[\"code_doc\"].map(lambda x : x[:-4])\n",
    "texte"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cbt2W2_v4G2n",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "audio_video_texte = pd.merge(audio_video, texte[texte.columns[1:]] ,on=\"code_doc\")\n",
    "audio_video_texte"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pwp7HzKz4iSA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "data = get_dataset(updated_csv)\n",
    "\n",
    "#dataset_upd[\"code_doc\"] = dataset_upd[\"code_doc\"].map(lambda x : x) \n",
    "data[\"code_doc\"] = data[\"code_doc\"].map(lambda x : x[:-6])\n",
    "#data = pd.DataFrame(data.mean(axis=1))\n",
    "data = data.replace(-1,np.nan)\n",
    "data[\"label\"]=data[data.columns[2:]].mean(axis=1)\n",
    "\n",
    "labels = data[[data.columns[1] , data.columns[len(data.columns)-1]]]\n",
    "\n",
    "labels_median = pd.DataFrame(labels.groupby(\"code_doc\").median())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lSX0gU2cFODO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "data = get_dataset(updated_csv)\n",
    "\n",
    "#dataset_upd[\"code_doc\"] = dataset_upd[\"code_doc\"].map(lambda x : x) \n",
    "data[\"code_doc\"] = data[\"code_doc\"].map(lambda x : x)\n",
    "#data = pd.DataFrame(data.mean(axis=1))\n",
    "data = data.replace(-1,np.nan)\n",
    "print(data)\n",
    "data_norm,maxi,mini= normalisation_annot(data)\n",
    "maxi = np.array(maxi).mean()\n",
    "mini = np.array(mini).mean()\n",
    "for annot in data_norm.columns[2:]:\n",
    "  data_norm[annot].hist()\n",
    "#data_norm.hist()\n",
    "#norm[norm.columns[2:]]\n",
    "data_norm[\"code_doc\"] = data[\"code_doc\"]\n",
    "data_norm.to_csv(\"label_normalised_moncoucou.csv\")\n",
    "data_norm[\"label\"]= data_norm[data_norm.columns[2:]].mean(axis=1)\n",
    "\n",
    "print(data_norm)\n",
    "#data_norm.to_csv(\"label_normalised.csv\")\n",
    "\n",
    "labels = pd.merge(data[\"code_doc\"], data_norm[\"label\"], left_index=True, right_index=True)\n",
    "\n",
    "print(labels)\n",
    "labels.to_csv(\"label_normalised.csv\")\n",
    "#labels_median = pd.DataFrame(labels.groupby(\"code_doc\").median())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Eli5Mr5h44Tr",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "full_data = pd.merge(audio_video_texte,labels,on=\"code_doc\")\n",
    "full_data\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lWGBBDuG9a4H",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "full_data_med = pd.merge(audio_video_texte,labels_median,on=\"code_doc\")\n",
    "full_data_med "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tGg1cjC4-HZp",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "full_data.columns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aB4xs4yT9uF4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "full_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(kf)\n",
    "df_x = full_data[full_data.columns[1:-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = full_data[dataset.columns[-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model= linear_model.Lasso()\n",
    "  #print(df_x.shape)\n",
    "  #print(df_y.shape)\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" +  str(un_norm(predict,maxi,mini) ) )\n",
    "  print(\"Ground truth = \" +  str(un_norm(df_y[test_index],maxi,mini) ))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "okoeXGod-Gym",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "full_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(kf)\n",
    "df_x = full_data_med[full_data.columns[1:-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = full_data_med[dataset.columns[-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = 0\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model= linear_model.Lasso(alpha=0.1)\n",
    "  #print(df_x.shape)\n",
    "  #print(df_y.shape)\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "\n",
    "  score = model.score(df_x[test_index], df_y[test_index])\n",
    "  aux += score\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(predict ) )\n",
    "  print(\"Ground truth = \" + str(df_y[test_index]))\n",
    "print(\"Score moyen : \" + str(float(aux/nb_split)))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-2ByDiEPAAd8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def get_network_full(nb_features):\n",
    "  model = Sequential()\n",
    " # model.add(Conv1D(4, int(nb_features[0]/2),input_shape=(nb_features[1], nb_features[2]), strides=1, padding='valid', dilation_rate=1, activation=None, \n",
    "  #                              use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', data_format=\"channels_first\",\n",
    "   #                             kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "  model.add(Dense(32, input_shape=(nb_features,), activation=\"relu\"))\n",
    "  model.add(Dropout(0.5))\n",
    "  #model.add(GaussianNoise(0.1))\n",
    "  model.add(Dense(16, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  model.add(Dense(8, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  model.add(Dense(4, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  \n",
    "  #model.add(Dense(nb_features, activation='relu'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Dense(2, activation='relu',kernel_regularizer=regularizers.l2(0.01) ))\n",
    "  #model.add(Dropout(0.25))\n",
    "  #model.add(Flatten())\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  adam = Adam(lr=0.0001)\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "  return model\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5KYRLnLIBDdn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "full_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(kf)\n",
    "df_x = full_data_med[full_data.columns[1:-1]].to_numpy()\n",
    "#print(df_x)\n",
    "df_y = full_data_med[dataset.columns[-1]].to_numpy()\n",
    "#print(df_y)\n",
    "nb_split=10\n",
    "print(df_x.shape)\n",
    "kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
    "aux = [0,0]\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  model= get_network_full(df_x.shape[1])\n",
    "  #print(df_x.shape)\n",
    "  #print(df_y.shape)\n",
    "  model.fit(df_x[train_index], df_y[train_index])\n",
    "  model.fit(df_x[train_index], df_y[train_index], validation_data=(df_x[test_index], df_y[test_index]),epochs=300\n",
    "            , verbose = 0, callbacks=[EarlyStopping(verbose=1,patience = 10)])\n",
    "  score = model.evaluate(df_x[test_index], df_y[test_index])\n",
    "\n",
    "  aux[0] += score[0]\n",
    "  aux[1] += score[1]\n",
    "  print(\"Final score : \" +str(score) )\n",
    "  predict = model.predict(df_x[test_index])\n",
    "  print(\"Pred = \" + str(predict ) )\n",
    "  print(\"Ground truth = \" + str(df_y[test_index]))\n",
    "print(\"Score moyen : \" + str(float(aux[0]/nb_split) +\" \"+ str(aux[1]/nb_split)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for train_index, test_index in kf.split(df_y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  x = df_x_norm[train_index]\n",
    "  #x= np.reshape(x,(1,x.shape[0], x.shape[1]))\n",
    "  #x = np.expand_dims(x, axis=0)\n",
    "  print(x.shape)\n",
    "  model=get_network(x.shape[1])\n",
    "  model.fit(x, df_y[train_index], validation_data=(x[test_index], df_y[test_index]),epochs=300\n",
    "            , verbose = 0, callbacks=[EarlyStopping(verbose=1,patience = 10)])\n",
    "  score = model.evaluate(df_x_norm[test_index], df_y[test_index])\n",
    "\n",
    "  print(\"Final loss : \" +str(score) )\n",
    "  predict = model.predict(x)\n",
    "  print(\"Pred = \" + str(un_norm(predict,maxi,mini) ))\n",
    "  print(\"Ground truth = \" + str(un_norm(df_y,maxi,mini)))\n",
    "  aux[0] += score[0]\n",
    "  aux[1] += score[1]\n",
    "aux = aux / n_splits str(un_norm(predict,maxi,mini) )\n",
    "print(\"Mean loss : \", end=\"\")\n",
    "\n",
    "\n",
    "print(aux)\n",
    "\n",
    "print(model.summary())\n",
    "'''"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fw9Aqds8BeZh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TX83KTgR7fZ",
    "colab_type": "text"
   },
   "source": [
    "Mise en place des modèles de Henry (adaptation des formules de Flesh à la langue française)\n",
    "\n",
    "https://fr.wikipedia.org/wiki/Test_de_lisibilit%C3%A9\n",
    "\n",
    "https://www.persee.fr/doc/colan_0336-1500_1980_num_45_1_1364 : \"Lisibilité et compréhension\" Georges Henry 1980 \n",
    "\n",
    "\n",
    "\n",
    "https://www.academia.edu/237263/Mod%C3%A8les_statistiques_pour_l_estimation_automatique_de_la_difficult%C3%A9_de_textes_de_FLE : Modèles statistiques pour l’estimation automatique de la difﬁculté de textes de FLE \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZpKZBWy-6uPe",
    "colab_type": "code",
    "outputId": "222451c8-578f-435f-b651-525fd886139a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    }
   },
   "source": [
    "new_text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
    "new_text_feat.iloc[129]"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0              129\n",
       "doc                   217_2\n",
       "nb_sentence         18.9474\n",
       "len_sentence            8.5\n",
       "cplx_words            0.725\n",
       "syll_100            148.427\n",
       "different_words    0.784314\n",
       "topic                  0.75\n",
       "Name: 129, dtype: object"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "scecTgaTnq2q",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "def human_interest():\n",
    "  return None\n",
    "\n",
    "def facilite_lect(nb_mot_phrase, nb_syll_mot):\n",
    "  '''\n",
    "  Implementation of Rudolf Flesh from an article of André Conquet and François \n",
    "  Richaudeau : \"Cinq méthodes de lisibilité\"\n",
    "  https://www.persee.fr/doc/colan_0336-1500_1973_num_17_1_3978#colan_0336-1500_1973_num_17_1_T1_0014_0000\n",
    "  param: \n",
    "  '''\n",
    "  return   206.835 -(nb_mot_phrase*1.815 + nb_syll_mot * 0.846) \n",
    "\n",
    "\n",
    "\n",
    "def score_doc(facilite_text, reco_audio=None, feat_vid=None):\n",
    "  '''\n",
    "  We assume that the complexity of a document is a combination of the text\n",
    "  complexity and the audio comprehensibility\n",
    "  Weights have to be learned to be accurate \n",
    "  '''\n",
    "  if reco_audio is None and feat_vid is None:\n",
    "    return facilite_text\n",
    "  if feat_vid is None :\n",
    "    return (0.7*facilite_text + 0.3*reco_audio )\n",
    "  vid = []\n",
    "  for i in feat_vid[\"scene_br_per_min\"]:\n",
    "    if i > 15:\n",
    "      vid.append(-5)\n",
    "    else:\n",
    "      vid.append(5)\n",
    "  #vid = pd.DataFrame(vid)\n",
    "  print(vid)\n",
    "  aux = 0.7*facilite_text + 0.3*reco_audio \n",
    "  for index, row in enumerate(aux):\n",
    "    aux[index] += vid[index]\n",
    "  return aux    \n",
    "  #return (0.7*facilite_text + 0.3*reco_audio + vid)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UGaritOFF8vS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tt4NvrgIto-l",
    "colab_type": "code",
    "outputId": "c80c693c-c731-41bf-cb47-ddb9160cb1a9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    }
   },
   "source": [
    "score_text = 100-facilite_lect(new_text_feat[\"len_sentence\"],new_text_feat[\"syll_100\"])\n",
    "score_text"
   ],
   "execution_count": 252,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      29.260867\n",
       "1      31.057720\n",
       "2      23.773652\n",
       "3      28.968902\n",
       "4      33.154229\n",
       "         ...    \n",
       "295    53.142921\n",
       "296    35.072699\n",
       "297    40.208294\n",
       "298    28.855719\n",
       "299    18.693436\n",
       "Length: 300, dtype: float64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 252
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LKkOfmao7RGB",
    "colab_type": "code",
    "outputId": "e66672c6-3bb6-4cb7-87f1-74492081dd26",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    }
   },
   "source": [
    "audio_feat = pd.read_csv(\"silence_rolling_mean.csv\", sep='§', engine='python', index_col=0, encoding='utf-8')\n",
    "# SCORE = Score mots non reconnus \n",
    "# 1 - score = score de mots reconnus \n",
    "audio_feat[\"SCORE\"] = (1-audio_feat[\"SCORE\"])*100\n",
    "audio_feat.hist()"
   ],
   "execution_count": 253,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc399b5a2e8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc3987462b0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc398714400>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc3986c2550>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc39866f6a0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc39869f7f0>]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 253
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nCw6tuKEBYmd",
    "colab_type": "code",
    "outputId": "ef7f9f97-5510-4e2a-a71f-cb26038b56d1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    }
   },
   "source": [
    "audio_feat.sort_values(\"SCORE\")"
   ],
   "execution_count": 254,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>SR</th>\n",
       "      <th>SNR</th>\n",
       "      <th>VBR</th>\n",
       "      <th>CONF</th>\n",
       "      <th>RECON</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>XML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1_13</td>\n",
       "      <td>0.623838</td>\n",
       "      <td>0.985466</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Ecoutez tout est en ordre madame Verneuil Vous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>126_13</td>\n",
       "      <td>0.661074</td>\n",
       "      <td>0.899894</td>\n",
       "      <td>0.626972</td>\n",
       "      <td>0.840429</td>\n",
       "      <td>mériter mieux beaucoup mieux brillante</td>\n",
       "      <td>6.070288</td>\n",
       "      <td>Jamais vu des gens aussi susceptibles C est pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>273_6</td>\n",
       "      <td>0.910039</td>\n",
       "      <td>0.957663</td>\n",
       "      <td>0.955634</td>\n",
       "      <td>0.862469</td>\n",
       "      <td>une recette en verre comment ton accord</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>Une recette en vers Ecoutez mes amis Oui oui n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>182_7</td>\n",
       "      <td>0.781410</td>\n",
       "      <td>0.996930</td>\n",
       "      <td>0.787405</td>\n",
       "      <td>0.853276</td>\n",
       "      <td>mets-moi combien acquisition Générale voulez-v...</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>J en ai marre Marre Marre Marre Ouvrez Ou j en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>178_11</td>\n",
       "      <td>0.398430</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.607258</td>\n",
       "      <td>0.869899</td>\n",
       "      <td>tu es très mignonne si j'arrive</td>\n",
       "      <td>8.923077</td>\n",
       "      <td>Vous avez mis le temps Elle était très mignonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>249_15</td>\n",
       "      <td>0.722198</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.971404</td>\n",
       "      <td>0.918842</td>\n",
       "      <td>je suivais les cours du soir Sexion photos à l...</td>\n",
       "      <td>85.579937</td>\n",
       "      <td>J ai suivi les cours du soir section photo à l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>205_9</td>\n",
       "      <td>0.878761</td>\n",
       "      <td>0.990992</td>\n",
       "      <td>0.929047</td>\n",
       "      <td>0.903994</td>\n",
       "      <td>mon frère Paul était à présent un petit bonhom...</td>\n",
       "      <td>87.257019</td>\n",
       "      <td>Mon frère Paul était à présent un petit bonhom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>267_15</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.999682</td>\n",
       "      <td>0.962893</td>\n",
       "      <td>0.898685</td>\n",
       "      <td>je connaissais peu de garçon j'étais tendu sec...</td>\n",
       "      <td>88.220551</td>\n",
       "      <td>Je connaissais peu de garçons J étais tendue s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>184_15</td>\n",
       "      <td>0.655932</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.952869</td>\n",
       "      <td>0.889372</td>\n",
       "      <td>j'ai 27 ans la première projection de mon prem...</td>\n",
       "      <td>89.571695</td>\n",
       "      <td>J ai vingt sept ans C est la première projecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2_4</td>\n",
       "      <td>0.619707</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.904679</td>\n",
       "      <td>j'ai compris que je n'arriverai jamais à les c...</td>\n",
       "      <td>90.476190</td>\n",
       "      <td>J ai compris que je n arriverai jamais à les c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SCENE  ...                                                XML\n",
       "129    1_13  ...  Ecoutez tout est en ordre madame Verneuil Vous...\n",
       "58   126_13  ...  Jamais vu des gens aussi susceptibles C est pa...\n",
       "202   273_6  ...  Une recette en vers Ecoutez mes amis Oui oui n...\n",
       "114   182_7  ...  J en ai marre Marre Marre Marre Ouvrez Ou j en...\n",
       "110  178_11  ...  Vous avez mis le temps Elle était très mignonn...\n",
       "..      ...  ...                                                ...\n",
       "177  249_15  ...  J ai suivi les cours du soir section photo à l...\n",
       "135   205_9  ...  Mon frère Paul était à présent un petit bonhom...\n",
       "196  267_15  ...  Je connaissais peu de garçons J étais tendue s...\n",
       "116  184_15  ...  J ai vingt sept ans C est la première projecti...\n",
       "26      2_4  ...  J ai compris que je n arriverai jamais à les c...\n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 254
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FeVVuA7U8s1B",
    "colab_type": "code",
    "outputId": "33cf4ce6-4d07-4be3-e908-c2449c9b23a7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    }
   },
   "source": [
    "score = score_doc(score_text,audio_feat[\"SCORE\"])\n",
    "score = pd.DataFrame(score)\n",
    "score = score.rename(columns={0:\"complex_score\"})\n",
    "\n",
    "score = pd.merge(new_text_feat[\"doc\"],score,left_index=True, right_index=True)\n",
    "score.sort_values(\"complex_score\")"
   ],
   "execution_count": 255,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>complex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>140_15</td>\n",
       "      <td>12.463345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>283_14</td>\n",
       "      <td>16.238798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>186_2</td>\n",
       "      <td>16.645223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>6_3</td>\n",
       "      <td>17.926852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1_13</td>\n",
       "      <td>19.925716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>238_13</td>\n",
       "      <td>53.965712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>291_8</td>\n",
       "      <td>55.385589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>150_15</td>\n",
       "      <td>55.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>276_11</td>\n",
       "      <td>57.123316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>295_15</td>\n",
       "      <td>58.541785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc  complex_score\n",
       "44   140_15      12.463345\n",
       "202  283_14      16.238798\n",
       "94    186_2      16.645223\n",
       "266     6_3      17.926852\n",
       "110    1_13      19.925716\n",
       "..      ...            ...\n",
       "152  238_13      53.965712\n",
       "211   291_8      55.385589\n",
       "55   150_15      55.906365\n",
       "194  276_11      57.123316\n",
       "215  295_15      58.541785\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 255
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nObX05F-9wJP",
    "colab_type": "code",
    "outputId": "6a685567-0039-4023-db67-73d2e3f55d67",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    }
   },
   "source": [
    "score.sort_values(\"complex_score\")"
   ],
   "execution_count": 256,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>complex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>140_15</td>\n",
       "      <td>12.463345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>283_14</td>\n",
       "      <td>16.238798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>186_2</td>\n",
       "      <td>16.645223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>6_3</td>\n",
       "      <td>17.926852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1_13</td>\n",
       "      <td>19.925716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>238_13</td>\n",
       "      <td>53.965712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>291_8</td>\n",
       "      <td>55.385589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>150_15</td>\n",
       "      <td>55.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>276_11</td>\n",
       "      <td>57.123316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>295_15</td>\n",
       "      <td>58.541785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc  complex_score\n",
       "44   140_15      12.463345\n",
       "202  283_14      16.238798\n",
       "94    186_2      16.645223\n",
       "266     6_3      17.926852\n",
       "110    1_13      19.925716\n",
       "..      ...            ...\n",
       "152  238_13      53.965712\n",
       "211   291_8      55.385589\n",
       "55   150_15      55.906365\n",
       "194  276_11      57.123316\n",
       "215  295_15      58.541785\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 256
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5TMoh8KCAjjP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "outputId": "858e3eb6-d725-4550-b577-2faa61e440f7"
   },
   "source": [
    "\n",
    "def get_dataset(csv_file):\n",
    "  names = csv_file.columns[2:]\n",
    "  dataset=[]\n",
    "  for index,row in csv_file.iterrows():\n",
    "    if any(row[names]!=-1):\n",
    "      dataset.append(row)\n",
    "  return pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "data = get_dataset(updated_csv)\n",
    "data_bis = pd.DataFrame()\n",
    "\n",
    "data_bis[\"code_doc\"]=data[\"code_doc\"].map(lambda x : x[:-6])\n",
    "data = data.replace(-1,np.nan)\n",
    "data_bis[\"label\"]=data[data.columns[2:]].median(axis=1)\n",
    "#data_bis[\"label\"] = data_bis[\"label\"].replace(-1,np.NaN)\n",
    "#print(data[data.columns[2:]])\n",
    "#print(score)\n",
    "print(data_bis)\n",
    "data[\"code_doc\"] = data[\"code_doc\"].map(lambda x : x[:-6])\n",
    "data_bis = pd.merge(data_bis, score, left_on=\"code_doc\", right_on=\"doc\")\n",
    "data_bis"
   ],
   "execution_count": 271,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "     code_doc  label\n",
      "5        57_6   88.0\n",
      "6        57_6  100.0\n",
      "7        57_6   88.0\n",
      "8        57_6   87.0\n",
      "9        57_6  100.0\n",
      "...       ...    ...\n",
      "1430    256_1   78.0\n",
      "1431    256_1   58.0\n",
      "1432    256_1   57.0\n",
      "1433    256_1   50.0\n",
      "1434    256_1   67.0\n",
      "\n",
      "[241 rows x 2 columns]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_doc</th>\n",
       "      <th>label</th>\n",
       "      <th>doc</th>\n",
       "      <th>complex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57_6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>32.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57_6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>32.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57_6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>32.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57_6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>32.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57_6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>32.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>256_1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>29.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>256_1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>29.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>256_1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>29.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>256_1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>29.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>256_1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>29.059389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code_doc  label    doc  complex_score\n",
       "0       57_6   88.0   57_6      32.437127\n",
       "1       57_6  100.0   57_6      32.437127\n",
       "2       57_6   88.0   57_6      32.437127\n",
       "3       57_6   87.0   57_6      32.437127\n",
       "4       57_6  100.0   57_6      32.437127\n",
       "..       ...    ...    ...            ...\n",
       "236    256_1   78.0  256_1      29.059389\n",
       "237    256_1   58.0  256_1      29.059389\n",
       "238    256_1   57.0  256_1      29.059389\n",
       "239    256_1   50.0  256_1      29.059389\n",
       "240    256_1   67.0  256_1      29.059389\n",
       "\n",
       "[241 rows x 4 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 271
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4TGwKzyFwgH3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "71e4b3f2-1b97-40df-d8c9-0b07332cab35"
   },
   "source": [
    "def dist_label(df_score):\n",
    "  aux = 0\n",
    "  last_ind = 0\n",
    "  for index, row in df_score.iterrows():\n",
    "    aux += abs(row['label']-row['complex_score'])\n",
    "    last_ind = index\n",
    "  aux/=(last_ind+1)\n",
    "  print(aux)\n",
    "    #print(abs(i[\"label\"] - i[\"complex_score\"]))\n",
    "    #print(i)\n",
    "dist_label(data_bis)\n"
   ],
   "execution_count": 258,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "25.274034366170202\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9q9hTihpy5Dh",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "de531e53-8130-40dd-e62f-73e7dbc95a46"
   },
   "source": [
    "video= pd.read_csv(\"feat_break.csv\")\n",
    "video.describe()\n",
    "#Scene_br_per_min\n",
    "print(video.columns)"
   ],
   "execution_count": 272,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'env_br_per_min', 'scene_br_per_min'], dtype='object')\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-tX5kG030b2m",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "outputId": "94c6dac8-5928-4ffb-b372-1fe453fd4925"
   },
   "source": [
    "score = score_doc(score_text,audio_feat[\"SCORE\"],video)\n",
    "score = pd.DataFrame(score)\n",
    "print(score)\n",
    "score = score.rename(columns={0:\"complex_score\"})\n",
    "\n",
    "score = pd.merge(new_text_feat[\"doc\"],score,left_index=True, right_index=True)\n",
    "score.sort_values(\"complex_score\")"
   ],
   "execution_count": 284,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[-5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, -5, 5, 5, 5, -5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, -5, 5, -5, -5, -5, 5, 5, -5, 5, 5, 5, -5, 5, 5, 5, -5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, -5, 5, 5, 5, 5, 5, 5, 5, -5, -5, -5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, -5, -5, -5, -5, 5, 5, 5, 5, -5, 5, 5, -5, 5, 5, -5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, -5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, -5, 5, 5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, 5, -5, 5, -5, 5, 5, 5, -5, 5, -5, 5, 5, 5, 5, 5, -5, -5, -5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, -5, -5, 5, 5, 5, 5, 5, 5, 5, -5, 5, 5, 5, 5, 5, -5, 5, 5]\n",
      "             0\n",
      "0    28.316659\n",
      "1    32.026020\n",
      "2    35.746360\n",
      "3    39.885561\n",
      "4    39.819072\n",
      "..         ...\n",
      "295  45.210078\n",
      "296  50.135768\n",
      "297  29.878089\n",
      "298  40.684833\n",
      "299  26.940186\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>complex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1_13</td>\n",
       "      <td>14.925716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>53_13</td>\n",
       "      <td>16.507219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>140_15</td>\n",
       "      <td>17.463345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>191_4</td>\n",
       "      <td>18.135326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>217_2</td>\n",
       "      <td>18.913418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>174_9</td>\n",
       "      <td>58.863985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>291_8</td>\n",
       "      <td>60.385589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>150_15</td>\n",
       "      <td>60.906365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>276_11</td>\n",
       "      <td>62.123316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>295_15</td>\n",
       "      <td>63.541785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc  complex_score\n",
       "110    1_13      14.925716\n",
       "248   53_13      16.507219\n",
       "44   140_15      17.463345\n",
       "100   191_4      18.135326\n",
       "129   217_2      18.913418\n",
       "..      ...            ...\n",
       "81    174_9      58.863985\n",
       "211   291_8      60.385589\n",
       "55   150_15      60.906365\n",
       "194  276_11      62.123316\n",
       "215  295_15      63.541785\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 284
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZD5SdpHBD4DN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "outputId": "f60ff38c-1369-4929-ed2c-685a11de1c67"
   },
   "source": [
    "\n",
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "data = get_dataset(updated_csv)\n",
    "data_bis = pd.DataFrame()\n",
    "\n",
    "data_bis[\"code_doc\"]=data[\"code_doc\"].map(lambda x : x[:-6])\n",
    "data = data.replace(-1,np.nan)\n",
    "data_bis[\"label\"]=data[data.columns[2:]].median(axis=1)\n",
    "#data_bis[\"label\"] = data_bis[\"label\"].replace(-1,np.NaN)\n",
    "#print(data[data.columns[2:]])\n",
    "#print(score)\n",
    "print(data_bis)\n",
    "data[\"code_doc\"] = data[\"code_doc\"].map(lambda x : x[:-6])\n",
    "data_bis = pd.merge(data_bis, score[score.columns[:2]], left_on=\"code_doc\", right_on=\"doc\")\n",
    "data_bis"
   ],
   "execution_count": 285,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "     code_doc  label\n",
      "5        57_6   88.0\n",
      "6        57_6  100.0\n",
      "7        57_6   88.0\n",
      "8        57_6   87.0\n",
      "9        57_6  100.0\n",
      "...       ...    ...\n",
      "1430    256_1   78.0\n",
      "1431    256_1   58.0\n",
      "1432    256_1   57.0\n",
      "1433    256_1   50.0\n",
      "1434    256_1   67.0\n",
      "\n",
      "[241 rows x 2 columns]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_doc</th>\n",
       "      <th>label</th>\n",
       "      <th>doc</th>\n",
       "      <th>complex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57_6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>37.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57_6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>37.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57_6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>37.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57_6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>37.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57_6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>57_6</td>\n",
       "      <td>37.437127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>256_1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>34.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>256_1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>34.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>256_1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>34.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>256_1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>34.059389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>256_1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>256_1</td>\n",
       "      <td>34.059389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code_doc  label    doc  complex_score\n",
       "0       57_6   88.0   57_6      37.437127\n",
       "1       57_6  100.0   57_6      37.437127\n",
       "2       57_6   88.0   57_6      37.437127\n",
       "3       57_6   87.0   57_6      37.437127\n",
       "4       57_6  100.0   57_6      37.437127\n",
       "..       ...    ...    ...            ...\n",
       "236    256_1   78.0  256_1      34.059389\n",
       "237    256_1   58.0  256_1      34.059389\n",
       "238    256_1   57.0  256_1      34.059389\n",
       "239    256_1   50.0  256_1      34.059389\n",
       "240    256_1   67.0  256_1      34.059389\n",
       "\n",
       "[241 rows x 4 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 285
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cyJJTH2kHTyG",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "f282d88e-4bcd-41c9-85d4-5c536a7130ba"
   },
   "source": [
    "\n",
    "dist_label(data_bis)\n"
   ],
   "execution_count": 286,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "23.28790687344402\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0bUSWIDMIOee",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}