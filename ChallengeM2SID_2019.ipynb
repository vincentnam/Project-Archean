{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ChallengeM2SID_2019 (2).ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OS setup\n",
    "!rm -rf challenge-m2-sid/\n",
    "!cat /etc/os-release\n",
    "!apt-get install -qq bc tree sox\n",
    "\n",
    "# Liaison avec les donnÃ©es\n",
    "#!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import GaussianNoise,BatchNormalization, Conv1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re  \n",
    "from google.colab import drive\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "from google.colab import files\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Longer comment on the function\n",
    "    Parameters:\n",
    "        :param input1: The first number to add \n",
    "        :param input2: The second number to add\n",
    "        :param input3: The third number to add (Default : None)\n",
    "        :type input1: int\n",
    "        :type input2: int\n",
    "        :type input3: int\n",
    "    \n",
    "    Returns:\n",
    "        answer: the computation of the sum\n",
    "        type : \n",
    "        \n",
    "    Other itema to note:\n",
    "        - This is a comment on something that has to be known\n",
    "        - This is another comment \n",
    "    :Example:\n",
    " \n",
    "        >>> addition(1, 1)\n",
    "        2\n",
    "        >>> add(2.1, 3.4)  # all int compatible types work\n",
    "        5.5\n",
    " \n",
    "        .. seealso:: sub(), div(), mul()\n",
    "        .. warning:: If there is any warnings \n",
    "        .. todo:: \n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Traitements des labels \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Return a part of the dataset with only 1 medium (text, audio, text + audio...)\n",
    "def get_medium(medium, df):\n",
    "  \"\"\"\n",
    "  # Return a subset of informations limited to a communication medium \n",
    "  # (audio : 100 , text : 001, audio and video : 110, audio and text : 101 \n",
    "  # audio, video and text : 111)\n",
    "  Parameters:\n",
    "      :param medium: ID for a medium \n",
    "      :param df: dataset containing \"code_doc\" columns containing \n",
    "      xx_x_medium_x as an document ID\n",
    "      \n",
    "      :type medium: string\n",
    "      :type df: DataFrame (pandas)\n",
    "  \n",
    "  Returns:\n",
    "      medium: the part of the dataset with only the choosen medium\n",
    "      type : DataFrame (pandas)\n",
    "      \n",
    "  :Example:\n",
    "\n",
    "      >>> print(get_medium(\"100\",csv_file))\n",
    " Unnamed: 0      code_doc  il08_09  ...  la09_10  cg13_14  mb00_12\n",
    "5              6    57_6_100_1       -1  ...     -1.0     -1.0       76\n",
    "55            56   147_1_100_1       -1  ...     -1.0     -1.0       64\n",
    "135          136   210_3_100_1       70  ...     -1.0     -1.0       -1\n",
    "        ... \n",
    "  \"\"\"\n",
    "  return (df[df[\"code_doc\"].map(lambda x : x[len(x)-5:-2]==medium)])  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def ret_max_docid(medium, only_commented):\n",
    "  '''\n",
    "\n",
    "  Choose the medium on which return the list of label for each document\n",
    "  Medium is a string : sequence of 3 bits : audio-video-texte sequence\n",
    "  only_commented : Dataframe of each annotated extract (not only extracts\n",
    "  ending with a \"1\")\n",
    "  Mean of multiple label is used when there are differents labels for one\n",
    "  document.\n",
    "  Parameters:\n",
    "      :param medium: ID for a medium \n",
    "      :param df: dataset containing \"code_doc\" columns containing \n",
    "      xx_x_medium_x as an document ID\n",
    "      \n",
    "      :type medium: string\n",
    "      :type df: DataFrame (pandas)\n",
    "  \n",
    "  Returns:\n",
    "      list_labels : couple list of each (document id, label) \n",
    "      type : list (of couple)\n",
    "  :Example:\n",
    "\n",
    "      >>>ret_max_docid(\"101\", only_commented)\n",
    "        [('57_6_101_0', 87.0),\n",
    "         ('88_11_101_1', 34.0),\n",
    "         ('51_5_101_1', 65.0),\n",
    "          ...\n",
    "  '''\n",
    "  # Get the list of annotated extracts for a medium\n",
    "  medium = get_medium(medium, only_commented)\n",
    "  # Replace all -1 by a NaN value  \n",
    "  medium = medium.replace(-1.,np.NaN)\n",
    "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
    "  return [(row[1],row[2:].mean()) for index,row in medium.iterrows() ]\n",
    "  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Annotation file reading\n",
    "\n",
    "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
    "\n",
    "def get_dataset(csv_file):\n",
    "  \"\"\"\n",
    "  Get only the commented row in the annoted csv file. The last digit is \n",
    "  here to know if a row is empty or not but some labels are forgotten. This \n",
    "  function return only row that contains something different from -1.\n",
    "  Parameters:\n",
    "      :param csv_file: DataFrame with all label for each document \n",
    "      :type csv_file : DataFrame (pandas)\n",
    "      \n",
    "  Returns:\n",
    "      dataset: The sub part of the annotation file with only commented \n",
    "      documents\n",
    "      type : DataFrame Pandas\n",
    "      \n",
    "  :Example:\n",
    "\n",
    "      >>> get_dataset(updated_csv)\n",
    "        \\t\tcode_doc\til08_09\tvg04_05\tfd03_04\tla09_10\tcg13_14\tja05_06\tfj11_12\tec20_11\tmb00_12\n",
    "      5\t6\t57_6_100_1\t-1\t-1\t-1\t-1.0\t-1.0\t-1.0\t100.0\t-1.0\t76\n",
    "      6\t7\t57_6_110_1\t100\t100\t-1\t-1.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
    "      7\t8\t57_6_111_1\t-1\t-1\t-1\t88.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
    "\n",
    "  \"\"\"\n",
    "  # 2 first columns are index and code_id\n",
    "  names = csv_file.columns[2:]\n",
    "  dataset=[]\n",
    "  for index,row in csv_file.iterrows():\n",
    "    if any(row[names]!=-1):\n",
    "      dataset.append(row)\n",
    "  return pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "dataset = get_dataset(updated_csv)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret_max_docid(\"100\", only_commented)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute a standard normalisation for the labels.\n",
    "def normalisation_annot(df):\n",
    "  \"\"\"\n",
    "  Compute a standard normalisation with mean and Standard deviation on label\n",
    "  to remove bias and make label comparables. Return the normalised distribution\n",
    "  with mean = 0 and std = 1, the max and the min of the distribution for each\n",
    "  annotator to make it available to get back the value of the label.\n",
    "  Parameters:\n",
    "      :param df: Label dataframe on wich perform the normalisation\n",
    "      :type df: DataFrame (pandas)\n",
    "      \n",
    "  Returns:\n",
    "      norm_df,max_list,min_list: tuple containing the normalised DataFrame, the\n",
    "      list of max for each annotator and the list of min for each annotator\n",
    "      type : (DataFrame (pandas), list,list)\n",
    "      \n",
    "  Other itema to note:\n",
    "      - Don't forget to remove -1 in the dataset, unless the normalisation\n",
    "      will be biased  \n",
    "\n",
    "  \"\"\"\n",
    "  name = df.columns[2:]\n",
    "  # Work on a copy of the DF\n",
    "  ret_df = df[df[name]!=-1]\n",
    "  max_list = []\n",
    "  min_list = []\n",
    "  for i, annot in enumerate(ret_df[name]):\n",
    "      ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
    "      max_list.append(ret_df[annot].max())\n",
    "      min_list.append(ret_df[annot].min())\n",
    "  return  ret_df, max_list, min_list \n",
    "\n",
    "norm_dataset,data_max, data_min = normalisation_annot(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "norm_dataset,data_max,data_min"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "norm_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for annot in norm_dataset:\n",
    "  norm_dataset[annot].hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}