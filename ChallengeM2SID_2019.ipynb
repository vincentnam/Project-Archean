{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChallengeM2SID_2019.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "TJB_Qi1KFPAy",
        "colab_type": "code",
        "outputId": "9093b221-9341-4b85-9543-713490b32424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# OS setup\n",
        "!rm -rf challenge-m2-sid/\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Liaison avec les donnÃ©es\n",
        "#!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Rq-iFYpFPA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import GaussianNoise,BatchNormalization, Conv1D\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re  \n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import spacy\n",
        "from google.colab import files\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn import preprocessing\n",
        "import sklearn.preprocessing\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "o9kIqLh4FPA4",
        "colab_type": "text"
      },
      "source": [
        "# Label preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CZRnow5RFPA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Return a part of the dataset with only 1 medium (text, audio, text + audio...)\n",
        "def get_medium(medium, df):\n",
        "  \"\"\"\n",
        "  # Return a subset of informations limited to a communication medium \n",
        "  # (audio : 100 , text : 001, audio and video : 110, audio and text : 101 \n",
        "  # audio, video and text : 111)\n",
        "  Parameters:\n",
        "      :param medium: ID for a medium \n",
        "      :param df: dataset containing \"code_doc\" columns containing \n",
        "      xx_x_medium_x as an document ID\n",
        "      \n",
        "      :type medium: string\n",
        "      :type df: DataFrame (pandas)\n",
        "  \n",
        "  Returns:\n",
        "      medium: the part of the dataset with only the choosen medium\n",
        "      type : DataFrame (pandas)\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> print(get_medium(\"100\",csv_file))\n",
        " Unnamed: 0      code_doc  il08_09  ...  la09_10  cg13_14  mb00_12\n",
        "5              6    57_6_100_1       -1  ...     -1.0     -1.0       76\n",
        "55            56   147_1_100_1       -1  ...     -1.0     -1.0       64\n",
        "135          136   210_3_100_1       70  ...     -1.0     -1.0       -1\n",
        "        ... \n",
        "  \"\"\"\n",
        "  return (df[df[\"code_doc\"].map(lambda x : x[len(x)-5:-2]==medium)])  \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# Return the list of label for each document\n",
        "def ret_max_docid(medium, only_commented):\n",
        "  '''\n",
        "  Choose the medium on which return the list of label for each document\n",
        "  Medium is a string : sequence of 3 bits : audio-video-texte sequence\n",
        "  only_commented : Dataframe of each annotated extract (not only extracts\n",
        "  ending with a \"1\")\n",
        "  Mean of multiple label is used when there are differents labels for one\n",
        "  document.\n",
        "  Parameters:\n",
        "      :param medium: ID for a medium \n",
        "      :param df: dataset containing \"code_doc\" columns containing \n",
        "      xx_x_medium_x as an document ID\n",
        "      \n",
        "      :type medium: string\n",
        "      :type df: DataFrame (pandas)\n",
        "  \n",
        "  Returns:\n",
        "      list_labels : couple list of each (document id, label) \n",
        "      type : list (of couple)\n",
        "  :Example:\n",
        "\n",
        "      >>>ret_max_docid(\"101\", only_commented)\n",
        "        [('57_6_101_0', 87.0),\n",
        "         ('88_11_101_1', 34.0),\n",
        "         ('51_5_101_1', 65.0),\n",
        "          ...\n",
        "  '''\n",
        "  # Get the list of annotated extracts for a medium\n",
        "  medium = get_medium(medium, only_commented)\n",
        "  # Replace all -1 by a NaN value  \n",
        "  medium = medium.replace(-1.,np.NaN)\n",
        "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
        "  return [(row[1],row[2:].mean()) for index,row in medium.iterrows() ]\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JXYcjqiPFPA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Annotation file reading\n",
        "\n",
        "def get_dataset(csv_file):\n",
        "  \"\"\"\n",
        "  Get only the commented row in the annoted csv file. The last digit is \n",
        "  here to know if a row is empty or not but some labels are forgotten. This \n",
        "  function return only row that contains something different from -1.\n",
        "  Parameters:\n",
        "      :param csv_file: DataFrame with all label for each document \n",
        "      :type csv_file : DataFrame (pandas)\n",
        "      \n",
        "  Returns:\n",
        "      dataset: The sub part of the annotation file with only commented \n",
        "      documents\n",
        "      type : DataFrame Pandas\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> get_dataset(updated_csv)\n",
        "        \\t\tcode_doc\til08_09\tvg04_05\tfd03_04\tla09_10\tcg13_14\tja05_06\tfj11_12\tec20_11\tmb00_12\n",
        "      5\t6\t57_6_100_1\t-1\t-1\t-1\t-1.0\t-1.0\t-1.0\t100.0\t-1.0\t76\n",
        "      6\t7\t57_6_110_1\t100\t100\t-1\t-1.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
        "      7\t8\t57_6_111_1\t-1\t-1\t-1\t88.0\t-1.0\t-1.0\t-1.0\t-1.0\t-1\n",
        "\n",
        "  \"\"\"\n",
        "  # 2 first columns are index and code_id\n",
        "  names = csv_file.columns[2:]\n",
        "  dataset=[]\n",
        "  for index,row in csv_file.iterrows():\n",
        "    if any(row[names]!=-1):\n",
        "      dataset.append(row)\n",
        "  return pd.DataFrame(dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmeNiUTo-hN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a standard normalisation for the labels.\n",
        "def normalisation_annot(df):\n",
        "  \"\"\"\n",
        "  Compute a standard normalisation with mean and Standard deviation on label\n",
        "  to remove bias and make label comparables. Return the normalised distribution\n",
        "  with mean = 0 and std = 1, the max and the min of the distribution for each\n",
        "  annotator to make it available to get back the value of the label.\n",
        "  Parameters:\n",
        "      :param df: Label dataframe on wich perform the normalisation\n",
        "      :type df: DataFrame (pandas)\n",
        "      \n",
        "  Returns:\n",
        "      norm_df,max_list,min_list: tuple containing the normalised DataFrame, the\n",
        "      list of max for each annotator and the list of min for each annotator\n",
        "      type : (DataFrame (pandas), list,list)\n",
        "      \n",
        "  Other itema to note:\n",
        "      - Don't forget to remove -1 in the dataset, unless the normalisation\n",
        "      will be biased  \n",
        "\n",
        "  \"\"\"\n",
        "  name = df.columns[2:]\n",
        "  # Work on a copy of the DF\n",
        "  ret_df = df[df[name]!=-1]\n",
        "  max_list = []\n",
        "  min_list = []\n",
        "  for i, annot in enumerate(ret_df[name]):\n",
        "      ret_df[annot]= (ret_df[annot] - ret_df[annot].mean()) / ret_df[annot].std()\n",
        "      max_list.append(ret_df[annot].max())\n",
        "      min_list.append(ret_df[annot].min())\n",
        "  for index in df.index :\n",
        "    ret_df[\"code_doc\"][index] = df[\"code_doc\"][index]\n",
        "  return  ret_df, np.array(max_list), np.array(min_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y8kWpXyDFPBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "\n",
        "\n",
        "dataset = get_dataset(updated_csv)\n",
        "#dataset = dataset.replace(50,np.NaN)\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JDwPeo0xFPBG",
        "colab_type": "code",
        "outputId": "d4b64f45-1fe7-4830-cbd7-e822da098028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "norm_dataset,data_max_list,data_min_list"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      \\t     code_doc   il08_09  ...   fj11_12   ec20_11   mb00_12\n",
              " 5    NaN   57_6_100_1       NaN  ...  1.359498       NaN  1.511797\n",
              " 6    NaN   57_6_110_1  2.355661  ...       NaN       NaN       NaN\n",
              " 7    NaN   57_6_111_1       NaN  ...       NaN       NaN       NaN\n",
              " 8    NaN   57_6_101_1       NaN  ...       NaN       NaN       NaN\n",
              " 9    NaN   57_6_001_1       NaN  ...       NaN  1.607416       NaN\n",
              " ...   ..          ...       ...  ...       ...       ...       ...\n",
              " 1430 NaN  256_1_100_1       NaN  ...       NaN  0.664170       NaN\n",
              " 1431 NaN  256_1_110_1       NaN  ... -0.192199       NaN  0.694386\n",
              " 1432 NaN  256_1_111_1       NaN  ...       NaN       NaN       NaN\n",
              " 1433 NaN  256_1_101_1       NaN  ...       NaN       NaN       NaN\n",
              " 1434 NaN  256_1_001_1 -0.308542  ...       NaN       NaN       NaN\n",
              " \n",
              " [241 rows x 11 columns],\n",
              " array([2.35566073, 1.00357724, 2.51622781, 1.59344352, 2.3850719 ,\n",
              "        1.85812355, 1.35949831, 1.60741643, 1.82967853]),\n",
              " array([-2.45148778, -2.59301938, -2.01415897, -3.2541503 , -1.68491953,\n",
              "        -1.45184789, -1.80855007, -2.33706812, -1.75784549]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Uk8YKxlIFPBI",
        "colab_type": "code",
        "outputId": "f4c3a037-ceab-4e3f-bdd1-52fb33f658e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "norm_dataset.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\\t</th>\n",
              "      <th>il08_09</th>\n",
              "      <th>vg04_05</th>\n",
              "      <th>fd03_04</th>\n",
              "      <th>la09_10</th>\n",
              "      <th>cg13_14</th>\n",
              "      <th>ja05_06</th>\n",
              "      <th>fj11_12</th>\n",
              "      <th>ec20_11</th>\n",
              "      <th>mb00_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>5.300000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>5.500000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.018587e-17</td>\n",
              "      <td>-7.872491e-17</td>\n",
              "      <td>9.891078e-17</td>\n",
              "      <td>1.402918e-16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.021196e-17</td>\n",
              "      <td>1.564405e-17</td>\n",
              "      <td>2.018587e-18</td>\n",
              "      <td>-6.257621e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.451488e+00</td>\n",
              "      <td>-2.593019e+00</td>\n",
              "      <td>-2.014159e+00</td>\n",
              "      <td>-3.254150e+00</td>\n",
              "      <td>-1.684920</td>\n",
              "      <td>-1.451848e+00</td>\n",
              "      <td>-1.808550e+00</td>\n",
              "      <td>-2.337068e+00</td>\n",
              "      <td>-1.757845e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.402119e-01</td>\n",
              "      <td>-2.442216e-01</td>\n",
              "      <td>-8.006625e-01</td>\n",
              "      <td>-4.476486e-01</td>\n",
              "      <td>-0.771780</td>\n",
              "      <td>-9.535726e-01</td>\n",
              "      <td>-9.518839e-01</td>\n",
              "      <td>-5.363252e-01</td>\n",
              "      <td>-8.269057e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.895480e-02</td>\n",
              "      <td>2.695779e-01</td>\n",
              "      <td>8.923489e-02</td>\n",
              "      <td>1.264085e-01</td>\n",
              "      <td>-0.171718</td>\n",
              "      <td>7.856901e-02</td>\n",
              "      <td>1.633984e-01</td>\n",
              "      <td>2.354218e-01</td>\n",
              "      <td>-3.220102e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>6.470959e-01</td>\n",
              "      <td>7.099775e-01</td>\n",
              "      <td>7.094664e-01</td>\n",
              "      <td>7.961419e-01</td>\n",
              "      <td>0.715332</td>\n",
              "      <td>8.259819e-01</td>\n",
              "      <td>1.003901e+00</td>\n",
              "      <td>7.284824e-01</td>\n",
              "      <td>8.079154e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.355661e+00</td>\n",
              "      <td>1.003577e+00</td>\n",
              "      <td>2.516228e+00</td>\n",
              "      <td>1.593444e+00</td>\n",
              "      <td>2.385072</td>\n",
              "      <td>1.858124e+00</td>\n",
              "      <td>1.359498e+00</td>\n",
              "      <td>1.607416e+00</td>\n",
              "      <td>1.829679e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        \\t       il08_09  ...       ec20_11       mb00_12\n",
              "count  0.0  5.500000e+01  ...  5.500000e+01  5.500000e+01\n",
              "mean   NaN -2.018587e-17  ...  2.018587e-18 -6.257621e-17\n",
              "std    NaN  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
              "min    NaN -2.451488e+00  ... -2.337068e+00 -1.757845e+00\n",
              "25%    NaN -5.402119e-01  ... -5.363252e-01 -8.269057e-01\n",
              "50%    NaN -1.895480e-02  ...  2.354218e-01 -3.220102e-02\n",
              "75%    NaN  6.470959e-01  ...  7.284824e-01  8.079154e-01\n",
              "max    NaN  2.355661e+00  ...  1.607416e+00  1.829679e+00\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qXtM3urlFPBK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c8QhiewFFPBL",
        "colab_type": "code",
        "outputId": "68ca33b4-360e-4c39-97a0-e884c3086088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "for annot in norm_dataset[norm_dataset.columns[2:]]:\n",
        "  norm_dataset[annot].hist()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAIcAAJFgANAoAhwAAgUAQ4Agfo/TCHAUDqov+YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjzZfdHFFuXn",
        "colab_type": "text"
      },
      "source": [
        "# Text features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EtW3d69yFPBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "4246875e-a344-454b-ce5a-85cc30ab2b2f"
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "\n",
        "dataset = get_dataset(get_medium(\"001\",updated_csv))\n",
        "norm_dataset,data_max, data_min = normalisation_annot(dataset)\n",
        "for annot in norm_dataset[norm_dataset.columns[2:]]:\n",
        "  norm_dataset[annot].hist()\n",
        "print(norm_dataset.describe())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        \\t       il08_09  ...       ec20_11       mb00_12\n",
            "count  0.0  1.100000e+01  ...  1.100000e+01  1.100000e+01\n",
            "mean   NaN -7.569702e-17  ...  8.074349e-17 -7.222758e-17\n",
            "std    NaN  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
            "min    NaN -1.847096e+00  ... -1.804910e+00 -1.302613e+00\n",
            "25%    NaN -3.051008e-01  ... -4.948405e-01 -1.089388e+00\n",
            "50%    NaN  3.298387e-01  ...  4.092918e-01  1.046743e-01\n",
            "75%    NaN  6.624260e-01  ...  6.676154e-01  8.509631e-01\n",
            "max    NaN  9.950133e-01  ...  1.368779e+00  1.170801e+00\n",
            "\n",
            "[8 rows x 10 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQCoUIXEQnE/wPnr97qTbU03AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPTPDwIx2BiV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b52d8e2-9464-4da5-e7cf-ec9d00d42c4e",
        "id": "3GkNdahl2BxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! python -m spacy download fr_core_news_md\n",
        "# Run this, then restart kernel before running rest of the notebook"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.1.0/fr_core_news_md-2.1.0.tar.gz (85.7MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 85.7MB 1.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.1.0-cp36-none-any.whl size=87463873 sha256=261faeeddc8bb53f2e742f82e0df6eae57e82a2560357671b085285b862ceeab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-91gzx3fx/wheels/7e/91/64/f61e597321455d6e42a76abac5736d919a265c31be451cc1ba\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.1.0\n",
            "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXPU1GuryU-9",
        "colab_type": "text"
      },
      "source": [
        "### 1 - Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBuAomOXeQnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re  \n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import datetime\n",
        "from getpass import getpass\n",
        "import spacy\n",
        "import gensim\n",
        "from nltk.corpus import stopwords \n",
        "import nltk\n",
        "import warnings\n",
        "import scipy\n",
        "import matplotlib as mlp\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "warnings.filterwarnings(\"ignore\",category = UserWarning)\n",
        "warnings.filterwarnings(\"ignore\",category = RuntimeWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYiV33FmeSz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete file before downloading data\n",
        "!rm -rf challenge-m2-sid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUA0DMuweZN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "b3425e72-51fd-43f0-8d9b-67e358598003"
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Data loading\n",
        "!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "Cloning into 'challenge-m2-sid'...\n",
            "remote: Enumerating objects: 938, done.\u001b[K\n",
            "remote: Counting objects: 100% (938/938), done.\u001b[K\n",
            "remote: Compressing objects: 100% (930/930), done.\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuyScQ_xeaW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete file before downloading data\n",
        "!rm -rf Project-Archean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADb0Msdmec-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data from GitHub\n",
        "user = getpass('BitBucket user')\n",
        "password = getpass('BitBucket password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "\n",
        "!git clone https://$GITHUB_AUTH@github.com/vincentnam/Project-Archean.git\n",
        "!cd Project-Archean && git checkout Texte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln92uRP6egw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_media_type(annot, noteurs, media='audio'):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        DataFrame annot : csv des annotations (modifiÃ©)\n",
        "        list noteurs : liste des annotateurs\n",
        "        str media : nom du mÃ©dia ('audio'/'video'/'texte')\n",
        "    Returns:\n",
        "        DataFrame df_m  : csv qui pour chaque scene contenant le media donne le nombre et la moyenne des notes\n",
        "        DataFrame df_mo : csv qui pour chaque scene contenant uniquement le media, donne le nombre et la moyenne des notes\n",
        "    \"\"\"\n",
        "    \n",
        "    les_medias = set(['audio','video','texte'])\n",
        "    les_medias.difference(set([media]))\n",
        "    \n",
        "    filtres = {}\n",
        "    filtres['isRated'] = annot['isRated'] == 1\n",
        "    filtres[media]     = annot[media] == 1\n",
        "    f = pd.DataFrame(filtres).apply(sum, axis=1) == len(filtres)\n",
        "    df_media = annot.loc[f,:].copy()\n",
        "    \n",
        "    for m in les_medias.difference(set([media])):\n",
        "        filtres[m] = annot[m] == 0\n",
        "    f = pd.DataFrame(filtres).apply(sum, axis=1) == len(filtres)\n",
        "    df_media_only = annot.loc[f,:].copy()\n",
        "    \n",
        "    if len(df_media) > 0:\n",
        "        df_media['moyenne'] = df_media[noteurs].apply(np.nanmean, axis=1)\n",
        "        df_m = df_media[['doc','moyenne']].groupby(['doc']).agg(['count','mean']).droplevel(level=0, axis=1)\n",
        "        df_m = df_m.sort_values('doc').reset_index()\n",
        "        print(media,\" : \",      len(set(df_media['doc'])), sep=\"\")\n",
        "    else : df_m = None\n",
        "    \n",
        "    if len(df_media_only) > 0:\n",
        "        df_media_only['moyenne'] = df_media_only[noteurs].apply(np.nanmean, axis=1)\n",
        "        df_mo = df_media_only[['doc','moyenne']].groupby(['doc']).agg(['count','mean']).droplevel(level=0, axis=1)\n",
        "        df_mo = df_mo.sort_values('doc').reset_index()\n",
        "        print(media,\"_only : \", len(set(df_media_only['doc'])), sep=\"\")\n",
        "    else : df_mo = None\n",
        "    \n",
        "    return df_m, df_mo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-CsYRXYCTjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_annotation(annot):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        DataFrame annot : csv original des annotations\n",
        "    Returns:\n",
        "        list annot : csv modififÃ© : remplacement de la colonne code_doc\n",
        "        DataFrame noteurs : liste des annotateurs\n",
        "    \"\"\"\n",
        "    annot = annot.replace(-1,np.nan)\n",
        "    noteurs = annot.columns[1:]\n",
        "\n",
        "    annot['doc']     = [\"_\".join(e.split(\"_\")[0:2]) for e in annot[\"code_doc\"]]\n",
        "    annot['audio']   = [int(e.split(\"_\")[2][0])     for e in annot[\"code_doc\"]]\n",
        "    annot['video']   = [int(e.split(\"_\")[2][1])     for e in annot[\"code_doc\"]]\n",
        "    annot['texte']   = [int(e.split(\"_\")[2][2])     for e in annot[\"code_doc\"]]\n",
        "    annot['isRated'] = [int(e.split(\"_\")[3])        for e in annot[\"code_doc\"]]\n",
        "\n",
        "    annot = annot.drop(\"code_doc\", axis=1)\n",
        "    \n",
        "    return annot, noteurs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4fJG660ehio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "label_normalised_origin = pd.read_csv('/content/Project-Archean/label_normalised_moncoucou.csv', sep=\",\", index_col=0, header=0)\n",
        "label_normalised_origin = label_normalised_origin.drop('\\t',axis=1)\n",
        "label_normalised, noteurs_normalised  = transform_annotation(label_normalised_origin)\n",
        "graded = label_normalised[(label_normalised['isRated'] == 1)].copy()\n",
        "\n",
        "text, text_only = get_media_type(graded, noteurs_normalised, media='texte')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7YVkIaye9L6",
        "colab_type": "text"
      },
      "source": [
        "### 2 -  Function that compares features with target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dep0TVrMejGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Compares feature with target\n",
        "\n",
        "def compar_anno(dic, DF_cible):\n",
        "  \"\"\"\n",
        "    Plots a chart of feature as ordinate, and target as abscissa and prints \n",
        "    correlation between target and feature\n",
        "\n",
        "    Parameters:\n",
        "        :param dic: Dictionnary with documents as keys and a feature as value\n",
        "        :param DF_cible: The target values\n",
        "        :type dic: Dictionnary\n",
        "        :type DF_cible: DataFrame\n",
        "\n",
        "    Returns:\n",
        "         /\n",
        "  \"\"\"\n",
        "  DF_dic = pd.DataFrame.from_dict(dic, orient='index', columns=['dic'])\n",
        "  DF_dic['doc']  = DF_dic.index\n",
        "  DF_dic['doc'] = DF_dic['doc'].apply(lambda x : x[:-4])\n",
        "  DF_dic = DF_dic.set_index('doc')\n",
        "  DF_cible = DF_cible.set_index('doc')\n",
        "  index_cible = list(DF_cible.index)\n",
        "  DF_dic = DF_dic.loc[index_cible]\n",
        "  DF_total = DF_cible.join(DF_dic)\n",
        "  plt.scatter(DF_total['mean'], DF_total['dic'])\n",
        "  plt.xlabel('Target')\n",
        "  plt.ylabel('Feature')\n",
        "  plt.title('Correlation between feature and target')\n",
        "  plt.show()\n",
        "  corr = scipy.stats.spearmanr(DF_total['mean'], DF_total['dic'])[0]\n",
        "  print('\\n Correlation between feature and target : ' + str(corr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHR2jU9vzQGJ",
        "colab_type": "text"
      },
      "source": [
        "### 3 - Getting clean words, sentences, lemmas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnB0JtWZengi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting a list of the documents text\n",
        "\n",
        "path_text = 'challenge-m2-sid/corpus/text/'\n",
        "List_txt = os.listdir(path_text)\n",
        "List_txt.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mdi9xoTgv4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets the sentences of each documents as strings\n",
        "\n",
        "def get_sentences(List_txt, path_text):\n",
        "  \"\"\"\n",
        "    Gets the sentences of each documents as strings by reading xml documents\n",
        "\n",
        "    Parameters:\n",
        "        :param List_txt: List of textual documents (names)\n",
        "        :param path_text: path to find the textual documents\n",
        "        :type List_txt: list\n",
        "        :type path_text: string\n",
        "    \n",
        "    Returns:\n",
        "        dic_docs: Dictionnary with documents as keys, and sentences of documents\n",
        "                 as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "  dic_docs = {}\n",
        "  for doc in List_txt:\n",
        "    tree = ET.parse(path_text + doc)\n",
        "    root = tree.getroot()\n",
        "    dic_docs[doc] = []\n",
        "    for s in root:\n",
        "      sentence = ''\n",
        "      for w in s:\n",
        "        word = w.text\n",
        "        if (word is not None):\n",
        "          sentence = sentence + word\n",
        "      dic_docs[doc].append(sentence)\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CU5-6O7q3k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets clean sentences\n",
        "\n",
        "def clean_sentences(dic_docs):  \n",
        "  \"\"\"\n",
        "    Deletes characters as punctuation, except '-'\n",
        "\n",
        "    Parameters:\n",
        "        :param dic_docs: Dictionnary out of 'get_sentences' function\n",
        "        :type dic_docs: Dictionnary\n",
        "        \n",
        "    Returns:\n",
        "        dic_docs: Dictionnary with documents as keys, and sentences of documents\n",
        "                 as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "  for key in dic_docs.keys() : \n",
        "    list_new = []\n",
        "    for sentence in dic_docs[key]:\n",
        "      sentence = sentence.replace(\"'\", ' ').replace(\"â\", ' ')\n",
        "      sentence = re.sub(\"([^\\s\\w\\-])\", '',sentence)\n",
        "      list_new.append(sentence)\n",
        "    dic_docs[key] = list_new\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvcRbvexwluh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets clean words\n",
        "\n",
        "def get_clean_words(dic_docs, mode = 'All'):\n",
        "  \"\"\"\n",
        "    Deletes words as blancs, or one letter words, or None\n",
        "    \n",
        "    Parameters:\n",
        "        :param dic_docs: Dictionnary out of 'clean_sentences' function\n",
        "        :param mode: mode of execution, getting clean words as sentences \n",
        "                     or list of words\n",
        "        :type dic_docs: Dictionnary\n",
        "        :type mode: string\n",
        "\n",
        "    Returns:\n",
        "        dic_docs: Dictionnary with documents as keys, and clean words as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "  if mode == 'All':\n",
        "    for key in dic_docs.keys() : \n",
        "      list_words = []\n",
        "      for sentence in dic_docs[key]:\n",
        "        for word in sentence.split():\n",
        "            w = word.replace(' ', '')\n",
        "            if len(w) != 0:\n",
        "              list_words.append(w.lower())\n",
        "      dic_docs[key] = list_words\n",
        "  if mode == 'Sentences':\n",
        "    for key in dic_docs.keys() : \n",
        "        list_words = []\n",
        "        for sentence in dic_docs[key]:\n",
        "          list_words_sent = []\n",
        "          for word in sentence.split():\n",
        "              w = word.replace(' ', '')\n",
        "              if len(w) > 1:\n",
        "                list_words_sent.append(w.lower())\n",
        "          list_words.append(list_words_sent)\n",
        "        dic_docs[key] = list_words\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qFaa2xt7LR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download French language modele, and french StopWords\n",
        "\n",
        "nlp = spacy.load('fr_core_news_md')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjXZYSjs7Ogj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gets lemmas of each word\n",
        "\n",
        "def get_lemmatize(dic_docs):\n",
        "  \"\"\"\n",
        "    Lowers words and replace them by their lemma if they are longer than\n",
        "    1 letter, for each word of each document\n",
        "\n",
        "    Parameters:\n",
        "        :param dic_docs: Dictionnary out of 'get_clean_words' \n",
        "                         function (sentences mode)\n",
        "        :type dic_docs: Dictionnary\n",
        "    \n",
        "    Returns:\n",
        "        dic_lemma: Dictionnary with documents as keys, and lemmatize sentences \n",
        "                   as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "\n",
        "  stop_words = set(stopwords.words('french')) \n",
        "  dic_lemma = {}\n",
        "  i = 1\n",
        "  N = len(dic_docs)\n",
        "  for doc in dic_docs.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    list_doc = []\n",
        "    for sentence in dic_docs[doc]:\n",
        "      list_sent = []\n",
        "      filtered_sentence = [w.lower() for w in sentence if w not in stop_words] \n",
        "      sentence_clean = ' '.join(w for w in filtered_sentence)\n",
        "      sentence_nlp = nlp(sentence_clean)\n",
        "      for token in sentence_nlp:\n",
        "        if len(token.lemma_) > 1 :\n",
        "          list_sent.append(token.lemma_)\n",
        "      list_doc.append(list_sent)\n",
        "    dic_lemma[doc] = list_doc\n",
        "    i = i + 1\n",
        "  return(dic_lemma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45_Zfg7WiDSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_docs = get_clean_words(clean_sentences(get_sentences(List_txt, path_text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj4hBl6qOvAI",
        "colab_type": "text"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMZyKyBS2bcC",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Clean words for 226_6 : \\n')\n",
        "print(dic_docs['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0poQFbBW2d1i",
        "colab": {}
      },
      "source": [
        "dic_lemma = get_lemmatize(get_clean_words(clean_sentences(get_sentences(List_txt, path_text)), 'Sentences'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bc8JY27h2fRx",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Lemmas for 226_6 : \\n')\n",
        "print(dic_lemma['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFaXktLP3Ca1",
        "colab_type": "text"
      },
      "source": [
        "### Feature 1 : number of low frequencie words per video "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hcNgsHHiY4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Read excel file\n",
        "\n",
        "def read_excel(file):\n",
        "  \"\"\"\n",
        "    Read the excel file, computes a normalized frequency, keeps only some of\n",
        "    the columns (word, lemma, pos_tag, frequency, number of syllable)\n",
        "    \n",
        "    Parameters:\n",
        "        :param file: Path leading to the Excel file\n",
        "        :type file: string\n",
        "    \n",
        "    Returns:\n",
        "        df_lex:  DataFrame of excel file, minus some columns\n",
        "        type : DataFrame\n",
        "  \"\"\"\n",
        "  dfs = pd.ExcelFile(file)\n",
        "  sh = dfs.sheet_names[0]\n",
        "  df_lex = dfs.parse('Sheet1')\n",
        "  df_lex = df_lex[['ortho', 'lemme', 'cgram', 'freqfilms2', 'nbsyll']]\n",
        "  serie = df_lex['freqfilms2']\n",
        "  normalized_serie=(serie)/max(serie)\n",
        "  df_lex['freqfilms2_norm'] = normalized_serie\n",
        "  return(df_lex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH1p2o6uiy_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_lex = read_excel('Project-Archean/Lexique-query.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mp5UEZ8F2iad",
        "colab": {}
      },
      "source": [
        "df_lex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pba9u33B7Yve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Computes complexity of a document\n",
        "\n",
        "def get_complexity_doc(doc, df_lex, dic_docs):\n",
        "  \"\"\"\n",
        "    Computes complexity of a document, by getting ratio of the number of words\n",
        "    with a small frequency on total number of words\n",
        "    \n",
        "    Parameters:\n",
        "        :param doc: Name of a document\n",
        "        :param df_lex: Dataframe out of 'read_excel' function\n",
        "        :param dic_docs: Dictionnary out of 'get_clean_words'\n",
        "                         function (All words mode)\n",
        "        :type doc: string\n",
        "        :type df_lex: Dataframe\n",
        "        :type dic_docs: Dictionnary\n",
        "    \n",
        "    Returns:\n",
        "        cplxty: Complexity of the document \n",
        "        type : float\n",
        "  \"\"\"\n",
        "  cplxty = 0\n",
        "  list_words = list(set(list(dic_docs[doc])))\n",
        "  for word in list_words:\n",
        "    try : \n",
        "      freq = max(df_lex[df_lex['ortho']==word]['freqlemfilms2_norm'])\n",
        "    except :\n",
        "      if len(word) > 3:\n",
        "        freq = 0\n",
        "      else : \n",
        "        freq = 1\n",
        "    if freq < 0.0001:\n",
        "      cplxty = cplxty + 1\n",
        "  cplxty = cplxty/(len(list_words))\n",
        "  return(cplxty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_WQRJpCj2fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets all the complexities\n",
        "\n",
        "def get_all_cplx(df_lex, dic_docs):\n",
        "  \"\"\"\n",
        "    Gets all the complexities by calling 'get_complexity_doc' function\n",
        "    \n",
        "    Parameters:\n",
        "        :param df_lex: Dataframe out of 'read_excel' function\n",
        "        :param dic_docs: Dictionnary out of 'get_clean_words'\n",
        "                         function (All words mode)\n",
        "        :type df_lex: Dataframe\n",
        "        :type dic_docs: Dictionnary\n",
        "    \n",
        "    Returns:\n",
        "        cplxty: Dictionnary with documents as keys, and complexity as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "  dic_cplx = {}\n",
        "  i = 1\n",
        "  N = len(dic_docs.keys())\n",
        "  for doc in dic_docs.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    dic_cplx[doc] = get_complexity_doc(doc, df_lex, dic_docs)\n",
        "    i = i + 1\n",
        "  return(dic_cplx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRalZfTjvj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_cplx = get_all_cplx(df_lex, dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkdDeV_kR1JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Lexical complexity for 226_6 : \\n')\n",
        "print(dic_cplx['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMq-ZXVnPouS"
      },
      "source": [
        "*   Comparing feature with target :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR5G43IT5qSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_cplx, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A2gw0b3cPNIW"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAby9i09oN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_docs_sent = clean_sentences(get_sentences(List_txt, path_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgyxSc23jIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets the duration of each document\n",
        "\n",
        "def get_len_video(List_txt, path_text):\n",
        "  \"\"\"\n",
        "  Gets the duration of each document by time codes (last minus first), in second\n",
        "\n",
        "    Parameters:\n",
        "        :param List_txt: List of textual documents (names)\n",
        "        :param path_text: path to find the textual documents\n",
        "        :type List_txt: list\n",
        "        :type path_text: string\n",
        "\n",
        "    Returns:\n",
        "        dic_doc_len_video: Dictionnary with documents as keys, and time of \n",
        "                           documents as values\n",
        "        type : Dictionnary\n",
        "  \"\"\"\n",
        "  dic_doc_len_video = {}\n",
        "  for doc in List_txt:\n",
        "    tree = ET.parse(path_text + doc)\n",
        "    root = tree.getroot()\n",
        "    ma = int(max([root[i].attrib['id'] for i in range(len(root))]))\n",
        "    start = root[0][0].attrib['value'][:8]\n",
        "    end = root[ma-1][-1].attrib['value'][:8]\n",
        "    format_ = '%H:%M:%S'\n",
        "    startDateTime = datetime.datetime.strptime(start, format_)\n",
        "    endDateTime = datetime.datetime.strptime(end, format_)\n",
        "    diff = endDateTime - startDateTime\n",
        "    time_s = diff.total_seconds()\n",
        "    dic_doc_len_video[doc] = time_s\n",
        "  return(dic_doc_len_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCTnRzweFFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets the mean length of sentences and the number of sentences per minute\n",
        "\n",
        "def get_length_sentences_nb(dic_docs_sent, dic_doc_len_video):\n",
        "  \"\"\"\n",
        "    Computes the mean length of sentences for each document (AVG), \n",
        "    and the number of sentences per minute for each document, thanks to the\n",
        "    duration of subtitles\n",
        "\n",
        "    Parameters:\n",
        "        :param dic_docs_sent: Dictionnary out of 'clean_sentences' function\n",
        "        :param dic_doc_len_video: Dictionnary out of 'get_len_video' function \n",
        "        :type dic_docs_sent: Dictionnary\n",
        "        :type dic_doc_len_video: Dictionnary\n",
        "    \n",
        "    Returns:\n",
        "        dic_len_sentence: Dictionnary with documents as keys, and mean sentences\n",
        "                          length as values \n",
        "        dic_nb_sentence : Dictionnary with documents as keys, and number of \n",
        "                          sentence per minute as values \n",
        "        type dic_len_sentence: Dictionnary\n",
        "        type dic_nb_sentence: Dictionnary\n",
        "  \"\"\"\n",
        "  dic_len_sentence = {}\n",
        "  dic_nb_sentence =  {}\n",
        "  for doc in dic_docs_sent.keys():\n",
        "    time = dic_doc_len_video[doc]\n",
        "    nb_s = len(dic_docs_sent[doc])\n",
        "    s_per_min = 60*nb_s/time\n",
        "    mean_len_s = np.mean([len(s.split()) for s in dic_docs_sent[doc]])\n",
        "    dic_len_sentence[doc] = mean_len_s\n",
        "    dic_nb_sentence[doc] = s_per_min\n",
        "  return(dic_len_sentence, dic_nb_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkgK9wgVDPLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_doc_len_video = get_len_video(List_txt, path_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uSzMh4SsPQia"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9vKEYetSBOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Lenght of video (in s) for 226_6 : \\n')\n",
        "print(dic_doc_len_video['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpxSNs_L5DkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_len_sentence, dic_nb_sentence = get_length_sentences_nb(dic_docs_sent,\n",
        "                                                            dic_doc_len_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "biUW2nPJPTRH"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-2qjiK9SKVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Average length of sentences for 226_6 : \\n')\n",
        "print(dic_len_sentence['226_6.xml'])\n",
        "print('\\nNumber of sentences per minute for 226_6 : \\n')\n",
        "print(dic_nb_sentence['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0unU3ygAPv7K"
      },
      "source": [
        "*   Comparing feature with target :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mqMVDu7u27rU",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_len_sentence, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bSG46Mfn2-d1",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_nb_sentence, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTMLtBiK-58E",
        "colab_type": "text"
      },
      "source": [
        "### Feature 4 : word repetition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVS4fTpvLfQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Computes the rate of different words\n",
        "\n",
        "def get_repetition_ratio_doc(doc, dic_docs):\n",
        "  \"\"\"\n",
        "      Computes the ratio between number of unique words and total number of\n",
        "      words\n",
        "\n",
        "      Parameters:\n",
        "          :param doc: Name of a document\n",
        "          :param dic_docs: Dictionnary out of 'get_clean_words' function \n",
        "          :type doc: string\n",
        "          :type dic_docs: Dictionnary\n",
        "\n",
        "      Returns:\n",
        "          rep: ratio of different words on total  number of words\n",
        "          type : float\n",
        "    \"\"\"\n",
        "  list_words_dif = list(set(dic_docs[doc]))\n",
        "  list_words = dic_docs[doc]\n",
        "  rep = len(list_words_dif)/len(list_words)\n",
        "  return(rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGuhlx9Mm4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#  Gets all repetition rates\n",
        "\n",
        "def get_all_rep (dic_docs):\n",
        "  \"\"\"\n",
        "      Gets all repetition rates by calling 'get_repetition_ratio_doc' function\n",
        "\n",
        "      Parameters:\n",
        "          :param dic_docs: Dictionnary out of 'get_clean_words' function \n",
        "          :type dic_docs: Dictionnary\n",
        "\n",
        "      Returns:\n",
        "          dic_repetition: Dictionnary with documents as keys, and repetition\n",
        "                          rate as values\n",
        "          type : Dictionnary\n",
        "    \"\"\"\n",
        "  dic_repetition = {}\n",
        "  for doc in dic_docs.keys():\n",
        "    dic_repetition[doc] = get_repetition_ratio_doc(doc, dic_docs)\n",
        "  return(dic_repetition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHA_Cg02M07F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_repetition = get_all_rep (dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "984HFsM-PgxV"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJKxGmCHTRfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Repetition ratio for 226_6 : \\n')\n",
        "print(dic_repetition['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o8l0qQ0KPzya"
      },
      "source": [
        "*   Comparing feature with target :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZquP2iO53xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_repetition, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE7clVBBO8PB",
        "colab_type": "text"
      },
      "source": [
        "### Feature 5 : Number of syllable for 100 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90mW8leTyrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Computes the number of syllable for 100 words \n",
        "\n",
        "def nb_syll_100 (dic_docs, df_lex):\n",
        "  \"\"\"\n",
        "      Computes the number of syllable for 100 words for each document, thanks to \n",
        "      length of document (number of words), and number of syllable.\n",
        "\n",
        "      Parameters:\n",
        "          :param dic_docs: Dictionnary out of 'get_clean_words' function \n",
        "          :param df_lex: DataFrame out of 'read_excel' function\n",
        "          :type dic_docs: Dictionnary\n",
        "          :type df_lex: DataFrame\n",
        "          \n",
        "      Returns:\n",
        "          dic_syll_per_100: Dictionnary with documents as keys, and number of \n",
        "                            syllable for 100 words as values\n",
        "          type : Dictionnary\n",
        "    \"\"\"\n",
        "  dic_syll_per_100 = {}\n",
        "  i = 1\n",
        "  N = len(dic_docs)\n",
        "  m = np.mean(df_lex['nbsyll'])\n",
        "  list_words = list(set(list(df_lex['ortho'])))\n",
        "  for doc in dic_docs.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    syll = 0\n",
        "    nb_word = len(dic_docs[doc])\n",
        "    syll = sum([int(max(df_lex[df_lex['ortho']==w]['nbsyll'])) for w in dic_docs[doc] if w in list_words])\n",
        "    syll = syll + sum([m for w in dic_docs[doc] if w not in list_words])\n",
        "    ratio = 100 * syll / nb_word \n",
        "    dic_syll_per_100[doc] = ratio\n",
        "    i = i + 1\n",
        "  return(dic_syll_per_100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ClY2y3WmMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_syll_per_100 = nb_syll_100 (dic_docs, df_lex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKSt8JJBPkKj"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BedmWESlTfh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Number of syllable for 100 words for 226_6 : \\n')\n",
        "print(dic_syll_per_100['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IDn_6eotP17d"
      },
      "source": [
        "*   Comparing feature with target :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qelOT6DK58IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_syll_per_100, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUJ7QwFiorOA",
        "colab_type": "text"
      },
      "source": [
        "### Feature 6 : Dispersion of words belonging to the 4 main topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Z-tsfCosxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Computes a list of words belonging to 4 topic per document\n",
        "\n",
        "def get_topics (dic_lemma):\n",
        "  \"\"\"\n",
        "      Computes the 4 main topics for each documents, with LDA model, and then\n",
        "       gets for each topic a list of the words that are part of this topic\n",
        "\n",
        "      Parameters:\n",
        "          :param dic_lemma: Dictionnary out of 'get_lemmatize' function \n",
        "          :type dic_lemma: Dictionnary\n",
        "\n",
        "      Returns:\n",
        "          dic_topics: Dictionnary with documents as keys, and one dictionnary \n",
        "                      for each topic as value. Each dictionnary has number of \n",
        "                      topic as key and list of words that are part of this topic\n",
        "                      as value\n",
        "          type : Dictionnary\n",
        "    \"\"\"\n",
        "  dic_topics = {}\n",
        "  i=1\n",
        "  N = len(dic_lemma)\n",
        "  for doc in dic_lemma.keys():\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    dictionary = gensim.corpora.Dictionary(dic_lemma[doc])\n",
        "    bow_corpus = [dictionary.doc2bow(s) for s in dic_lemma[doc]]\n",
        "    lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 4, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)\n",
        "    dic_topics_doc = {}\n",
        "    for idx, topic in lda_model.print_topics(-1):\n",
        "      topics = topic.split('\"')\n",
        "      list_topic_i = []\n",
        "      for j in range(1, len(topics), 2):\n",
        "        list_topic_i.append(topics[j])\n",
        "      dic_topics_doc[idx] = list_topic_i\n",
        "    dic_topics[doc] = dic_topics_doc\n",
        "    i = i + 1\n",
        "  return(dic_topics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsRjjz7CzRxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_topics = get_topics (dic_lemma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hgpXHgITqdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('4 main topics for 226_6 : ')\n",
        "print(dic_topics['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxhnPaIJ4vUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Computes the over-dispersed topic rate\n",
        "\n",
        "def topic_in_time(dic_topics, dic_lemma, test, list_doc = []):\n",
        "  \"\"\"\n",
        "      Computes the VMR rate (variance/mean) for each topic of each document and \n",
        "      gets the ratio of topics with VMR > 1 on number of topics if test is False\n",
        "      OR plots the dispersion of topics for 4 representative documents if \n",
        "      test is True\n",
        "\n",
        "      Parameters:\n",
        "          :param dic_topics: Dictionnary out of 'get_topics' function \n",
        "          :param dic_lemma: Dictionnary out of 'get_lemmatize' function\n",
        "          :param test: Boolean value, to know if it has to compute all documents\n",
        "                       or example ones\n",
        "          :param list_doc: list of documents for plot, only used if test is True\n",
        "          :type dic_topics: Dictionnary\n",
        "          :type dic_lemma: Dictionnary\n",
        "          :type test: Boolean\n",
        "          :type test: list\n",
        "\n",
        "      Returns:\n",
        "        if test is False :\n",
        "          dic_syll_per_100: Dictionnary with documents as keys, and ratio of \n",
        "                            over-dispersed topic on total number of topics\n",
        "                            as values\n",
        "          type : Dictionnary\n",
        "        if test is True :\n",
        "          /\n",
        "    \"\"\"\n",
        "\n",
        "  if test is False :\n",
        "    dic_time_topic = {}\n",
        "    for doc in dic_topics.keys():\n",
        "      lemmas = dic_lemma[doc]\n",
        "      cpt_disp = 0\n",
        "      for topic in dic_topics[doc].keys():\n",
        "        index = []\n",
        "        for w in dic_topics[doc][topic]:\n",
        "          index.extend([i for i, n in enumerate(lemmas) if w in n])\n",
        "        VMR = np.var(index)/np.mean(index)\n",
        "        if VMR > 1:\n",
        "          cpt_disp = cpt_disp + 1\n",
        "      dic_time_topic[doc] = cpt_disp/4\n",
        "    return(dic_time_topic) \n",
        "\n",
        "  else : \n",
        "    colors = ['blue', 'green', 'red', 'yellow']\n",
        "    for doc in list_doc:\n",
        "      lemmas = dic_lemma[doc]\n",
        "      plt.figure()\n",
        "      for topic in dic_topics[doc].keys():\n",
        "        index = []\n",
        "        for w in dic_topics[doc][topic]:\n",
        "          index.extend([i for i, n in enumerate(lemmas) if w in n])\n",
        "        plt.scatter(index, [i for i in range(len(index))],\n",
        "                    label = 'topic ' + str(topic),\n",
        "                    color = colors[int(topic)])\n",
        "      plt.legend()\n",
        "      plt.title('Dispersion of topics in document ' + doc)\n",
        "      plt.xlabel('Position of word in document')\n",
        "      plt.ylabel('Does not matter')\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkcpAc0E_OQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_time_topic = topic_in_time(dic_topics, dic_lemma, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZyNx45OQKGN"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OxTzdbvT2aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Dispersion rate of topics for 226_6 : ')\n",
        "print(dic_time_topic['226_6.xml'])\n",
        "topic_in_time(dic_topics, dic_lemma, True, ['226_6.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63drTZ9_8iz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of the 4 level of dispersion\n",
        "# Here we can see 4 documents labelized from 0.25 to 1 (in this order)\n",
        "\n",
        "topic_in_time(dic_topics, dic_lemma, True, ['113_11.xml', '184_15.xml', '160_9.xml', '124_13.xml'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RQWyY_w6K6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compar_anno(dic_time_topic, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-Foc-BqJk3",
        "colab_type": "text"
      },
      "source": [
        "## 4 - Features agregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bNPYhIJ3Nno",
        "colab": {}
      },
      "source": [
        "\n",
        "# Aggregates all features\n",
        "\n",
        "def create_DF_agreg(dic_nb_sentence,\n",
        "                    dic_len_sentence,\n",
        "                    dic_cplx,\n",
        "                    dic_syll_per_100,\n",
        "                    dic_repetition,\n",
        "                    dic_time_topic):\n",
        "  \"\"\"\n",
        "      Aggregates all features for every documents in one DataFrame\n",
        "\n",
        "      Parameters:\n",
        "          :param dic_nb_sentence: Dictionnary out of 'dic_nb_sentence' function\n",
        "          :param dic_len_sentence: Dictionnary out of 'dic_len_sentence' \n",
        "                                  function\n",
        "          :param dic_cplx: Dictionnary out of 'get_all_cplx' function \n",
        "          :param dic_syll_per_100: Dictionnary out of 'nb_syll_100' function \n",
        "          :param dic_repetition:  Dictionnary out of 'dic_repetition' function \n",
        "          :param dic_time_topic: Dictionnary out of 'topic_in_time' function  \n",
        "          :type dic_nb_sentence: Dictionnary\n",
        "          :type dic_len_sentence: Dictionnary\n",
        "          :type dic_cplx: Dictionnary\n",
        "          :type dic_syll_per_100: Dictionnary\n",
        "          :type dic_repetition: Dictionnary\n",
        "          :type dic_time_topic: Dictionnary\n",
        "          \n",
        "      Returns:\n",
        "          DF: DataFrame with column for documents, and others for features\n",
        "          type : DataFrame\n",
        "    \"\"\"\n",
        "  col = ['doc',\n",
        "         'nb_sentence',\n",
        "         'len_sentence',\n",
        "         'cplx_words',\n",
        "         'syll_100',\n",
        "         'different_words',\n",
        "         'topic']\n",
        "  list_DF = []\n",
        "  for doc in dic_nb_sentence.keys():\n",
        "    list_DF_doc = [doc[:-4],\n",
        "                   dic_nb_sentence[doc],\n",
        "                   dic_len_sentence[doc],\n",
        "                   dic_cplx[doc],\n",
        "                   dic_syll_per_100[doc],\n",
        "                   dic_repetition[doc],\n",
        "                   dic_time_topic[doc]]\n",
        "    list_DF.append(list_DF_doc)\n",
        "  DF = pd.DataFrame(list_DF, columns=col)\n",
        "  return(DF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k9-NVtsuXLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF_aggreg = create_DF_agreg(dic_nb_sentence,\n",
        "                    dic_len_sentence,\n",
        "                    dic_cplx,\n",
        "                    dic_syll_per_100,\n",
        "                    dic_repetition,\n",
        "                    dic_time_topic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x3520ctBQMNm"
      },
      "source": [
        "*   Example :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8EfGxpHUImo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example on video 226_6 : Cyrano de Bergerac\n",
        "\n",
        "print('Features for 226_6 : ')\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(DF_aggreg[DF_aggreg['doc'] == '226_6'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5U7aOpD3cfM",
        "colab": {}
      },
      "source": [
        "DF_aggreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipNpzonH7EQ3",
        "colab": {}
      },
      "source": [
        "\n",
        "# Gets the X and y to give to the model\n",
        "\n",
        "def get_X_y_model(DF_aggreg, DF_cible):\n",
        "  \"\"\"\n",
        "      Gets the X and y for model prediction, by joining the 2 DataFrames on doc\n",
        "      number (aggregation one, and target one). This is made to be sure the\n",
        "      right label is assigned to the right document.\n",
        "\n",
        "      Parameters:\n",
        "          :param DF_aggreg: DataFrame with features and number of document as \n",
        "                            columns\n",
        "          :param DF_cible: DataFrame with number of document and labels as\n",
        "                          columns\n",
        "          :type DF_aggreg: DataFrame\n",
        "          :type DF_cible: DataFrame\n",
        "\n",
        "      Returns:\n",
        "          X: DataFrame with only features as columns and doc as index\n",
        "          type X : DataFrame\n",
        "          y: DataFrame with only label as column and doc as index\n",
        "          type y : DataFrame\n",
        "    \"\"\"\n",
        "  DF_aggreg = DF_aggreg.set_index('doc')\n",
        "  DF_cible = DF_cible.set_index('doc')\n",
        "  index_cible = list(DF_cible.index)\n",
        "  DF_aggreg = DF_aggreg.loc[index_cible]\n",
        "  DF_total = DF_cible.join(DF_aggreg)\n",
        "  X = DF_total[['nb_sentence',\n",
        "          'len_sentence',\n",
        "          'cplx_words',\n",
        "          'syll_100',\n",
        "          'different_words',\n",
        "          'topic']]\n",
        "\n",
        "  y = DF_total['mean']\n",
        "  return(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3emRt6mH_XlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = get_X_y_model(DF_aggreg, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-y2lpI3A3gRV",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Plots different analysis on model and features\n",
        "\n",
        "def Lasso_model(X,y):\n",
        "  \"\"\"\n",
        "     First standardize features, then computes correlation between those and\n",
        "     plots the correlations. \n",
        "     Then computes Lasso model and predict on it, shows what feature Lasso kept\n",
        "     for the model.\n",
        "     Shows the prediction over the target with a scatter plot\n",
        "\n",
        "      Parameters:\n",
        "          :param X: DataFrame out of 'get_X_y_model' function\n",
        "          :param y:  DataFrame out of 'get_X_y_model' function\n",
        "          :type X: DataFrame\n",
        "          :type y: DataFrame\n",
        "\n",
        "      Returns:\n",
        "         /\n",
        "    \"\"\"\n",
        "  scaler = StandardScaler(with_mean=True, with_std=True, copy=True)\n",
        "  scaler.fit(X)\n",
        "  DF_scaled = pd.DataFrame(scaler.transform(X),\n",
        "                          index = X.index, columns = list(X))\n",
        "  DF_scaled['mean'] = y\n",
        "\n",
        "  X_N = DF_scaled[['nb_sentence',\n",
        "          'len_sentence',\n",
        "          'cplx_words',\n",
        "          'syll_100',\n",
        "          'different_words',\n",
        "          'topic']]\n",
        "  y_N = DF_scaled['mean']\n",
        "  reg = Lasso(alpha = 0.07)\n",
        "  reg.fit(X_N, y_N)\n",
        "  pred = reg.predict(X_N)\n",
        "  coef = pd.Series(reg.coef_, index = X_N.columns)\n",
        "  imp_coef = coef.sort_values()\n",
        "  print(\"\\n Lasso picked \" + str(sum(coef != 0)) \\\n",
        "        +  \" features and eliminated the other \" \\\n",
        "        +  str(sum(coef == 0)) + \" features \\n\")\n",
        "  \n",
        "  corr = X_N.corr()\n",
        "  plt.figure()\n",
        "  sns.heatmap(corr, cmap=\"Blues\")\n",
        "  plt.title('Correlation between features')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.scatter(y_N, pred)\n",
        "  plt.xlabel('Target')\n",
        "  plt.ylabel('Prediction with Lasso')\n",
        "  plt.title('Prediction on standardized data')\n",
        "  plt.xlim(-2,2)\n",
        "  plt.ylim(-2,2)\n",
        "  plt.show()\n",
        "\n",
        "  imp_coef = coef.sort_values()\n",
        "  plt.figure()\n",
        "  imp_coef.plot(kind = \"barh\")\n",
        "  plt.title(\"Feature importance using Lasso Model\")\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "78zOHeur3hyf",
        "colab": {}
      },
      "source": [
        "Lasso_model(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRwBlOzZRZxE",
        "colab_type": "text"
      },
      "source": [
        "## 5 - Personal conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjSA-m473nM1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHRyl7ydFzFc",
        "colab_type": "text"
      },
      "source": [
        "# Audio features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N_Z1AZOF1FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyHYm4KiF2KD",
        "colab_type": "text"
      },
      "source": [
        "# Video features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc43AdbFF3T6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnx9UQULF3fH",
        "colab_type": "text"
      },
      "source": [
        "# Agregation models\n",
        "The models works on csv file from features extractions (some features take lot of time to be computed. To make it possible, we'll work directly with csv results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk02dN5ruBGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an aggregation DataFrame of features\n",
        "def create_features_dataframe(text_path ,audio_path, video_path ):\n",
        "    \"\"\"\n",
        "  # Create an aggregation DataFrame of each medium features to create a dataset\n",
        "  # for the learning model. Each medium is merge on document column.\n",
        "  Parameters:\n",
        "      :param text_path: path to the csv containing calculated text features \n",
        "      :param audio_path: path to the csv containing calculated audio features\n",
        "      :param video_path: path to the csv containing calculated video features\n",
        "      :type text_path: string\n",
        "      :type audio_path: string\n",
        "      :type video_path: string\n",
        "  \n",
        "  Returns:\n",
        "      audio_video_text: DataFrame with all the features concatenate in the same\n",
        "      object\n",
        "      type : DataFrame (pandas)\n",
        "  Other itema to note:\n",
        "    - All medium are merge together. It may be more accurate for the problem\n",
        "    merge text features only with text documents, audio text features only with\n",
        "    audio documents, etc...\n",
        "  :Example:\n",
        "\n",
        "      >>> print(create_features_dataframe(\"Text_Features_6.csv\",\n",
        "      \"./silence_rolling_mean_new.csv\",\"feat_break.csv\"))\n",
        "\tcode_doc\tSR\tSNR\tVBR\tCONF\tRecognition score\tenv_br_per_min\tscene_br_per_min\tnb_sentence\tlen_sentence\tcplx_words\tsyll_100\tdifferent_words\ttopic\n",
        "0\t100_1\t0.506749\t0.975847\t0.937432\t0.891960\t46.659483\t11.789474\t15.157895\t54.545455\t10.350000\t0.753968\t138.665032\t0.608696\t0.75\n",
        "1\t107_7\t0.875052\t0.992874\t0.996106\tNaN\t17.618720\t1.441441\t2.882883\t44.000000\t14.681818\t0.789474\t137.962893\t0.470588\t1.00\n",
        "        ... \n",
        "  \"\"\"\n",
        "  text_feat = pd.read_csv(text_path)\n",
        "  # Audio csv is build with special separator and encoding\n",
        "  audio_feat = pd.read_csv(audio_path, sep='Â§', engine='python', index_col=0, encoding='utf-8') \n",
        "  audio_feat[\"SCORE\"] = (1-audio_feat[\"SCORE\"])*100\n",
        "  video_feat= pd.read_csv(\"feat_break.csv\")\n",
        "  audio_video = pd.merge(audio_feat,video_feat,left_on=\"SCENE\",right_on=\"Unnamed: 0\")\n",
        "  audio_video = audio_video.drop([\"Unnamed: 0\"], axis=1)\n",
        "  audio_video = audio_video.rename(columns={\"SCENE\":\"code_doc\", \"SCORE\": \"Recognition score\"})\n",
        "  audio_video = audio_video.drop([\"RECON\",\"XML\"],axis=1)\n",
        "  audio_video_text = pd.merge(audio_video,text_feat,left_on=\"code_doc\",right_on=\"doc\")\n",
        "  audio_video_text = audio_video_text.drop([\"Unnamed: 0\",\"doc\"],axis=1)\n",
        "  return audio_video_text\n",
        "\n",
        "\n",
        "features = create_features_dataframe(\"Text_Features_6.csv\",\"./silence_rolling_mean_new.csv\",\"feat_break.csv\")\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7KuxC3ShGp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjbdjqKLu6Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a training dataset with features and labels\n",
        "def create_model_dataset(labels,features):\n",
        "  \"\"\"\n",
        "  # Create an aggregation of features (x set) and labels (y set) to provide \n",
        "  # data for learning model. Label are the last columns of the dataframe and\n",
        "  # keep the code_doc for each tuple.\n",
        "  Parameters:\n",
        "      :param labels: DataFrame with annotation of each annotator for each\n",
        "      document \n",
        "      :param features: DataFrame with all features, created with \n",
        "       create_features_dataframe(..) function.\n",
        "      :type labels: DataFrame (pandas) \n",
        "      :type features: DataFrame (pandas)\n",
        "  \n",
        "  Returns:\n",
        "      model_dataset: Dataframe with the features and the labels in the same\n",
        "      document. Labels are last column and first column is the code_doc\n",
        "      type : DataFrame (pandas)\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> print(create_model_dataset(...,...))\n",
        " code_doc        SR       SNR  ...  different_words  topic    labels\n",
        "0      100_1  0.506749  0.975847  ...         0.608696   0.75 -0.187638\n",
        "1      100_1  0.506749  0.975847  ...         0.608696   0.75  0.414244\n",
        "        ... \n",
        "  \"\"\"\n",
        "  dataset = labels\n",
        "  dataset[\"labels\"] = dataset[dataset.columns[2:]].mean(axis=1)\n",
        "  labels = pd.merge(dataset[\"code_doc\"],dataset[\"labels\"], right_index=True, left_index=True)\n",
        "  labels[\"code_doc\"] = labels[\"code_doc\"].map(lambda x : x[:-6])\n",
        "  model_dataset = pd.merge(features, labels, on=\"code_doc\")\n",
        "  return model_dataset\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "features = create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\")\n",
        "\n",
        "\n",
        "\n",
        "#print(create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "print(model_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT_9tLvfC2xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dataset = get_dataset(updated_csv)\n",
        "dataset[\"code_doc\"] = dataset[\"code_doc\"].map(lambda x :x[:-6] )\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Om3WgOzF5nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unnormalise datas to make it human readable\n",
        "def un_norm(in_values, maxi,mini):\n",
        "  \"\"\"\n",
        "  # Change the range of in_values from normalised values ([-3,3]) to the\n",
        "  # initial range of values ([0,100]) to make it human readable and \n",
        "  # understandable\n",
        "  Parameters:\n",
        "      :param in_values : list of values to un-normalise\n",
        "      :param maxi: maximum value of the distribution of normalised data to \n",
        "      compare to\n",
        "      :param mini: minimum value of the distribution of normalised data to \n",
        "      compare to  \n",
        "      :type labels: iterable (list, Dataframe, array...) \n",
        "      :type maxi: float\n",
        "      :type mini: float\n",
        "  \n",
        "  Returns:\n",
        "      values: list of values un-normalised (with the initial range)\n",
        "      type : numpy array\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> print(un_norm([0.6066652923822403],data_max, data_min))\n",
        "      69.19081818170463\n",
        "  \"\"\"\n",
        "  values = np.array([])\n",
        "  for i,value in enumerate(in_values):\n",
        "    values = np.append(values,100*(value - mini)/(maxi - mini))\n",
        "  return values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2DtVamKPbFV",
        "colab_type": "text"
      },
      "source": [
        "### Kfold validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npjje2ZfPeUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validation function for a model\n",
        "def kfold_valid(model,model_dataset, data_max, data_min, verbose=0 ):\n",
        "   \"\"\"\n",
        "  # Valid model with kfold validation. Take an scikit-learn model with\n",
        "  # fit() and score() method. Score used are RÂ² score from scikit-learn. The \n",
        "  # best score is 1 and can go to -inf. If RÂ²=0, the model is constant and \n",
        "  # always predict the y labels\n",
        "  Parameters:\n",
        "      :param model: learning model from scikit-learn or compatible  \n",
        "      :param model_data: DataFrame containing x and y set ; created with\n",
        "      create_model_dataset(labels,features) function\n",
        "      :param data_max: maximum of the distribution after normalisation ;  \n",
        "      :param data_min: minimum of the distribution after normalisation \n",
        "      :param verbose (default:0): if verbose = 1, print for each model \n",
        "      prediction and ground truth \n",
        "      \n",
        "      :type model: learning model from scikit-learn or compatible  \n",
        "      :type model_data: DataFrame (pandas)\n",
        "      :type data_max: float  \n",
        "      :type data_min: float \n",
        "      :type verbose (default:0): int [0,1]\n",
        "      \n",
        "  Returns:\n",
        "      mean_score : mean score over kfold validation with 10 folds \n",
        "      type : float\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> model = linear_model.Lasso(alpha=0.1)\n",
        "      >>> lasso_score = kfold_valid(model, model_dataset,data_max,data_min)\n",
        "    \n",
        "    (44, 7) : x_set shape\n",
        "  Final score : -0.24054111866533903\n",
        "  Final score : -0.07246287170463583\n",
        "  Final score : -0.4313794791716872\n",
        "  Final score : 0.17992142432998948\n",
        "  Final score : -0.02666638704382618\n",
        "  Final score : 0.003121865088597131\n",
        "  Final score : -0.9381668682410977\n",
        "  Final score : -0.14343816199947357\n",
        "  Final score : -1.030613322481495\n",
        "  Final score : -0.1075240882471391\n",
        "  Score moyen : -0.28077490081361073\n",
        "  \"\"\"\n",
        "  \n",
        "  df_x = model_dataset[model_dataset.columns[1:len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_x)\n",
        "  df_y = model_dataset[model_dataset.columns[len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_y)\n",
        "  nb_split=10\n",
        "  print(df_x.shape)\n",
        "  kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
        "  aux = 0\n",
        "  for train_index, test_index in kf.split(df_y):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    model= in_model\n",
        "    model.fit(df_x[train_index], df_y[train_index])\n",
        " print(get_medium(\"100\",csv_file))\n",
        " Unnamed: 0      code_doc  il08_09  ...  la09_10  cg13_14  mb00_12\n",
        "5              6    57_6_100_1       -1  ...     -1.0     -1.0       76\n",
        "55            56   147_1_100_1       -1  ...     -1.0     -1.0       64\n",
        "135          136   210_3_100_1       70  ...     -1.0     -1.0       -1\n",
        "        ... \n",
        "    score = model.score(df_x[test_index], df_y[test_index])\n",
        "    aux += score\n",
        "    \n",
        "    print(\"Final score : \" +str(score) )\n",
        "    predict = model.predict(df_x[test_index])\n",
        "    if verbose==1:\n",
        "      print(\"Pred = \" + str(un_norm(predict,data_max,data_min)) )\n",
        "      print(\"Ground truth = \" + str(un_norm(df_y[test_index],data_max,data_min)))\n",
        "  print(\"Score moyen : \" + str(float(aux/nb_split)))\n",
        "  return float(aux/nb_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z16ekrqAKmVW",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning models with KFolds (10 folds) \n",
        "* Lasso regression (scikit-learn)\n",
        "* SGD Regressor (scikit-learn)\n",
        "* Gradient Boosting regressor (scikit-learn)\n",
        "* MLP regressor (scikit-learn)\n",
        "* Decision trees (scikit-learn)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoDLvcAJPHFi",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Regression (scikit-learn) : only text medium\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10zaiOOlJwqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
        "text_label = get_medium(\"001\",updated_csv)\n",
        "text_feat = text_feat.rename(columns={\"doc\":\"code_doc\"})\n",
        "# Get label dataset\n",
        "dataset = get_medium(\"001\",get_dataset(updated_csv))\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,text_feat )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model = linear_model.Lasso(alpha=0.1)\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJDIVMExJq3j",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Regression (scikit-learn) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akzr3iATLHZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "\n",
        "#print(norm_dataset[norm_dataset.columns[2:]].mean(axis=1))\n",
        "#print(create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model = linear_model.Lasso(alpha=0.1)\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c8rGPRRB2zY",
        "colab_type": "text"
      },
      "source": [
        "## SGD Regressor (Text only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKOpFuBk3NNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
        "text_label = get_medium(\"001\",updated_csv)\n",
        "text_feat = text_feat.rename(columns={\"doc\":\"code_doc\"})\n",
        "# Get label dataset\n",
        "dataset = get_medium(\"001\",get_dataset(updated_csv))\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,text_feat )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "model=  linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=\"elasticnet\")\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRHYLcnf36Eb",
        "colab_type": "text"
      },
      "source": [
        "## SGD Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aziSaE6U3-EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "#norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "model=  linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=\"elasticnet\")\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXwwBbE4dxg",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting Regressor (Text only)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z94eTI6sCIAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
        "text_label = get_medium(\"001\",updated_csv)\n",
        "text_feat = text_feat.rename(columns={\"doc\":\"code_doc\"})\n",
        "# Get label dataset\n",
        "dataset = get_medium(\"001\",get_dataset(updated_csv))\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,text_feat )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=  GradientBoostingRegressor(loss=\"ls\",learning_rate=0.5,n_estimators=10000)\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmUG0Ps7CE1r",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVGJFBcP4dm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "#norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=  GradientBoostingRegressor(loss=\"ls\",learning_rate=0.5,n_estimators=10000)\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLWKFdzf7RF7",
        "colab_type": "text"
      },
      "source": [
        "## MLP regressor (scikit-learn)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixPYe_857Uko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "#norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model= MLPRegressor()\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_fnEF6071qV",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZG_-zQ73Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "#norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=tree.DecisionTreeRegressor()\n",
        "\n",
        "\n",
        "lasso_score = kfold_valid(model, model_dataset,data_max,data_min,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg4mrF18LG6W",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning : Neural network \n",
        "\n",
        "\n",
        "Deep learning model with Keras over Tensorflow ( KFold with 10 folds as it is a small neural network with low number of samples ) :\n",
        "* Dense multilayer neural network with dropout, regularization, early stopping on validation ( optimizer : Adam, loss : MSE, metric : MAE)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLYXSZvlEApL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_network(nb_features):\n",
        "  model = Sequential()\n",
        " # model.add(Conv1D(4, int(nb_features[0]/2),input_shape=(nb_features[1], nb_features[2]), strides=1, padding='valid', dilation_rate=1, activation=None, \n",
        "  #                              use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', data_format=\"channels_first\",\n",
        "   #                             kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
        "  model.add(Dense(8, input_shape=(nb_features,)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  #model.add(GaussianNoise(0.1))\n",
        "  model.add(Dense(4, activation='relu',kernel_initializer='normal'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
        "  \n",
        "  #model.add(Dense(nb_features, activation='relu'))#,kernel_regularizer=regularizers.l2(0.01)))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Dense(2, activation='relu',kernel_regularizer=regularizers.l2(0.01) ))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(Flatten())\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  adam = Adam(lr=0.0001)\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def kfold_valid_keras(in_model,model_dataset, data_max, data_min, verbose=0,nb_epoch = 100 ):\n",
        "  \"\"\"\n",
        "  # Valid model with kfold validation for keras model. Take an compatible keras\n",
        "  # model with fit() and evaluate() function. Score used are score from \n",
        "  # evaluate. It depends on the loss function  \n",
        "  Parameters:\n",
        "      :param model: learning model from scikit-learn or compatible  \n",
        "      :param model_data: DataFrame containing x and y set ; created with\n",
        "      create_model_dataset(labels,features) function\n",
        "      :param data_max: maximum of the distribution after normalisation ;  \n",
        "      :param data_min: minimum of the distribution after normalisation \n",
        "      :param verbose (default:0): if verbose = 1, print for each model \n",
        "      prediction and ground truth \n",
        "      \n",
        "      :type model: learning model from scikit-learn or compatible  \n",
        "      :type model_data: DataFrame (pandas)\n",
        "      :type data_max: float  \n",
        "      :type data_min: float \n",
        "      :type verbose (default:0): int [0,1]\n",
        "      \n",
        "  Returns:\n",
        "      mean_score : mean score over kfold validation with 10 folds \n",
        "      type : float\n",
        "      \n",
        "  :Example:\n",
        "\n",
        "      >>> model=get_network(len(model_dataset.columns[1:-1]))\n",
        "      >>> mean_score = kfold_valid_keras(model, model_dataset,data_max,data_min)\n",
        "    (44, 7) : x_set shape\n",
        "    ....\n",
        "    Epoch 00011: early stopping\n",
        "    4/4 [==============================] - 0s 257us/step\n",
        "    Final score : [0.41310545802116394, 0.62394779920578]\n",
        "    Epoch 00014: early stopping\n",
        "    4/4 [==============================] - 0s 188us/step\n",
        "    Final score : [1.2279276847839355, 0.9716480374336243]\n",
        "    Score moyen : 0.7768264234066009\n",
        "    83.01624438964666\n",
        "  \"\"\"\n",
        "  \n",
        "  df_x = model_dataset[model_dataset.columns[1:len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_x)\n",
        "  df_y = model_dataset[model_dataset.columns[len(model_dataset.columns)-1]].to_numpy()\n",
        "  #print(df_y)\n",
        "  nb_split=10\n",
        "  print(df_x.shape)\n",
        "  kf = KFold(n_splits = nb_split, shuffle = True, random_state = 0)\n",
        "  aux = 0\n",
        "  for train_index, test_index in kf.split(df_y):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    model= in_model\n",
        "    model.fit(df_x[train_index], df_y[train_index], validation_data=(df_x[test_index], df_y[test_index]),epochs=300\n",
        "            , verbose = 0, callbacks=[EarlyStopping(verbose=1,patience = 10)])\n",
        "    score = model.evaluate(df_x[test_index], df_y[test_index])\n",
        "    aux += score[0]\n",
        "    \n",
        "    print(\"Final score : \" +str(score) )\n",
        "    predict = model.predict(df_x[test_index])\n",
        "    if verbose==1:\n",
        "      print(\"Pred = \" + str(un_norm(predict,data_max,data_min)) )\n",
        "      print(\"Ground truth = \" + str(un_norm(df_y[test_index],data_max,data_min)))\n",
        "  print(\"Score moyen : \" + str(float(aux/nb_split)))\n",
        "  return float(aux/nb_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdpHhYjgEDcV",
        "colab_type": "text"
      },
      "source": [
        "### Dense neural network (Only on text dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdwpR4s5EFuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "text_feat = pd.read_csv(\"Text_Features_6.csv\")\n",
        "text_label = get_medium(\"001\",updated_csv)\n",
        "text_feat = text_feat.rename(columns={\"doc\":\"code_doc\"})\n",
        "# Get label dataset\n",
        "dataset = get_medium(\"001\",get_dataset(updated_csv))\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,text_feat )\n",
        "# Remove Na row : unless error are raised  \n",
        "#print(model_dataset)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model= get_network(len(model_dataset.columns[1:-1]))\n",
        "\n",
        "\n",
        "mean_score = kfold_valid_keras(model, model_dataset,data_max,data_min)\n",
        "mean_score = 100*(mean_score - data_min)/(data_max - data_min)\n",
        "print(mean_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMu8jCsoE8Ed",
        "colab_type": "text"
      },
      "source": [
        "###Dense neural network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwOZ70oiLm3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "# Get label dataset\n",
        "dataset = get_dataset(updated_csv)\n",
        "# Normalize dataset\n",
        "norm_dataset,data_max_list, data_min_list = normalisation_annot(dataset)\n",
        "data_max = data_max_list.mean()\n",
        "data_min = data_min_list.mean()\n",
        "# Transform code_doc to match on merge\n",
        "#norm_dataset[\"code_doc\"] = norm_dataset[\"code_doc\"].map(lambda x : x[:-6] )\n",
        "# Create dataset with feature and labels in one DataFrame\n",
        "model_dataset= create_model_dataset(norm_dataset,create_features_dataframe(\"Text_Features_6.csv\",\"silence_rolling_mean_new.csv\",\"feat_break.csv\") )\n",
        "# Remove Na row : unless error are raised  \n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "model=get_network(len(model_dataset.columns[1:-1]))\n",
        "\n",
        "\n",
        "mean_score = kfold_valid_keras(model, model_dataset,data_max,data_min)\n",
        "mean_score = 100*(mean_score - data_min)/(data_max - data_min)\n",
        "print(mean_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJUIsLYFTNa",
        "colab_type": "text"
      },
      "source": [
        "# 2nd approach : statistical modelisation\n",
        "Based on Henry model (that are an adaptation to french language of the Flesh formula for english language text readability)\n",
        "\n",
        "\n",
        "https://fr.wikipedia.org/wiki/Test_de_lisibilit%C3%A9\n",
        "\n",
        "\n",
        "https://en.wikipedia.org/wiki/Readability_test \n",
        "\n",
        "\n",
        "https://www.persee.fr/doc/colan_0336-1500_1980_num_45_1_1364 : \"LisibilitÃ© et comprÃ©hension\" Georges Henry 1980 \n",
        "\n",
        "\n",
        "https://www.persee.fr/doc/colan_0336-1500_1973_num_17_1_3978#colan_0336-1500_1973_num_17_1_T1_0014_0000 This document describes 5 differents method to make the text complexity scoring. Each could be combine to make a certainly efficient model.  \n",
        "\n",
        "Another method to make a complexity score for text document made by research from \"UniversitÃ© Catholique de Louvain\" in France that could be used to make a statistical model of complexity estimation. https://www.academia.edu/237263/Mod%C3%A8les_statistiques_pour_l_estimation_automatique_de_la_difficult%C3%A9_de_textes_de_FLE \n",
        "\n",
        "The text complexity score is the Henry formula that takes in account the vocabulary complexity with the number of syllable for 100 words and the complexity of sentences with the lenght of the sentence.\n",
        "\n",
        "Based on the text complexity formula, we assume that audio complexity is mainly described with the recognition score (the rate of words recognized by an automatic recognition model (mainly Google neural network) ). \n",
        "\n",
        "\n",
        "The video features were a difficult part to aggregate. Video is commonly not part of complexity estimation. We choosed to use the number of scene breaks to take a look at the quantity of visual informations that are given and we assume that if there are too much informations, it leads people to be more confused with video.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J29ln4qF8he4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def human_interest():\n",
        "  # TODO : this function has to return the human_interest of a text. It's the \n",
        "  # second part of the Henry model assuming that a text complex by its intern\n",
        "  # complexity but also by the interest that it can provide to someone.\n",
        "  return None\n",
        "\n",
        "def facilite_lect(nb_mot_phrase, nb_syll_mot):\n",
        "  '''\n",
        "   Implementation of Rudolf Flesh from an article of AndrÃ© Conquet and FranÃ§ois \n",
        "    Richaudeau : \"Cinq mÃ©thodes de lisibilitÃ©\"\n",
        "  https://www.persee.fr/doc/colan_0336-1500_1973_num_17_1_3978#colan_0336-1500_1973_num_17_1_T1_0014_0000\n",
        "  Parameters:\n",
        "      :param nb_mot_phrase: mean number of words in a sentence \n",
        "      :param nb_syll_mot: mean number of syllable for 100 words\n",
        "      \n",
        "      \n",
        "      :type model: float or list of float (array numpy or DataFrame)\n",
        "      :type model_data: float or list of float( array numpy or DataFrame pandas)\n",
        "      \n",
        "  Returns:\n",
        "      readability_score : the readability_score of a text, our text complexity \n",
        "      score \n",
        "      type : float or list of float (depends on the input)\n",
        "  Other itema to note:\n",
        "    - The score has been defined to make a range from 100(easy) to 0 (difficult),\n",
        "    in our case, the range we want is the opposite so we have to substract this\n",
        "    score to 100 to have the good range. \n",
        "    - The parameters have to be compatible type or the same type.\n",
        "  :Example:\n",
        "\n",
        "      >>> print(100-facilite_lect(new_text_feat[\"len_sentence\"],new_text_feat[\"syll_100\"]))\n",
        "      0      29.260867\n",
        "      1      31.057720\n",
        "      2      23.773652\n",
        "      3      28.968902\n",
        "      4      33.154229\n",
        "  '''\n",
        "  return   206.835 -(nb_mot_phrase*1.815 + nb_syll_mot * 0.846) \n",
        "\n",
        "\n",
        "# Score function for multimedia document\n",
        "def score_doc(facilite_text, reco_audio=None, feat_vid=None):\n",
        "  '''\n",
        "  We assume that the complexity of a document is a combination of the text\n",
        "  complexity and the audio comprehensibility\n",
        "  Weights have to be learned to be accurate \n",
        "  Parameters:\n",
        "      :param facilite_text: score of text complexity (compute with facilite_text\n",
        "      function that compute Henry formula) \n",
        "      :param reco_audio (default = None) : recognition score (range [0,100])\n",
        "      :param feat_vid (default = None) : number of scene break in 1 minute\n",
        "      \n",
        "      :type facilite_text: float or list of float (array numpy or DataFrame)\n",
        "      :type reco_audio: float or list of float( array numpy or DataFrame pandas)\n",
        "      :type feat_vid: float or list of float( array numpy or DataFrame pandas)\n",
        "      \n",
        "  Returns:\n",
        "      complexity_score : the complexity score of a multimedia document \n",
        "      type : float or list of float (depends on the input)\n",
        "  Other itema to note:\n",
        "    - Our model is a linear combination with abitrary defined weights (on \n",
        "    empirical results). This model should be better if a regression on theses\n",
        "    weights is made.\n",
        "    - If audio and / or video features are not given, it still will perform\n",
        "    scoring.\n",
        "  Exemple : \n",
        "  >>> score_doc(text_score,audio_score,nb_scene_break )\n",
        "  0      58.515238\n",
        "  1      54.715241\n",
        "  2      68.236936\n",
        "  3      77.557951\n",
        "  4      62.491477\n",
        "          ... \n",
        "  '''\n",
        "  vid_threshold = 15\n",
        "  if reco_audio is None and feat_vid is None:\n",
        "    return facilite_text\n",
        "  if feat_vid is None :\n",
        "    return (0.7*facilite_text + 0.3*reco_audio )\n",
        "  vid = []\n",
        "  for i in feat_vid:\n",
        "    # 15 is approximatively the number scene_break \n",
        "    # under which are 75% of the documents  \n",
        "    if i > vid_threshold:\n",
        "      vid.append(-5)\n",
        "    else:\n",
        "      vid.append(5)\n",
        "  aux = 0.7*facilite_text + 0.3*reco_audio \n",
        "  for index, row in enumerate(aux):\n",
        "    aux[index] += vid[index]\n",
        "  return aux    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDnQEikRy5nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_multimedia = create_features_dataframe(\"Text_Features_6.csv\",\"./silence_rolling_mean_new.csv\",\"feat_break.csv\")\n",
        "text_score = facilite_lect(data_multimedia[\"len_sentence\"],data_multimedia[\"syll_100\"])\n",
        "audio_score =data_multimedia[\"Recognition score\"] \n",
        "nb_scene_break = data_multimedia[\"scene_br_per_min\"]\n",
        "score = pd.DataFrame(score_doc(text_score,audio_score,nb_scene_break ))\n",
        "\n",
        "score = score.rename(columns={0:\"complex_score\"})\n",
        "\n",
        "score = pd.merge(data_multimedia[\"code_doc\"],score,left_index=True, right_index=True)\n",
        "score.sort_values(\"complex_score\")\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySMo88QszaIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "updated_csv = pd.read_csv(\"/content/annotations_challenge_sid (2).csv\", sep=\",\" )\n",
        "data = get_dataset(updated_csv)\n",
        "data_test = pd.DataFrame()\n",
        "\n",
        "data_test[\"code_doc\"]=data[\"code_doc\"].map(lambda x : x[:-6])\n",
        "data = data.replace(-1,np.nan)\n",
        "data_test[\"label\"]=data[data.columns[2:]].median(axis=1)\n",
        "data[\"code_doc\"] = data[\"code_doc\"].map(lambda x : x[:-6])\n",
        "data_test = pd.merge(data_test, score[score.columns[:2]], left_on=\"code_doc\", right_on=\"code_doc\")\n",
        "data_test\n",
        "def dist_label(df_score):\n",
        "  aux = 0\n",
        "  last_ind = 0\n",
        "  for index, row in df_score.iterrows():\n",
        "    aux += abs(row['label']-row['complex_score'])\n",
        "    last_ind = index\n",
        "  aux/=(last_ind+1)\n",
        "  print(aux)\n",
        "\n",
        "print(\"The mean distance from labels is :\")\n",
        "dist_label(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIRtJ4GC1HcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}