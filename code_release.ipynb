{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "code_release.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkW7sqD1zV4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf challenge-m2-sid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zryTkj3zT2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cedb7ab-4d27-43ae-e43c-bcf3745f3518"
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# Liaison avec les données\n",
        "!git clone \"https://etudiantsid:etudiantsidPW;@gitlab.com/jeromefarinas/challenge-m2-sid.git\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.3 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 132681 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package bc.\n",
            "Preparing to unpack .../4-bc_1.07.1-2_amd64.deb ...\n",
            "Unpacking bc (1.07.1-2) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../5-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../7-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../8-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package tree.\n",
            "Preparing to unpack .../9-tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up bc (1.07.1-2) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Cloning into 'challenge-m2-sid'...\n",
            "remote: Enumerating objects: 938, done.\u001b[K\n",
            "remote: Counting objects: 100% (938/938), done.\u001b[K\n",
            "remote: Compressing objects: 100% (930/930), done.\u001b[K\n",
            "Receiving objects: 100% (938/938), 2.15 GiB | 35.79 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "remote: Total 938 (delta 5), reused 933 (delta 3)\u001b[K\n",
            "Checking out files: 100% (904/904), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7nhbJiyQj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "from sklearn import preprocessing\n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import spacy\n",
        "from google.colab import files\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51HL92_6ySiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_text = 'challenge-m2-sid/corpus/text/'\n",
        "List_txt = os.listdir(path_text)\n",
        "List_txt.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu4hWmun07Vf",
        "colab_type": "text"
      },
      "source": [
        "# Section "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFUjK5tjzahv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get only text betwen headers \n",
        "def get_sentences(List_txt, path_text):\n",
        "    '''\n",
        "    \n",
        "    :param List_txt : list : file names on which it will be computed\n",
        "    :param path_text : string : path to the directory where to find files  \n",
        "    :return: dictionnary : contains list of sentences for each document\n",
        "    '''\n",
        "  dic_docs = {}\n",
        "  for doc in List_txt:\n",
        "    root = ET.parse(path_text + doc).getroot()\n",
        "    dic_docs[doc] = []\n",
        "    for s in root:\n",
        "      sentence = ''\n",
        "      for w in s:\n",
        "        word = w.text\n",
        "        if (word is not None):\n",
        "          sentence = sentence + word\n",
        "      dic_docs[doc].append(sentence)\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LHKlKXBzcVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove ponctuation in sentences \n",
        "def clean_sentences(dic_docs):  \n",
        "    '''\n",
        "    :param dic_docs: dictionnary that contains list of sentences for each doc\n",
        "    :return: dic_docs : dictionnary that contains list of sentences without \n",
        "    ponctuation and simple quotes; return \"clean sentences\"\n",
        "    '''\n",
        "  for key in dic_docs.keys() : \n",
        "    list_new = []\n",
        "    for sentence in dic_docs[key]:\n",
        "      sentence = sentence.replace(\"'\", ' ').replace(\"’\", ' ')\n",
        "      sentence = re.sub(\"([^\\s\\w\\-])\", '',sentence)\n",
        "      list_new.append(sentence)\n",
        "    dic_docs[key] = list_new\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q1kGwQAzez0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read excel lexique file \n",
        "def read_excel(file):\n",
        "  # Change into def get_lexique(excel_file): ?\n",
        "  '''\n",
        "  Read excel file and return a pandas DataFrame\n",
        "  :param file :  string : path of the excel file to read\n",
        "  :return: df_lex : DataFrame : pandas DataFrame containing \n",
        "  '''\n",
        "  dfs = pd.ExcelFile(file)\n",
        "  sh = dfs.sheet_names[0]\n",
        "  df_lex = dfs.parse('Sheet1')\n",
        "  df_lex = df_lex[['ortho', 'lemme', 'cgram', 'freqlemfilms2']]\n",
        "  serie = df_lex['freqlemfilms2']\n",
        "  normalized_serie=(serie)/max(serie)\n",
        "  df_lex['freqlemfilms2_norm'] = normalized_serie\n",
        "  return(df_lex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhNgIOrpyoW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes spaces, empty word and lower all  \n",
        "def get_clean_words(dic_docs):\n",
        "  '''\n",
        "  Remove spaces, empty words and lower every words in text of each document\n",
        "  :param dic_docs : dictionnary : contains sentences for each document \n",
        "  :return: dic_docs : dictionnary : contains sentences with only lowered \n",
        "  useful words  \n",
        "  '''\n",
        "  for doc in dic_docs.keys() : \n",
        "    list_words = []\n",
        "    for sentence in dic_docs[doc]:\n",
        "      for word in sentence.split():\n",
        "          w = word.replace(' ', '')\n",
        "          if len(w) != 0:\n",
        "            list_words.append(w.lower())\n",
        "    dic_docs[doc] = list_words\n",
        "  return(dic_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiSuuof4z7_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get complexity score of one text document\n",
        "def get_complexity_doc(doc, df_lex, dic_docs,threshold_complex = 0.0001):\n",
        "  '''\n",
        "  Get text complexity score of one document : the score is based on\n",
        "  words frequencies in french. We assume that if a word is not often\n",
        "  used, this word is a complex word.\n",
        "\n",
        "  :param doc :  string : path of the excel file to read\n",
        "  :param df_lex :  pandas.DataFrame : contains the french lexique and \n",
        "  frequencies  \n",
        "  :param dic_docs :   \n",
        "  :param threshold_complex : int : threshold that define what is a \n",
        "  complex word (based on frequencies of vocabulary document)\n",
        "  :return: df_lex : DataFrame : pandas DataFrame containing \n",
        "  '''\n",
        "  cplxty = 0\n",
        "  for word in list(set(dic_docs[doc])):\n",
        "    try : \n",
        "      freq = max(df_lex[df_lex['ortho']==word]['freqlemfilms2_norm'])\n",
        "    except :\n",
        "      if len(word) >= 3:\n",
        "        freq = 0\n",
        "      else : \n",
        "        freq = 1\n",
        "    if freq < threshold_complex:\n",
        "      cplxty = cplxty + 1\n",
        "\n",
        "  cplxty = cplxty/(len(list(set(dic_docs[doc]))))\n",
        "  return(cplxty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y0P_J7Mz-PN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get complexity score of a list of text document\n",
        "def get_all_cplx(List_txt, df_lex, dic_docs):\n",
        "  dic_cplx = {}\n",
        "  i = 1\n",
        "  N = len(List_txt)\n",
        "  for doc in List_txt:\n",
        "    print(str(i) + ' / ' + str(N))\n",
        "    dic_cplx[doc] = get_complexity_doc(doc, df_lex, dic_docs)\n",
        "    i = i + 1\n",
        "  return(dic_cplx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2BK7Mtv0A05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def normalize_results(dic_cplx, ma):\n",
        "  dic_cplx_N = {}\n",
        "  for doc in dic_cplx.keys():\n",
        "    score = dic_cplx[doc]\n",
        "    score = score * 100 /ma\n",
        "    dic_cplx_N[doc] = score\n",
        "  return(dic_cplx_N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDrHaHk9sOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_max_docid(medium, only_commented):\n",
        "  # Get the list of annotated extracts for a medium\n",
        "  medium = get_medium(medium, only_commented)\n",
        "  # Get list of files identifiants\n",
        "  list_file = medium[\"code_doc\"]\n",
        "  # Return the list of couple (doc_id, evaluation max of complexity)\n",
        "  # Return [(doc_id, max(annot)),....]\n",
        "  return {(i[0][:-6]+\".xml\"):i[1:].max() for i in medium[medium.columns[-7:]].values }"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}